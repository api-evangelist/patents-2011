---

title: System and method for image-based rendering with object proxies
abstract: A system and method for rendering with an object proxy. In one embodiment, a method includes forming a set of view textures corresponding to a set of viewing directions; selecting a viewing direction for rendering; selecting at least two view textures from the formed set based on the selected viewing direction; and rendering the object proxy at the selected viewing direction. The rendering step includes applying texture from the selected view textures onto the selected object proxy. The view texture set forming step includes: calculating texture coordinates for the object proxy based on the level of obstruction at different portions of the object proxy and texture packing data; and drawing portions of the object based on the level of obstruction data for the object proxy and based on the texture packing data to obtain a view texture at the selected viewing direction.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08072456&OS=08072456&RS=08072456
owner: Graphics Properties Holdings, Inc.
number: 08072456
owner_city: New Rochelle
owner_country: US
publication_date: 20110120
---
This application is a divisional of U.S. application Ser. No. 12 050 104 filed Mar. 17 2008 now allowed which is a divisional of U.S. application Ser. No. 10 197 845 filed Jul. 19 2002 now U.S. Pat. No. 7 362 335 both of which are incorporated by reference herein in their entirety. This application is related to a commonly owned application by Mech System and Method for Forming an Object Proxy U.S. application Ser. No. 10 197 822 filed Jul. 19 2002 now U.S. Pat. No. 6 831 642 and incorporated by reference herein in its entirety.

A wide variety of applications rely on computer graphics to generate images. An image is made up of an array of picture elements pixels and can be displayed on a display unit such as a monitor screen or cathode ray tube. Images often include graphical representations of objects. Many different types of computing devices with graphics capabilities are used to generate images. Such computing devices use graphics processing. A combination of software firmware and or hardware is used to implement graphics processing. For example graphics processing including rendering can be carried out in a graphics card graphics subsystem graphics processor graphics or rendering pipeline and or a graphics application programming interface API and libraries such as OPENGL.

In computer graphics the geometry of an object is represented by primitives. Common primitives are points lines and polygons such as triangles or quads. Each primitive is made up of points called vertices. Each vertex includes information relating to the object and its graphical display as an image. For example vertex information can include but is not limited to vertex coordinates texture coordinates an alpha value and a depth value. Vertex coordinates define the location of a respective vertex in a three dimensional coordinate space x y z such as an object coordinate space or a world coordinate space. In this way vertex coordinates define the geometry of an object surface. Texture coordinates are coordinates that map to an image in a two dimensional space s t or a three dimension space r s t . One way this image also called a texture is used in graphics processing is to provide additional surface detail to the object. An alpha value is used to represent transparency information. The depth value is used to define depth information.

Increasing demands are being made upon graphics processing. These demands include realism speed and cost. Realistic images are desired to be rendered at real time interactive rates while avoiding burdensome graphics processing or hardware requirements. One way to achieve more realism is to use complex objects. Complex objects however can involve a large number of primitives. For example hundred thousands or millions of triangles may be needed to represent complex objects. This increases the number of calculations and other processing work required to fully render the object.

Billboard image based rendering algorithms have been used as an alternative to full rendering of objects. In such a billboard approach object data is rendered as if it were mapped or tiled on a flat plane or billboard. The billboard approach however sacrifices realism and geometry detail. Accordingly its usefulness is limited to objects viewed from afar unless hundreds of pre computed texture images are used exceeding the limits of texture hardware. The billboard approach also generally requires many pre computed texture images.

There is a needed for a method and system for rendering that provides an intermediate level of rendering quality in between full object rendering and a billboard rendering. Others have approached this problem by using proxy structures for complex objects. These approaches are limited however in that they cannot deal with concave proxies and their rendering algorithms are not well suited for mixing image based rendering objects with regular scenes. Furthermore the rendering algorithms of these approaches are complex and too slow for many if not all real time rendering environments. Thus the approaches of others to this problem have not been successful in fulfilling the need for a method and system for rendering that provides an intermediate level of rendering quality in between full object rendering and a billboard rendering.

The present invention overcomes each of the above identified problems and has additional advantages as described herein. The present invention leverages object proxies to provide an intermediate level of rendering quality.

The present invention provides a system and method for rendering an object proxy. In one embodiment a method includes the steps of forming a set of view textures corresponding to a set of viewing directions selecting a viewing direction for rendering selecting at least two view textures from the formed set based on the selected viewing direction and rendering the object proxy at the selected viewing direction. The rendering step includes applying texture from the selected view textures onto the selected object proxy. This rendering can include but is not limited to image based rendering. Multiple object proxies can be used. One or more objects can be rendered in a single scene or frame for display or animation or other applications.

According to one feature a pre computed view texture is a texture according to the invention that contains view information for an associated pre computed object proxy. In embodiments a view texture according to the invention comprises a pre rendered full view image of an object of interest and pre rendered extra texture patches associated with partially obstructed or fully obstructed polygons of the object proxy. This view information is used during rendering to draw the object of interest in a scene. A pre computed object proxy is a simplification of an object boundary or contour.

According to one embodiment the view texture set forming step includes calculating texture coordinates for the object proxy based on the level of obstruction at different portions of the object proxy and texture packing data and drawing portions of the object based on the level of obstruction data for the object proxy and based on the texture packing data to obtain a view texture at the selected viewing direction.

In one example this drawing step includes i drawing the portions of the object that correspond to unobstructed front facing portions of the object proxy with additional displacement based on corresponding texture packing data ii drawing the portions of the object that correspond to at least partially obstructed front facing portions of the object proxy with additional displacement based on corresponding texture packing data and removal of any intervening object portions and iii drawing the portions of the object that correspond to back facing portions of the object proxy that are visible from nearby viewing directions with additional displacement based on corresponding texture packing data and removal of intervening object portions whereby a view texture having texture patches can be obtained.

In one embodiment a view texture set forming step includes i selecting a particular viewing direction from a set of viewing directions ii determining level of obstruction data for each polygon of an object proxy iii storing the level of obstruction data iv for each polygon determining whether the polygon is visible from the selected particular viewing direction and whether texture should be applied from a neighboring viewing direction v determining texture packing data and vi storing the texture packing data. The view texture set forming step further includes vii adjusting texture coordinates of each polygon for the selected particular viewing direction based on said determining step iv and said texture packing data.

Any type of texture packing technique and data can be used with the present invention. In one embodiment the texture packing data comprises shift and rotation data relative to a viewing direction which is used in a texture packing algorithm to create texture patches.

According to a feature of the present invention the method can include storing the object proxy together with a set of texture coordinates for each viewing direction of the set of viewing directions. Alternatively the method can include forming groups of viewing directions and storing a modified object proxy together with a set of texture coordinates for each group of viewing directions.

The present invention also provides a system for rendering an object proxy. The object proxy approximates the geometry of a respective object. In one embodiment the system includes a view texture former and a renderer. The view texture former forms a set of view textures corresponding to a set of viewing directions. The renderer renders the object proxy at a viewing direction with texture applied from view textures selected from the set of view textures.

In one example the view texture former includes an object proxy texture coordinate calculator and a drawer. The object proxy texture coordinate calculator calculates texture coordinates for the object proxy based on the level of obstruction at different portions of the object proxy and based on texture packing data. The drawer draws portions of the object based on the level of obstruction data for the object proxy and based on the texture packing data to obtain a view texture at a respective viewing direction. Further in one example implementation a drawer is provided that draws the portions of the object that correspond to unobstructed front facing portions of the object proxy with additional displacement based on corresponding texture packing data draws the portions of the object that correspond to at least partially obstructed front facing portions of the object proxy with additional displacement based on corresponding texture packing data and removal of any intervening object portions and draws the portions of the object that correspond to back facing portions of the object proxy that are visible from nearby viewing directions with additional displacement based on corresponding texture packing data and removal of intervening object portions whereby a view texture having texture patches can be obtained.

Rendering based on the use of object proxies according to the present inventions has advantages. First such rendering with the use of object proxies according to the present invention is faster and less expensive than fully rendering objects based on object geometry data. This is especially true for complex objects with large numbers of polygons. On the other hand rendering with the use of object proxies according to the present invention provides more surface detail and realism than conventional approaches that render to a billboard. In this way the present invention allows rendering of one or more objects based on their object proxies to be carried out for display or animation in real time at an interactive rate even on cheaper graphics hardware.

The present invention also provides level of detail rendering and a method for creating a level of detail rendering node. In an embodiment a level of detail rendering node is created by combining three node components. A first node component includes an object and at least one texture. This first node component is used to draw an image of the object at a first level of detail having high resolution. Typically the first node component is used to draw images of the object that are close to a viewer of a scene. A second node component includes an object proxy and a plurality of view textures. The object proxy approximates the geometry of the object. The second node component is used to draw the image of the object at a second level of detail having intermediate resolution. A third node component includes a billboard with several small views. The third node component is used to draw the image of the object at a third level of detail having low resolution. Typically the third node component is used to draw images of the object that are far from the viewer. During rendering the first node component the second node component or the node component of the level of detail node is selected and used to draw the image of the object based on an input distance. In embodiments the input distance is the distance between the image of the object and the viewer.

Further embodiments features and advantages of the present invention as well as the structure and operation of the various embodiments of the present invention are described in detail below with reference to accompanying drawings.

The present invention provides a method a system and a computer program product for image based rendering with object proxies. An object proxy is a simplification of an object boundary that is useful for hardware accelerated image based rendering. As described herein image based rendering with object proxies according to the present invention makes it possible both to render more image based objects in a single computer generated scene and to render these image based objects using fewer views textures than conventional image based rendering schemes.

The following terms are defined so that they may be used to describe embodiments of the present invention. As used herein 

 Pixel means a data structure which is used to represent a picture element. Any type of pixel format can be used.

 Real time or Interactive Rate refers to a rate at which successive display images can be redrawn without undue delay upon a user or application. This can include but is not limited to a nominal rate of between 30 60 frames second. In some example embodiments such as some flight simulators or some interactive computer games an interactive rate may be approximately 10 frames second. In some examples real time can be one update per second.

 Texture means an array of texels. A texel can be a color or an intensity value. A texture can be any array of values that is used to determine a value for a pixel. As used herein the term texture includes for example texture maps bump maps and gloss maps.

 Texture sample means a sample selected from a texture map or texture. The sample can represent one texel value or can be formed from two or more texel values blended together. Different weighting factors can be used for each texel blended together to form a texel. The terms texel and texture sample are sometimes used interchangeably.

 Texture unit refers to graphics hardware firmware and or software that can be used to obtain a texture sample e.g. a point sample or a filtered texture sample from a texture. A texture unit can in some instances obtain multiple texture samples from multiple textures.

Architecture includes six overlapping layers. Layer represents a high level software application program. Layer represents a three dimensional 3D graphics software tool kit such as OPENGL PERFORMER. Layer represents a graphics application programming interface API which can include but is not limited to OPENGL available from Silicon Graphics Incorporated. Layer represents system support such as operating system and or windowing system support. Layer represents firmware. Finally layer represents hardware including graphics hardware. Hardware can be any hardware or graphics hardware including but not limited to a computer graphics processor single chip or multiple chip a specially designed computer an interactive graphics machine a gaming platform a low end game system a game console a network architecture et cetera. Some or all of the layers of architecture will be available in most commercially available computers.

As will be apparent to a person skilled in the relevant art after reading the description of the invention herein various features of the invention can be implemented in any one of the layers of architecture or in any combination of layers of architecture .

Host system comprises an application program a hardware interface or graphics API a processor and a memory . Application program can be any program requiring the rendering of a computer image. The computer code of application program is executed by processor . Application program assesses the features of graphics subsystem and display through hardware interface or graphics API . Memory stores information used by application program .

Graphics subsystem comprises a vertex operation module a pixel operation module a rasterizer a texture memory and a frame buffer . Texture memory can store one or more textures or images such as texture . Texture memory is connected to a texture unit by a bus not shown . Rasterizer comprises a texture unit and a blending unit . Texture unit and blending unit can be implemented separately or together as part of a graphics processor. The operation of these features of graphics system would be known to a person skilled in the relevant art given the description herein.

In embodiments of the present invention texture unit can obtain multiple point samples or multiple filtered texture samples from textures and or images stored in texture memory . Blending unit blends texels and or pixel values according to weighting values to produce a single texel or pixel. The output of texture unit and or blending unit is stored in frame buffer . Display can be used to display images stored in frame buffer .

The embodiment of the invention shown in has a multipass graphics pipeline. It is capable of operating on each pixel of an image object during each pass that the image makes through the graphics pipeline. For each pixel of the image during each pass that the image makes through the graphics pipeline texture unit can obtain at least one texture sample from the textures and or images stored in texture memory . Although the embodiment of the invention shown in has a multipass graphics pipeline it is noted here that other embodiments of the invention do not have a multipass graphics pipeline. As described below method embodiments of the invention can be implemented using systems that do not have a multipass graphics pipeline.

In an embodiment method operates as follows. A viewing direction for rendering an object is chosen. Next at least two pre computed view textures and a pre computed object proxy associated with the chosen viewing direction are selected. Blending weights are assigned to each of the selected view textures. The object is then drawn to a buffer using the selected object proxy the selected view textures and the assigned blending weights. The selected view textures are blended during rendering in accordance with the assigned blending weights.

As illustrated in method comprises steps and . Each of these steps will now be described in further detail with reference to the flowchart of .

In step as noted above a viewing direction for rendering the object of interest is selected. As used herein viewing direction means the direction from which the object will appear to be seen by a viewer after it is drawn or rendered. The viewing direction selected in step can be any arbitrary direction. illustrates several example viewing directions associated with an object proxy .

In step at least two pre computed view textures and an associated pre computed object proxy are selected. As used herein a pre computed view texture is a texture according to the invention that contains view information for an associated pre computed object proxy. In embodiments a view texture according to the invention comprises a pre rendered full view image of an object of interest and pre rendered extra texture patches associated with partially obstructed or fully obstructed polygons of the object proxy. This view information is used during rendering to draw the object of interest in a computer scene. A pre computed object proxy as described above is a simplification of an object boundary that is useful for hardware accelerated image based rendering.

In accordance with the invention view textures are pre computed for particular views of an object or object proxy. Thus each pre computed view texture has an associated viewing direction. For example a particular view texture can be associated with either a front view of an object a side view of an object or a top view of an object. A method for forming a set of view textures for a pre computed object proxy according to an embodiment of the invention is described below with reference to .

In embodiments of the invention object proxies pre computed in accordance with the methods described by Mech in U.S. patent application Ser. No. 10 197 822 filed Jul. 19 2002 now U.S. Pat. No. 6 831 642 entitled Method and System for Forming an Object Proxy which is incorporated herein by reference in its entirety are used with the method of the present invention. In U.S. patent application Ser. No. 10 197 822 for example a method includes forming a volume that encompasses the object forming an isosurface within the volume adjusting the isosurface relative to a surface of the object and pruning the isosurface to obtain the object proxy. The present invention is not limited however to using just the object proxies described by Mech in U.S. patent application Ser. No. 10 197 822 now U.S. Pat. No. 6 831 642. In general object proxies computed by any means can be used with method of the present invention.

In embodiments of the invention the three or the four closest view textures to the viewing direction selected in step are chosen in step . As described below with reference to viewing directions can be thought of as defining points on the surface of a unit sphere. Thus the viewing direction selected in step and the viewing directions associated with individual view textures can also be thought of as points on a unit sphere. If these points on the unit sphere are triangulated each spherical triangle defines a group of views a group of view textures and or a group of viewing directions. Similarly if the viewing directions are thought of as defining rings of views with each ring having the same angle from a horizontal plane the two nearest point in two neighboring rings also define a group of views a group of view textures and or a group of viewing directions. Therefore in embodiments the three or the four points on a unit sphere for which pre computed view textures exist that are closest to the point representing the viewing direction selected in step are used to determine which view textures are selected in step .

In one embodiment the three points representing the vertices of a spherical triangle into which the point representing the selected viewing direction falls are used to select the view textures in step . In another embodiment wherein rings of views are used the two nearest rings and the two nearest points on each ring closest to the selected viewing direction point for which pre computed view textures exists are used to select four view textures in step . In general any technique can be used to select view textures in step that are nearest to the viewing direction selected in step .

As described herein pre computed view textures are associated with a particular pre computed object proxy. Thus the object proxy selected in step is the object proxy associated with the selected view textures.

In step blending weights are assigned to each view texture selected in step . In embodiments for example where three nearest view textures are selected in step the weights assigned to the selected view textures are determined using barycentric coordinates of the viewing direction point inside a spherical triangle. In embodiments for example where four nearest view textures are selected in step the weights assigned to the selected view textures are determined based on the distances from the rings and from the view textures in the rings. In general any technique that defines continuous and linear weights across a group of view textures can be used to assign the weights in step .

In step the object of interest is drawn to a buffer using the selected object proxy of step the selected view textures of step and the assigned blending weights of step . The selected view textures are blended during the rendering or drawing of the object in accordance with the assigned blending weights.

In one embodiment using a multipass graphics pipeline and for which three view textures are to be combined the object is drawn to the buffer as follows. During a first pass object proxy polygons e.g. triangles are rendered into an alpha channel of the buffer using the first selected view texture and its assigned blending weight. During this first pass overwrite the contents of the alpha channel. During a second pass object proxy polygons are rendered into the alpha channel of the buffer using the second selected view texture and its assigned blending weight blending this result with the result of the first pass. During a third pass object proxy polygons are rendered into an alpha channel of the buffer using the third selected view texture and its assigned blending weight blending this result with the result of the second pass. During a fourth pass object proxy polygons are rendered into a color channel of the buffer using the first selected view texture and its assigned blending weight and blending this result with the background colors using the values in the alpha channel. During a fifth pass object proxy polygons are rendered into the color channel of the buffer using the second selected view texture and its assigned blending weight adding this result to the result of the fourth pass. During a sixth pass object proxy polygons are rendered into the color channel of the buffer using the third selected view texture and its assigned blending weight adding this result to the result of the fifth pass. In another embodiment using hardware with register combiners the steps described above can be performed in a single pass through the graphics pipeline by appropriately setting the register combiners.

It is a feature of method that it can be used to create various rendering steps in between for example the full rendering of a complex object and billboard image based rendering. This is due in part to the fact that method can be used with an object proxy having fewer images than a billboard rendering scheme but less geometry than a full version of an object of interest. By creating several rendering steps between these two extremes in accordance with the invention it is possible to create several levels of detail that are used based on distances between a viewer and the rendered object. For example at close distances a full version of the object is used in rendering. As the viewer of the scene moves away from the object an object proxy having the appropriate level of detail is selected from a group of proxies and used in rendering. This group of proxies include more complex proxies having a limited number of associated view textures and less complex proxies having a large number of associated view textures. At large distances a billboard with many small views is used in rendering.

In step a first node component having an object and at least one texture is formed. The first node component is used to draw an image of the object at a first level of detail having high resolution. Typically the first node component is used to draw images of the object that are close to a viewer.

In step a second node component having an object proxy and a plurality of view textures is formed. As described herein the object proxy approximates the geometry of the object. The second node component is used to draw the image of the object at a second level of detail having intermediate resolution.

In embodiments of the invention additional node components similar to the second node component are also foamed. These node components have object proxies of varying numbers of polygons e.g. triangles and they have varying numbers of view textures. These additional node components when formed increase the levels of detail available and provide additional intermediate levels of rendering quality in between full object rendering and a billboard rendering.

In step a third node component having a billboard with several small views is formed. The third node component is used to draw the image of the object at a third level of detail having low resolution. Typically the third node component is used to draw images of the object that are far from the viewer.

In step the first node component the second node component and the third node component are combined into a level of detail node. During rendering the first node component the second node component or the node component of the level of detail node is selected and used to draw the image of the object based on an input distance.

In embodiments having several additional node components similar to the second node component all of the node components are combined to form the level of detail node.

In embodiments the input distance is the distance between the image of the object and the viewer. Thus when the viewer is close to the image of the object the image is drawn in the scene using the object of the first node component. In this instance the image is drawn with high resolution. As the viewer starts walking away from the image the distance between the image and the viewer increases. As the viewer continues to walk away from the image of object at some point the level of detail rendering node starts using the object proxy of the second node component rather than the object of the first node component to drawn the image in the scene. In this instance the image is drawn with medium resolution. As the viewer walks further and further away from the image of the object at some point the level of detail rendering node starts using the billboard of the third node component to drawn the image in the scene with low resolution. In embodiments having graphics hardware that supports blending between different levels of detail the transitions between the node components of the level of detail node are seamless.

The advantages of this feature and other features of the invention will be apparent to persons skilled in the relevant computer art given the description herein.

In step a set of viewing directions is determined for an object proxy. The set of viewing directions can be determined in any chosen manner. For example as illustrated by in embodiments the viewing directions can be chosen to be uniformly distributed in two dimensions or three dimensions about the object proxy. In other embodiments the set of viewing directions are not chosen to be uniformly distributed about the object proxy. In some embodiments for example more views are chosen for directions showing a lot of object details and fewer views are chosen for directions showing only minor object details. In some embodiments more views are chosen for directions in which the geometry of the object proxy is significantly different than the geometry of the object and fewer views are chosen for directions in which the geometry of the object proxy and the object are similar.

In step a level of obstruction is determined for and assigned to each triangle of the associated object proxy when viewed from the viewing direction selected in step . In an embodiment the numerical values 1 1 2 2 3 3 . . . N N are used to indicate a triangle s level of obstruction. In this embodiment the numerical value 1 is assigned to a triangle that is front facing and that is not obstructed by another triangle. The numerical value 1 is assigned to a triangle that is back facing and obstructed by a single front facing triangle i.e. a level 1 triangle . The numerical value 2 is assigned to a triangle that is front facing and obstructed by a single front facing triangle a level 1 triangle and a single back facing triangle a level 1 triangle . The numerical value 2 is assigned to a triangle that is back facing and obstructed by two front facing triangles a level 1 triangle and a level 2 triangle and a single back facing triangle a level 1 triangle . In general a triangle having a level of obstruction N is obstructed by N 1 front facing triangles and N 1 back facing triangles. A triangle have a level of obstruction N is obstructed by N front facing triangles and N 1 back facing triangles.

In step the level of obstruction data determined in step is stored. In an embodiment this data is stored in a memory.

In step for each triangle of the object proxy it is determined whether the triangle is visible from the selected viewing direction and whether the triangle should use texture from a neighboring viewing direction. Texture from a neighboring view is used for example for obstructed and or back facing triangles that can come into view as the object proxy is rotated about an axis.

In step a texture packing scheme is selected for packing the view texture. Any texture packing scheme can be selected. Preferably the selected texture packing scheme is one that packs polygons e.g. triangles around an image of irregular shape.

In step the shift and rotation data needed to pack each texture patch is determined. This shift and rotation data is used below in steps and to determine texture coordinates for each triangle of the object proxy.

In step the shift and rotation data determined in step is stored. In an embodiment this data is also stored in a memory.

In step the texture coordinates of each triangle of the object proxy are adjusted using the shift and rotation data stored in step . This is done so that the correct texture or texture patch will be used to render the triangles of the object proxy. In an embodiment the shift and rotation data stored in step are applied to the texture coordinates associated with the object proxy and the selected viewing direction to create new texture coordinates. These new texture coordinates then map to the correct texture or texture patch of a view texture formed in accordance with the invention.

In step it is determined whether a texture packing scheme has been computed for each viewing direction of the set of viewing directions chosen in step . If a texture packing scheme has not been computed for each of the viewing directions another viewing direction is selected step and the steps through are repeated for the newly selected viewing direction. If a texture packing scheme has been computed for each of the viewing directions control passes from step to step .

A reason for computing the texture packing scheme for each of the viewing directions before forming any view textures is that some of the view textures may include texture patches from neighboring view directions. If several view textures are combined into one large texture e.g. several textures are combined to form a large N M texture these texture patches may be present in the combined textures and thus do not have to be packed with the current view.

In step one of the viewing directions is selected from the set of viewing direction chosen in step . This step starts the second loop of method .

In step the portions of the object that correspond to the unobstructed triangles of the object proxy are drawn to the buffer. These portions are shifted and rotated in accordance with the shift and rotation data stored in step . In an embodiment the unobstructed portions of the object drawn in step are the portions corresponding to the triangles of the object proxy having a level of obstruction value equal to 1. In embodiments the unobstructed portion drawn in step is an image of the object.

In step the portions of the object that correspond to the obstructed triangles of the object proxy are drawn to the buffer. These portions are shifted and rotated in accordance with the shift and rotation data stored in step . In an embodiment the obstructed portions of the object drawn in step are the portions corresponding to the triangles of the object proxy having a level of obstruction value greater than 1 i.e. 2 3 4 . . . N .

In embodiments the portions drawn in step are texture patches corresponding to portions of the object that are either partially or fully obstructed when the object is viewed from the selected viewing direction but that are unobstructed when the object is viewed from a neighboring view direction. This point is further described below with reference to .

In an embodiment the portions drawn in step are drawn by rendering the object and setting a clip plane to the plane of the particular object proxy polygons triangles that are being drawn and setting the initial depth value by rendering object proxy triangles having levels of obstruction N . . . L where L is the current level of obstruction into the depth buffer.

In step the portions of the object that correspond to back facing triangles of the object proxy are drawn to the buffer. These portions are shifted and rotated in accordance with the shift and rotation data stored in step . In an embodiment the portions of the object draw in step are the portions corresponding to the triangles of the object proxy having a level of obstruction value less than 1 i.e. 2 3 4 . . . N .

In an embodiment the portions drawn in step are texture patches. In an embodiment the portions drawn in step are drawn by using texture from the closest neighboring viewing direction in which the back facing triangles being drawn are front facing.

The above example OPENGL implementation is illustrative and not intended to limit the present invention.

Continuing with steps and in optional step the contents of the buffer is down sampled. This optional step filters the contents of the buffer if filtering is needed.

In step the contents of the buffer is stored in a memory thereby forming a view texture in accordance with an embodiment of the present invention. This stored pre computed view texture can be read from memory and used for example with an object proxy in accordance with method to render an object in a computer scene.

In step it is determined whether a view texture has been formed for each of the viewing directions selected in step . If a view texture has not been formed for all of the viewing directions another viewing direction is selected step and the steps through are repeated for the newly selected viewing direction. If view textures have been formed for all of the viewing directions control passes from step to optional step .

In optional step the object proxy is stored together with a set of texture coordinates for each of the viewing textures formed in steps . In an embodiment a single proxy shape and a set of texture coordinates is stored for each viewing direction selected in step . This is not the only storage arrangement that can be used in accordance with method . Other storage arrangements are also possible.

In optional step groups of viewing directions are formed. In an embodiment groups of three viewing directions are formed in step . These groups are the spherical triangle groups described herein. In another embodiment groups of four viewing directions are formed. These groups are the ring view groups described herein. Other groupings are also possible.

In optional step a modified object proxy is stored for each group of viewing directions together with a set of texture coordinates for the group of viewing directions. Thus in embodiments a single proxy shape and a set of texture coordinates is stored for each group of viewing directions formed in step . As noted herein this is not the only storage arrangement that can be used. For example in some embodiments of the invention more than one object proxy with a set of textures coordinates can be associated with a particular group of viewing direction. This is particularly the case when the invention is used to implement level of detail rendering schemes wherein the object proxy and view textures used to render an object for a given group of viewing direction are selected based on a distance criterion.

The steps described above for method are illustrative of how to form a viewing texture in accordance with the invention. As noted above several of the steps described are optional steps. These optional steps are not intended to limit the present invention.

In an embodiment the object proxy is formed according to the methods described by Mech in U.S. patent application Ser. No. 10 197 822 filed Jul. 19 2002 now U.S. Pat. No. 6 831 642 entitled Method And System For Forming An Object Proxy. In U.S. patent application Ser. No. 10 197 822 for example a method includes aiming a volume that encompasses the object forming an isosurface within the volume adjusting the isosurface relative to a surface of the object and pruning the isosurface to obtain the object proxy. Other methods can also be used to form object proxies that are used in accordance with the present invention.

As described herein many different object proxies can be formed for object . These different object proxies have varying degrees of complexity numbers of triangles. Thus the object proxy is only illustrative and not intended to limit the invention described herein.

In various views of the object i.e. images are represented in a simplified manner. These various views can be render or drawn using the object in accordance with the steps of method . Each view in represents a view from a different viewing direction in accordance with the invention.

As explained herein the four views and i.e. images of object from different viewing directions can be rendered using the object and used to form a part of one or more view textures in accordance with the invention. This feature of the invention is further described below with reference to .

As illustrated by obstruction of object proxy triangles occurs when the object proxy is not convex. When an object proxy is not convex there are viewing directions in which object proxy triangles are either partially or fully obstructed.

In an embodiment as described above with reference to the steps of method the present invention address the issue of fully or partially obstructed triangles by rendering an object such as object and setting a clip plane during rendering to a plane of the object proxy containing the fully or partially obstructed triangle being rendered. For back facing triangles the appropriate texture is either set to fully transparent or a texture from the closest view in which the back facing triangle is front facing is used. These rendering techniques of the invention make it possible to correctly render fully or partially obstructed triangles. As described below in an embodiment texture patches are rendered for fully or partially obstructed triangles and made a part of one or more view textures according to the invention.

The texture patches and represent texture patches needed to correctly render the fully or partially obstructed triangles of object proxy that form the surfaces of the tires shown in . As can be seen in the texture patches and have been packed around the view using shifts and rotations. The texture patches and have been packed around the view using shifts. The texture packing scheme shown in is only illustrative and not intended to limit the invention. As described herein any texture packing scheme can be used.

Texture patch represents a texture patch for a the ladder of object . When object is viewed from a front viewing direction the ladder of object is either partially or fully obstructed. When viewed from a front viewing direction the triangles of an object proxy forming the surface of the ladder would also be either partially or fully obstructed as illustrated by . However as the object proxy is rotated and rendered from other viewing directions the triangles forming the surface of the ladder become visible. Thus the texture patch has been added to the view texture associated with the front view of object so that view texture can be used to render the ladder of object when a viewing direction other than that represented by view is desired. Typically the texture patch will be blended with a texture patch from a neighboring view texture during render as described above with regards to method .

As described herein the invention is very flexible and further features and advantages of the present invention will become apparent to a person skilled in the relevant art given the description of the invention herein.

As shown in in one embodiment view texture former includes an object proxy texture coordinate calculator and a drawer . View texture former determines and stores level of obstruction data for each polygon in each object proxy . View texture former also determines and stores texture packing data . Any type of texture packing technique and data can be used with the present invention. In one embodiment texture packing data has shift and rotation data relative to a viewing direction which is used in a texture packing algorithm to create texture patches.

In one example object proxy texture coordinate calculator calculates texture coordinates for an object proxy based on the level of obstruction at different portions of the object proxy and based on texture packing data. Drawer draws portions of the object based on the level of obstruction data for the object proxy and based on the texture packing data to obtain a view texture at a respective viewing direction. In one example implementation drawer draws the portions of the object that correspond to unobstructed front facing portions of the object proxy with additional displacement based on corresponding texture packing data draws the portions of the object that correspond to at least partially obstructed front facing portions of the object proxy with additional displacement based on corresponding texture packing data and removal of any intervening object portions and draws the portions of the object that correspond to back facing portions of the object proxy that are visible from nearby viewing directions with additional displacement based on corresponding texture packing data and removal of intervening object portions whereby a view texture having texture patches can be obtained.

According to a further embodiment view texture former comprises control logic and or program code for carrying out each of the steps described above with respect to and renderer comprises control logic and or program code for carrying out each of the steps described above with respect to . In one example object proxy texture coordinate calculator comprises control logic and or program code for carrying out each of the steps described above with respect to . Drawer comprises control logic and or program code for carrying out each of the steps as described above with respect to . Either drawer or view texture former then can carry out each of the steps as described above with respect to . These are examples only and not intended to limited the present invention. Functionality can be distributed in alternate arrangements between processing components in as would be apparent to a person skilled in the art given this description.

In addition the present invention including each of steps described above with respect to and graphics system including its components described with respect to can be implemented in software firmware hardware or any combination thereof. Various features of the invention including each of steps described above with respect to and graphics system including its components described with respect to can be implemented in any one of the layers of architecture or in any combination of layers of architecture as described in . Various features of the invention each of steps described above with respect to and graphics system including its components described with respect to can also be implemented in system as described with respect to above or in system as described with respect to below. These are examples only and not intended to limit the present invention. Functionality can also be distributed in alternate arrangements between processing components as would be apparent to a person skilled in the art given this description.

Computer system includes one or more processors such as processor and one or more graphics subsystems such as graphics subsystem . One or more processors and one or more graphics subsystems can execute software and implement all or part of the features of the present invention described herein. Graphics subsystem can be implemented for example on a single chip as a part of processor or it can be implemented on one or more separate chips located on a graphic board. Each processor is connected to a communication infrastructure e.g. a communications bus cross bar or network . After reading this description it will become apparent to a person skilled in the relevant art how to implement the invention using other computer systems and or computer architectures.

Computer system also includes a main memory preferably random access memory RAM and can also include secondary memory . Secondary memory can include for example a hard disk drive and or a removable storage drive representing a floppy disk drive a magnetic tape drive an optical disk drive etc. The removable storage drive reads from and or writes to a removable storage unit in a well known manner. Removable storage unit represents a floppy disk magnetic tape optical disk etc. which is read by and written to by removable storage drive . As will be appreciated the removable storage unit includes a computer usable storage medium having stored therein computer software and or data.

In alternative embodiments secondary memory may include other similar means for allowing computer programs or other instructions to be loaded into computer system . Such means can include for example a removable storage unit and an interface . Examples can include a program cartridge and cartridge interface such as that found in video game devices a removable memory chip such as an EPROM or PROM and associated socket and other removable storage units and interfaces which allow software and data to be transferred from the removable storage unit to computer system .

In an embodiment computer system includes a frame buffer and a display . Frame buffer is in electrical communication with graphics subsystem . Images stored in frame buffer can be viewed using display . Many of the features of the invention described herein are performed within the graphics subsystem .

Computer system can also include a communications interface . Communications interface allows software and data to be transferred between computer system and external devices via communications path . Examples of communications interface can include a modem a network interface such as Ethernet card a communications port etc. Software and data transferred via communications interface are in the form of signals which can be electronic electromagnetic optical or other signals capable of being received by communications interface via communications path . Note that communications interface provides a means by which computer system can interface to a network such as the Internet.

Computer system can include one or more peripheral devices which are coupled to communications infrastructure by graphical user interface . Example peripheral devices which can from a part of computer system include for example a keyboard a pointing device e.g. a mouse a joy stick and a game pad. Other peripheral devices which can form a part of computer system will be known to a person skilled in the relevant art given the description herein.

The present invention can be implemented using software running that is executing in an environment similar to that described above with respect to . In this document the term computer program product is used to generally refer to removable storage unit a hard disk installed in hard disk drive or a carrier wave or other signal carrying software over a communication path wireless link or cable to communication interface . A computer useable medium can include magnetic media optical media or other recordable media or media that transmits a carrier wave. These computer program products are means for providing software to computer system .

Computer programs also called computer control logic are stored in main memory and or secondary memory . Computer programs can also be received via communications interface . Such computer programs when executed enable the computer system to perform the features of the present invention as discussed herein. In particular the computer programs when executed enable the processor to perform the features of the present invention. Accordingly such computer programs represent controllers of the computer system .

In an embodiment where the invention is implemented using software the software may be stored in a computer program product and loaded into computer system using removable storage drive hard drive or communications interface . Alternatively the computer program product may be downloaded to computer system over communications path . The control logic software when executed by the one or more processors causes the processor s to perform the functions of the invention as described herein.

In another embodiment the invention is implemented primarily in firmware and or hardware using for example hardware components such as application specific integrated circuits ASICs . Implementation of a hardware state machine so as to perform the functions described herein will be apparent to a person skilled in the relevant art.

The present invention has been described above with the aid of functional building blocks and method steps illustrating the performance of specified functions and relationships thereof. The boundaries of these functional building blocks and method steps have been arbitrarily defined herein for the convenience of the description. Alternate boundaries can be defined so long as the specified functions and relationships thereof are appropriately performed. Any such alternate boundaries are thus within the scope and spirit of the claimed invention. One skilled in the art will recognize that these functional building blocks can be implemented by discrete components application specific integrated circuits processors executing appropriate software and the like or any combination thereof.

Various embodiments of the present invention have been described above which are capable of being implemented on an interactive graphics machine. It should be understood that these embodiments have been presented by way of example only and not limitation. It will be understood by those skilled in the relevant art that various changes in form and details of the embodiments described above may be made without departing from the spirit and scope of the present invention as defined in the claims. Thus the breadth and scope of the present invention should not be limited by any of the above described exemplary embodiments but should be defined only in accordance with the following claims and their equivalents.

