---

title: Hierarchical tree AAM
abstract: An active appearance model is built by arranging the training images in its training library into a hierarchical tree with the training images at each parent node being divided into two child nodes according to similarities in characteristic features. The number of node levels is such that the number of training images associated with each leaf node is smaller than a predefined maximum. A separate AAM, one per leaf node, is constructed using each leaf node's corresponding training images. In operation, starting at the root node, a test image is compared with each parent node's two child nodes and follows a node-path of model images that most closely matches the test image. The test image is submitted to an AAM selected for being associated with the leaf node at which the test image rests. The selected AAM's output aligned image may be resubmitted to the hierarchical tree if sufficient alignment is not achieved.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08306257&OS=08306257&RS=08306257
owner: Seiko Epson Corporation
number: 08306257
owner_city: Tokyo
owner_country: JP
publication_date: 20110131
---
The present invention relates to an active appearance model AAM machine and method. More specifically it relates to an AAM approach whose training phase creates multiple smaller AAMs capable of aligning an input test image more quickly through uses of multiple small AAM as opposed to a single large AAM and is further able to align a larger range of input test images than typical by providing better support for outlier true examples of a class of object.

In the field of computer vision it is generally desirable that an image not only be captured but that a computer be able to identify and label various features within the captured image. Basically a goal of computer vision is for the computer to understand the content of a captured image.

Various approaches to identifying features within a captured image are known. Early approaches centered on the concept of identifying shapes. For example if a goal was to identify a specific item such as wrench or a type of wrench then a library of the different types of acceptable wrenches i.e. true examples defined as images of true wrenches would be created. The outline shapes of the wrenches within these true examples would be stored and a search for the acceptable shapes would be conducted on a captured image. This approach of shape searching was successful when one had an exhaustive library of acceptable shapes the library was not overly large and the subject of the captured images did not deviate from the predefined true shapes.

For complex searches however this approach is not effective. The limitations of this approach become readily apparent when the subject being sought within an image is not static but is prone to change. For example a human face has definite characteristics but does not have an easily definable number of shapes and or appearances it may adopt. It is to be understood that the term appearance is herein used to refer to color and or light differences across an object as well as other surface texture variances. The difficulties in understanding a human face becomes even more acute when one considers that it is prone to shape distortion and or change in appearance within the normal course of human life due to changes in emotion expression speech age etc. It is self apparent that compiling an exhaustive library of human faces and their many variations is a practical impossibility.

Recent developments in image recognition of objects that change their shape and appearance such as a human face are discussed in Statistical Models of Appearance for Computer Vision by T. F. Cootes and C. J. Taylor hereinafter Cootes et al. Imaging Science and Biomedical Engineering University of Manchester Manchester M13 9PT U.K. email t.cootes man.ac.uk http www.isbe.man.ac.uk Mar. 8 2004 which is hereby incorporated in its entirety by reference.

Cootes et al. explain that in order for a machine to be able to understand what it sees it must make use of models that describe and label the expected structure being imaged. In the past model based vision has been applied successfully to images of man made objects but their use has proven more difficult in interpreting images of natural subjects which tend to be complex and variable. The main problem is the variability of the subject being examined. To be useful a model needs to be specific that is it should represent only true examples of the modeled subject. To identify a variable object however the model needs to be general and represent any plausible true example of the class of object it represents.

Recent developments have shown that this apparent contradiction can be handled by statistical models that can capture specific patterns of variability in shape and appearance. It has further been shown that these statistical models can be used directly in image interpretation.

To facilitate the application of statically models subjects to be interpreted are typically separated into classes. This permits the statistical analysis to use prior knowledge of the characteristics of a particular class to facilitate its identification and labeling and even to overcome confusion caused by structural complexity noise or missing data.

Additionally in order to facilitate further processing of identified and labeled subjects within a captured image it is beneficial for the identified subject to be transformed into i.e. be fitted onto a model or canonical shape of the class of object being sought. Preferably this model or canonical shape would be of predefined shape and size and have an inventory of labels identifying characteristic features at predefined locations within the predefined shape. For example although the human face can vary widely it can be conformed to a standard shape and size. Once conformed to the standard shape and size the transformed face can then be further processed to determine its expression its gaze direction the individual to whom the face belongs etc.

A method that uses this type of alignment is the active shape model. With reference to the active shape model uses a predefined model face A and a list of predefined deformation parameters each having corresponding deformation constraints to permit the model face to be stretched and move to attempt to align it with a subject image . Equivalently the list of predefined deformation parameters may be applied to subject image and have it be moved and deformed to attempt to align it with model face A. This alternate approach has the added benefit that as subject image is being aligned with model face A it is simultaneously being fitted to the shape and size of model face A. Thus once alignment is complete the fitted image is already in a preferred state for further processing.

For illustrative purposes shows model face A being fitted to subject face . The example of is an exaggerated case for illustration purposes. It is to be understood that a typical model face A would have constraints regarding its permissible deformation points relative to other points within itself. For example if aligning the model face meant moving its left eye up one inch and moving its right eye down one inch then the resultant aligned image would likely not be a human face and thus such a deformation would typically not be permissible.

In the example of model face A is first placed roughly within the proximity of predefined points of interest and typically placed near the center of subject face as is illustrated in image . By comparing the amount of misalignment resulting from moving model face A in one direction or another and the results of adjusting a size multiplier in any of several predefined directions one can determine how to better align model face A as illustrated in image . An objective would be to align as closely as possible predefined landmarks such as the pupils nostril mouth corners etc. as illustrated in image . Eventually after a sufficient number of such landmark points have been aligned the subject image is warped onto model image A resulting in a fitted image of predefined shape and size with identified and labeled points of interest such as outlines of eye features nose features mouth features cheek structure etc. that can be further processed to achieve specific objectives.

This approach however does not take into account changes in appearance such as for example changes in shadow color or texture. A more holistic or global approach that jointly considers the object s shape and appearance is the Active Appearance Model AAM . Although Cootes et al. appear to focus primarily on the gray level or shade feature of appearance they do describe a basic principle that AAM searches for the best alignment of a model face including both model shape parameters and model appearance parameters onto a subject face while simultaneously minimizing misalignments in shape and appearance. In other words AAM applies knowledge of the expected shapes of structures their spatial relationships and their gray level appearance or more generally color value appearance such as RGB values to restrict an automated system to plausible interpretations. Ideally AAM is able to generate realistic images of sought objects. An example would be a model face capable of generating convincing images of any individual such as by changing the individual s expression. AAM achieves this by formulating interpretation as a matching problem given an image to interpret structures are located and labeled by adjusting the model s parameters in such a way that it generates an imagined image that is as similar as possible to a plausible variation.

Although AAM is a useful approach implementation of AAM still poses several challenges. For instance as long as the AAM machine manages to find a fit within its defined parameters it will assume that the fitted image is a match i.e. a true example of a plausible variation . However there is no guarantee that the fitted image is in fact a true example.

In other words even if an AAM machine appears to have aligned a subject input image with a model image the resulting aligned image may not be a true representation of the class of object being sought. For example if the initial position of the model image is too far misaligned from the subject input image the model image may be aligned incorrectly on the subject input image. This would result in a distorted untrue representation of the warped output image.

Other limitations of an AAM machine relate to the computing complexity required to apply statistical analysis to a training library of true samples in order to define distinguishing parameters and define the parameter s permissible distortions. By the nature of the applied statistical analysis the results will permit alignment only with a fraction of the images within the training library. If the class of object being sought is prone to wide variation it may not be possible to properly align a shape model image or an appearance model image to an input subject image that has characteristics beyond a norm defined by the statistical analysis. This is true of even images within the training library from which the shape model image and appearance model image are constructed. Typically the constructed model image will be capable of being aligned to only 90 to 95 of the sample images within a training library.

It is an object of the present invention to provide an AAM with faster alignment process particularly when training using an extended large library of true sample images.

It is another object of the present invention to provide an AAM better able to align a larger number of true samples of a specific class of object including true outlier samples.

These objects are achieved in an object recognition device for recognizing a class of object in an input test image the device comprising an input for receiving the input test image a plurality of active appearance model processing blocks AAMs each of the plurality of AAMs having been trained with a distinct group of independent digital training images each training image in all groups of training images having a true example of the class of object with a common predefined set of characteristic features of the class of object identified and labeled each group of training images being made distinct by sharing specific traits in select characteristic features distinct from the specific traits in other groups of training images each of the plurality of AAMs having a corresponding model image and a corresponding statistical model fitting function reflecting the specific traits of the group of training images from which it is trained a data processing module for implementing the following data processing steps a defining the input test image as a current image b applying the current image to a selected AAM selected from among the plurality of AAMs the selected AAM having a corresponding model image that most closely matches the current image as compared to the model images corresponding to the not selected AAMs the selected AAM processing the current image to produce an intermediate aligned image c IF a misalignment measure of the intermediate aligned image and a predefined model image is greater than a predefined maximum measure THEN defining the intermediate aligned image as the current image and returning to step b ELSE outputting the intermediate aligned image as a successful recognition of the class of object.

In this device in step c within the IF statement the predefined model image is the selected AAM s corresponding model image. Alternatively wherein in step c within the IF statement the predefined model image is a model image created from a combination of all the groups of training images used to train all of the plurality of AAMs. Further alternatively within in step c the IF statement further includes AND IF step b has been executed less than a fixed maximum cycle count.

Additionally in step c the IF statement further includes AND IF the misalignment measure is smaller than the misalignment measure obtained in an immediately previous application of step b .

Also in step b the selected AAM has a statistical model fitting function whose reflected specific traits most closely match the same traits on the current image. Preferably in step b a misalignment measure of the current image and the model image corresponding to the selected AAM is smaller than a misalignment measure of the current image and the model images corresponding to all other of the plurality of AAMs.

The above described recognition device wherein A the plurality of AAMs are accessible through a hierarchical tree path with a separate one of the plurality of AAMs being associated with a corresponding separate leaf node of the hierarchical tree in a one to one relationship the hierarchical tree having 1 a root node associated with an extended library of training images comprised of all of the independent training images used in the training of all of the plurality of AAMs 2 a plurality of hierarchical levels downward from the root node to each of the leaf nodes each leaf node being the terminal node i.e. bottom most node in a link path from the root node to each leaf node and with each inner node along each link path from the root node to each leaf node being a parent node having a left child node and a right child node 3 the extended library being divided progressively into a plurality of smaller groups of training images as one progresses downward from the root node to each leaf node and each group of training images associated with a leaf node being the distinct group of independent training images used in the training of the leaf node s associated AAM 4 at each progressive depth level change from a parent node to its left child node and right child node the parent node s associated group of training images being divided into a two smaller groups one per left and right child node according to similarities in characteristic features of the training images each smaller group being associated with its corresponding child node 5 each child node having a corresponding node model image created from the training images associated with it and B the selecting of an AAM from among the plurality of AAMs in step b includes i defining the root node as a current node ii IF the current image more closely matches the node model image associated with the current node s left child node than its right child node THEN redefining the current node as the left child node ELSE redefining the current node as the right child node iii IF the current node is a leaf node THEN selecting the AAM associated with the current node to receive the current image ELSE returning to step ii .

Additionally the training of the plurality of AAMs includes the following steps i accessing an extended training library comprised of all of the independent training images in all of the distinct groups of training images ii arranging all training images in the extended training library into a hierarchical tree structure according to a measure of similarity of predefined specific characteristic feature s of the training images the hierarchical tree structure having a root node i.e. topmost node a plurality of inner nodes and a plurality of leaf nodes i.e. terminal nodes the inner nodes defining link paths from the root node to each leaf node the number of leaf nodes being selected so that the number of training images at each leaf node is not greater than a predefined maximum number iii creating a separate AAM for each leaf node using only the training images associated with each respective leaf node the collection of thus created AAMs being the plurality of active appearance model processing blocks AAMs.

In this approach step ii preferably includes I defining the root node and associating with it the entirety of extended training library II 

defining the root node as a current node III defining the a memory pointer current node depth as the node depth of the root node IV applying a processing sequence to the current node to created child nodes if necessary V IF all nodes at the current node depth have not been processed THEN redefining current node as a next node not yet processed at current node depth and returning to step IV VI IF there are any other nodes at a depth level below the current node depth THEN incrementing current node depth to the next lower depth level redefining current node as a next node not yet processed at current node depth and returning to step IV .

Additionally in IV the processing sequence includes IF the number of training images associated with the current node is not greater than a max image count THEN creating an AAM using only the training images associated with the current node and defining the current node as a leaf node and associating the created AAM with the current node ELSE creating a model image using only the training images associated with the current node sub dividing the current node s associated training images into first and second groups of training images according to similarities in characteristic features of its associated training images creating a first child node under and linked to the current node and associating the first group of training images with the first child node creating a second child node under and linked to the current node and associating the second group of training images with the second child node.

The above objects are also met in a method of implementing object recognition to recognize a class of object in an input test image the method comprising receiving the input test image providing a plurality of active appearance model processing blocks AAMs each of the plurality of AAMs having been trained with a distinct group of independent training images each training image in all groups of training images having a true example of the class of object with a common predefined set of characteristic features of the class of object identified and labeled each group of training images being made distinct by sharing specific traits in select characteristic features distinct from the specific traits in other groups of training images each of the plurality of AAMs having a corresponding model image and a corresponding statistical model fitting function reflecting the specific traits of the group of training images from which it is trained implementing the following data processing steps a defining the input test image as a current image b applying the current image to a selected AAM selected from among the plurality of AAMs the selected AAM having a corresponding model image that most closely matches the current image as compared to the model images corresponding to the not selected AAMs the selected AAM processing the current image to produce an intermediate aligned image c IF a misalignment measure of the intermediate aligned image and a predefined model image is greater than a predefined maximum measure THEN defining the intermediate aligned image as the current image and returning to step b ELSE outputting the intermediate aligned image as a successful recognition of the class of object.

In this approach in step c within the IF statement the predefined model image is the selected AAM s corresponding model image. Alternatively in step c within the IF statement the predefined model image is a model image created from a combination of all the groups of training images used to train all of the plurality of AAMs. Still alternatively in step c the IF statement further includes AND IF step b has been executed less than a fixed maximum cycle count. Preferably in step c the IF statement further includes AND IF the misalignment measure is smaller than the misalignment measure obtained in an immediately previous application of step b .

Also in step b the selected AAM has a statistical model fitting function whose reflected specific traits most closely match the same traits on the current image. In step b a misalignment measure of the current image and the model image corresponding to the selected AAM is smaller than a misalignment measure of the current image and the model images corresponding to all other of the plurality of AAMs.

In this approach it is preferred that A the plurality of AAMs are accessible through a hierarchical tree path with a separate one of the plurality of AAMs being associated with a corresponding separate leaf node of the hierarchical tree in a one to one relationship the hierarchical tree having 1 a root node associated with an extended library of training images comprised of all of the independent training images used in the training of all of the plurality of AAMs 2 a plurality of hierarchical levels downward from the root node to each of the leaf nodes each leaf node being the terminal node i.e. bottom most node in a link path from the root node to each leaf node and with each inner node along each link path from the root node to each leaf node being a parent node having a left child node and a right child node 3 the extended library being divided progressively into a plurality of smaller groups of training images as one progresses downward from the root node to each leaf node and each group of training images associated with a leaf node being the distinct group of independent training images used in the training of the leaf node s associated AAM 4 at each progressive depth level change from a parent node to its left child node and right child node the parent node s associated group of training images being divided into a two smaller groups one per left and right child node according to similarities in characteristic features of the training images each smaller group being associated with its corresponding child node 5 each child node having a corresponding node model image created from the training images associated with it and B the selecting of an AAM from among the plurality of AAMs in step b includes i defining the root node as a current node ii IF the current image more closely matches the node model image associated with the current node s left child node than its right child node THEN redefining the current node as the left child node ELSE redefining the current node as the right child node iii IF the current node is a leaf node THEN selecting the AAM associated with the current node to receive the current image ELSE returning to step ii .

In a preferred embodiment the training of the plurality of AAMs includes the following steps i accessing an extended training library comprised of all of the independent training images in all of the distinct groups of training images ii arranging all training images in the extended training library into a hierarchical tree structure according to a measure of similarity of predefined specific characteristic feature s of the training images the hierarchical tree structure having a root node i.e. topmost node a plurality of inner nodes and a plurality of leaf nodes i.e. terminal nodes the inner nodes defining link paths from the root node to each leaf node the number of leaf nodes being selected so that the number of training images at each leaf node is not greater than a predefined maximum number iii creating a separate AAM for each leaf node using only the training images associated with each respective leaf node the collection of thus created AAMs being the plurality of active appearance model processing blocks AAMs.

Preferably step ii includes I defining the root node and associating with it the entirety of extended training library II defining the root node as a current node III defining the a memory pointer current node depth as the node depth of the root node IV applying a processing sequence to the current node to created child nodes if necessary V IF all nodes at the current node depth have not been processed THEN redefining current node as a next node not yet processed at current node depth and returning to step IV VI IF there are any other nodes at a depth level below the current node depth THEN incrementing current node depth to the next lower depth level redefining current node as a next node not yet processed at current node depth and returning to step IV .

Further preferably in step IV the processing sequence includes IF the number of training images associated with the current node is not greater than a max image count THEN creating an AAM using only the training images associated with the current node and defining the current node as a leaf node and associating the created AAM with the current node ELSE creating a model image using only the training images associated with the current node sub dividing the current node s associated training images into first and second groups of training images according to similarities in characteristic features of its associated training images creating a first child node under and linked to the current node and associating the first group of training images with the first child node creating a second child node under and linked to the current node and associating the second group of training images with the second child node.

The above objects are also met in a method of implementing an active appearance model for recognition of a class of object in an input test image the method comprising i accessing an extended training library comprised of a plurality of independent training images each training image having a true example of the class of object with a common predefined set of characteristic features of the class of object identified and labeled ii arranging all training images in the extended training library into a hierarchical tree structure according to similarities in predefined specific characteristic feature s of the training images the hierarchical tree structure having a root node i.e. topmost node a plurality of inner nodes and a plurality of leaf nodes i.e. terminal nodes the inner nodes defining link paths from the root node to each leaf node with each inner node along each link path from the root node to each leaf node being a parent node having a left child node and a right child node at each progressive depth level change within the hierarchical tree from a parent node to its left child node and right child node the parent node s associated group of training images being divided into a two smaller groups one per left and right child node according to similarities in characteristic features of the training images each smaller group of training images being associated with its corresponding child node each child node having a corresponding node model image created from its associated training images the number of leaf nodes being selected so that the number of training images at each leaf node is not greater than a predefined maximum number the training images at each leaf node sharing specific traits in select characteristic features distinct from the specific traits in the training images at other leaf nodes iii creating a plurality of active appearance model AAM blocks one per each leaf node using only the training images associated with each respective leaf node each of the plurality of AAM blocks having a corresponding model image and a corresponding statistical model fitting function reflecting the specific traits of the training images from which it is trained iv implementing the following data processing steps a defining the input test image as a current image b applying the current image to a selected AAM block selected from among the plurality of AAM blocks the selected AAM block having a corresponding model image that most closely matches the current image as compared to the model images corresponding to the not selected AAM blocks the selected AAM block processing the current image to produce an intermediate aligned image c IF a misalignment measure of the intermediate aligned image and a predefined model image is greater than a predefined maximum measure THEN defining the intermediate aligned image as the current image and returning to step b ELSE outputting the intermediate aligned image as a successful recognition of the class of object.

Using this method step ii may include I defining the root node and associating with it the entirety of extended training library II defining the root node as a current node III defining the a memory pointer current node depth as the node depth of the root node IV applying a processing sequence to the current node to created child nodes if necessary V IF all nodes at the current node depth have not been processed THEN redefining current node as a next node not yet processed at current node depth and returning to step IV VI IF there are any other nodes at a depth level below the current node depth THEN incrementing current node depth to the next lower depth level redefining current node as a next node not yet processed at current node depth and returning to step IV .

Preferably in IV the processing sequence includes IF the number of training images associated with the current node is not greater than a max image count THEN defining the current node as a leaf ELSE creating a model image using only the training images associated with the current node sub dividing the current node s associated training images into first and second groups of training images according to similarities in characteristic features of its associated training images creating a first child node under and linked to the current node and associating the first group of training images with the first child node creating a second child node under and linked to the current node and associating the second group of training images with the second child node.

In this method preferably in step c within the IF statement the predefined model image is the selected AAM block s corresponding model image. Alternatively in step c within the IF statement the predefined model image is a model image created from a combination of all the groups of training images used to train all of the plurality of AAM blocks. Further alternatively in step c the IF statement further includes AND IF step b has been executed less than a fixed maximum cycle count.

Also in this method in processing step b the selected AAM block is selected according to the following sub step i defining the root node as a current node ii IF the current image more closely matches the node model image associated with the current node s left child node than its right child node THEN redefining the current node as the left child node ELSE redefining the current node as the right child node iii IF the current node is a leaf node THEN selecting the AAM block associated with the current node to receive the current image ELSE returning to sub step ii .

Other objects and attainments together with a fuller understanding of the invention will become apparent and appreciated by referring to the following description and claims taken in conjunction with the accompanying drawings.

With reference to before an Active Appearance Model machine AAM may be used it must first be trained to recognize a specific class of objects. For illustrative purposes the following discussion will assume that AAM is designed to recognize specific features of a human face but it is to be understood that the present invention may be applied to any class of object.

A model face may be constructed from a training library of individual training images   to i.e. true examples of valid faces . Typically an individual manually places landmark points on each sample face in each training image to outline specific features characteristic to the class of object being represented. The landmark points are ideally selected in such a way that the landmark points outline distinguishable features within the class of object common to every training image.

For instance a common feature within a human face class may be the eyes. When building a model of the appearance of a human eye in a face training image landmark points may be placed at the corners of the eyes since these features would be easy to identify in each training image. In addition to the landmark points however AAM also makes use of appearance data i.e. shade data and or color data and or texture data etc. at various patches or regions of each training image to create a distribution range of acceptable appearances for corresponding patches within model face . This appearance data constitutes additional features in the overall statistical analysis.

As stated above Active appearance model machine AAM undergoes a training phase before it can be used in an operation phase. In the training phase AAM creates a model image and statistical model of the class of object it is intended to recognize i.e. a human face in the present example . In the operation phase AAM uses the model image and statistical model to search for its specific class of object within an input test image not shown in .

In this training phase AAM would have access to a training library of training images   to each of which has an example of the class of object AAM is intended to learn to recognize. Since in the present example it is assumed that AAM is being trained to identify a human face class training library consists of a plurality of true face training images   to each having landmark points outlining characteristic features of a human face subjects. Preferably training images   to are independent of each other i.e. are not a sequential video capture of a single human subject but rather are examples of different human subjects and or having different expressions and or appearances etc. . Library may be housed in a memory store internal and or external to AAM .

It is to be understood that AAM machine may be embodied by a computing device and or data processing device. As it is generally known in the art such computing devices and data processing devices may include one or more central processing units arithmetic units registers clocks memories input output interfaces GPU s ASICs PLA s FPLAs buses bus interfaces network connections controllers input output devices displays etc.

AAM includes a learn module and an align module . In the training phase learn module goes through training library and uses statistical analysis to create model face by combining information from the training images within training library . Preferably learn module also defines deformation parameters i.e. variable feature parameters with defined constraints for a statistical model fitting function defining shape and appearance features of model face . Preferably the deformation parameters are such that they permit the shape and appearance of model face to be warped enough to be aligned with a large percentage of the training images within training library .

In the operation phase align module optimizes the model fitting function to attempt to fit i.e. warp or align model face to a possible representation of a human face within an input test image not shown and outputs the aligned i.e. fitted face .

Align module may also be used during the training phase to test the results from learn module . In the training face align module may be used to attempt to warp model face onto all the training images within library or equivalently warp the training images onto model face . This would provide a measure of the effectiveness of the model parameters produced by learn module . Typically align module may successfully align model face to only 90 to 95 of the training images within library .

Since in the operation phase align module may adjust model face to align it with an input test image of a human face the resultant aligned face is effectively a representation of the input test image having been warped or fitted onto model face . Additionally since the input test image is fitted onto model face the resultant aligned face will have the same known size and shape as model face and have its various characteristic shape features i.e. eyes pupils nose mouth outline chine eyebrow etc. and appearance features identified labeled and mapped i.e. their locations identified . Aligned face is thus in an ideal state for further processing if desired.

In the training phase as is stated above learn module defines the deformation parameters for a statistical model used to fit or align model face to an input test image. An initial step in this process is typically to align the many training images   to within training library to establish a range of variation among the characteristic features of the training images. This process typically makes use of the sum of square distances. In other words an L norm approach is typically used to align the many training images within training library during the training phase. This may be roughly thought of as an averaging of the training images within training library . The sum of square distances has the advantage of centering the training images so that variations in regions of interest are more equally spaced. An illustrative example of this L norm approach is illustrated in using oval shapes .

With reference to five oval shapes are shown for illustrative purposes. Using an L norm approach for shape alignment such as the Procrustes analysis known in the art effectively centers the ovals into a first cluster . An average shape may then be defined. Double headed arrows illustrate the variations of the different oval shapes from the average shape .

For comparison purposes shows the same oval shapes but this time oval shapes are aligned using an L norm approach. The L norm approach attempts to align oval shapes along a common edge. As a result a second cluster with a commonly aligned edge is created. An average shape defined using second cluster is therefore less likely to have shape similar to those of the training shapes i.e. oval shapes . Furthermore as is illustrated by the double headed arrows within the extremes in variation are likely to be far more pronounced than the approach of and may range from a very small variation to a very large variation. Consequently the art generally teaches against the use of an L norm approach in favor of an L norm approach.

Although not shown it is to be understood that the averaging of appearance variations among the training images within training library may be similarly accomplished by Procrustes analysis.

With reference to where all elements similar to have similar reference characters and are described above the structure of a general AAM in the operation phase may exclude training library . This is because the relevant image information from training library would have been captured by the statistical model and model parameters defined by learn module in the training phase.

In operation i.e. in the operation phase a new input image i.e. input test image that is to be submitted to AAM may optionally be preprocessed prior to submission to AAM . This preprocessing may include an initial determination of whether an object of the type i.e. class of object AAM is trained to recognize i.e. a human face in the present example is indeed present within input test image . This may be achieved with face detection algorithms as is generally known in the art. This process may also add at least a few landmark points at some of the more easily identifiable characteristic facial features within input test image to create a preprocessed image . Alignment module would receive preprocessed image or alternatively receive input test image directly and optimize the model fitting function to attempt to align i.e. warp or fit model face to preprocessed image and output an aligned i.e. fitted face . That is alignment module searches for the best alignment of model face including both shape and appearance parameters its input image i.e. input test image or preprocessed image by simultaneously minimizing misalignments in shape and appearance.

An example of this type of alignment is illustrated in . A preprocessed image is shown with various landmark points highlighting various characteristic features of a human face. For illustration purposes image illustrates the landmark points alone. The results of aligning a model face not shown to preprocess image is output fitted face . Note that both shape and appearance features are aligned or fitted in output fitted face .

As an additional example four image pairs illustrating various stages in an alignment process of a model face onto an input test image are illustrated in . Within each image pair the left image illustrates the model face shape alignment highlighted by landmark points and the right image illustrates both the shape and appearance alignment of the model face onto the input image. Image pair illustrates an initial position of the model face on the input image. Image pair illustrates the result of an unconstrained AAM search. Image pair shows the results of having the right eye center constrained and image pair shows the results of having the right eye center and left eyebrow fixed. As the error is minimized the model face is better aligned to the input test image as is illustrated by image pair .

A detailed explanation of the statistical optimization within the alignment process is beyond the scope of the present paper but a quick overview is presented herein for reference purposes. The alignment process is an iterative process with small improvements in optimization obtained it each iteration. Typically the iterative process ends when no further improvement or no improvement greater than a predefined minimum threshold can be achieved. Typically alignment module would use an L norm approach for alignment.

If a shape is described by n points in d dimensions then the shape may be represented by an nd element vector formed by concatenating the elements of the individual point position vectors. For instance in a 2 dimensional 2 D image one can represent the n landmark points x y for a single example as a 2n element vector x where x x . . . x y . . . y . Given i training images one would generate i such vectors. The sample images are then aligned as described above. To simplify the problem the dimensionality of the data is preferably reduced from nd to something more manageable. Typically this is achieved by applying Principal Component Analysis PCA to the data. The data form a cloud of points in the nd dimensional space. PCA computes the main axes of this cloud allowing one to approximate any of the original points using a model with fewer than nd parameters. The result is a linear model of the shape variation of the object samples.

To create a complete image of an object or structure both its shape and its appearance i.e. the pattern of light intensity and or color variation across the region of the object need to be modeled. To build a statistical model of the appearance over an image patch each training image is warped so that its control points match the mean shape i.e. model face . This may be done using triangulation as it is known in the art. The intensity information is then sampled from a shape normalized image over the region covered by the mean shape to form an appearance vector.

For example in Sand Amay define the shape and appearance of a model face . Through PCA one may obtain S a measure of shape variation and T a measure of appearance variation. A misalignment in shape S may thus be defined as S S S. Since PCA S produces an array of eigenvalues this may be described as P where P is an eigenvector and is the projection coefficients. Using this notation S S . Similarly a misalignment in appearance T may be defined as T T A. Again PCA T produces an array of eigenvalues which may be described as A where A is an eigenvector and is the projection coefficients. Using this notation T A A .

As stated above to align a model face one typically uses an L norm approach. This is may be termed an L AAM. Applicants have found however that a more robust alignment is achievable using an L norm approach which is herein termed an L AAM.

The objective is to use Lminimization to compute an AAM parameter update during each iteration. This is achieved by re expressing the Lobjective as an Lminimization problem. Each iteration updates a shape parameter p and an appearance parameter . A benefit of using an L norm minimization approach is that the optimal solution will result in a sparse error vector E A I where A is the appearance base i.e. current iteration of the model face and I is the input image to be aligned i.e. input test image or preprocessed input test image warped to the shape normalized model as it is known in the art.

A basic difference between the two approaches is that the L norm is robust to Gaussian noise whereas the L norm is robust to outlier noise. That is the L norm can handle occlusions and extraneous artifacts better. The Appearance bases A in the L norm formulation should ideally be computed by L decomposition of training data.

To reiterate some of the benefits of the present L AAM machine the solution to the L AAM minimizer finds a sparser solution than the L norm. Consequently the solution x to

A visual illustration of these advantages is shown in . shows that L norm is robust to occlusions and naturally handles outliers. shows that L norm can further handle smaller model sizes or sub sampled model pixels and thus achieve faster alignment. illustrates that in an L AAM similar objects are represented very well by the appearance bases.

As is explained above in reference to the active appearance model produces an aligned face . However it is not guaranteed that the produced align face will be a true representation of a plausible face i.e. a realistic example of a true face . Various circumstances such as a poor starting position of the model face during the alignment process may result in poor alignment and outputting an untrue face as a true aligned face. Examples of poorly aligned model faces are shown in . In both examples of the model face is aligned to half of the input test image resulting in a distorted untrue face as indicated by the light face outline.

In order to avoid outputting an untrue aligned face it is presently proposed that a standard AAM machine be modified to incorporate a canonical face classifier to verify the validity of an aligned face produced by align unit before the produced aligned face is sent to the AAM machine s output. It is to be understood that a canonical face classifier is proposed because the class of object that the AAM of the present example is trained to recognize is a human face class. However in general when an AAM machine is trained to processes an image of any particular class of object the classifier would be a canonical class classifier trained to determining if the aligned image produced by the align module is a true representation of the particular class of object.

With reference to where all elements similar to those of have similar reference characters and are explained above the present AAM incorporates a canonical face classifier which receives the aligned face output from align module and classifies it as a true face or an untrue face. If canonical face classifier classifies aligned face as a true face then the alignment is deemed a success and aligned face is output as output image from AAM . If canonical face classifier classifies aligned face as an untrue face then the alignment is deemed a failure and the AAM alignment is stopped or re initialized i.e. the next input image is acquired. For example if the present AAM is in a system that tracks the movement of a face and AAM fails to accurately align an initially captured image from a human subject then the re initialization of AAM would include capturing a new image of the human subject and re attempting the alignment process.

As it is known in the art a classifier such as canonical face classifier is trained by means of a library having a plurality of true samples i.e. samples of true faces in the present example and a plurality of untrue samples i.e. samples of untrue faces . Ideally after reviewing the true and untrue samples of library canonical face classifier would identify characteristics by which it may distinguish true faces from untrue faces.

In a preferred embodiment the training images within training library see are used in the construction of library . That is the true samples would be comprised of or at least partially include training images   to from training library and the untrue samples would be constructed by introducing distortions into the training images of training library . A benefit of this approach is that the characteristic features within training images   to have previously been manually identified and demarcated see so that during the training of canonical face classifier it is more likely or even assured that canonical face classifier will focus on the identified characteristic features of the particular class of object.

Further preferably AAM is used in the construction of library . In this case AAM is used to construct an aligned face of each training image within library or at least of those to which the model face is successfully aligned . This would result in library being a library of fitted faces i.e. a library of previously aligned faces . Further preferably true samples are comprised of true fitted faces and untrue samples are comprised of true fitted faces that have been distorted but which maintain the same size and perimeter outline as fitted faces. This would further facilitate the training of canonical classifier since all the image within the library of fitted faces both true samples and untrue samples would have the same size and perimeter outline as model face and as aligned face produced by align module .

Since in normal operation canonical face classifier examines aligned face output from align module having trained canonical classifier on a library of fitted faces having the same size and perimeter outline as aligned face further improves the success rate of canonical face classifier . That is the rate at which canonical classifier correctly classifies aligned face as a true face or as an untrue face is improved over training canonical face classifier with a library of unfitted faces.

It is to be understood however that any library of suitable training images not necessarily from training library may be used to train canonical face classifier . Nonetheless it is preferred that the training images   to be submitted to AAM to create library of fitted faces . After the created fitted faces have been manually approved as true faces to construct a positive training set of true faces samples of untrue faces are constructed by introducing distortions into the true faces to construct a negative training set of untrue faces. The two training sets and are combined to create the library of fitted faces which is used to train canonical face classifier .

With reference to library of fitted faces includes positive training set of true face samples preferably constructed from ground truth perfectly labeled sample faces and includes a negative training set of untrue face samples preferably generated by randomly perturbing shape parameters of positive face samples. Further preferably the perturbations are relative to shape model eigenvalues. Additional untrue samples for negative training set may be created by applying pre defined translation scale and rotation offsets to the positive face samples .

It is presently preferred that more negative samples than positive samples be used in the construction of canonical classifier . Specifically a 10 1 ratio of negative to positive training samples is preferred.

With reference to where all elements similar to have similar reference characters and are described above it is presently preferred that a processing stage use Haar features and or adaboosting as is known in the art to train canonical face classifier . Alternatively a support vector machine SVM or linear discriminant analysis LDA may also be used to create canonical face classifier as it is known in the art. It is to be understood that the specific method of training canonical classifier is not critical to the invention and any technique known in the art of classifier technology and classifier training may be used to train canonical face classifier .

It is noted that since aligned face which is output from align module has a pre defined shape and size and this facilitates the classification process. That is the model face i.e. canonical image pre defines the face search size. This improves efficiency since canonical face classifier only needs to consider one scale of the image.

In an alternate embodiment integral image and cascaded weak classifiers may be used to improve efficiency. This approach may make use of the Viola and Jones face detector known in the art.

Thus by integrating canonical face classifier in an AAM one can achieve a higher reliability than is possible using the typical AAM alignment error techniques.

The above described L AAM provides for a more robust alignment and the integration of a canonical face classifier into a general AAM architecture reduces the probability of the AAM producing false positive outputs i.e. reduces the possibility that the AAM will produce non true examples of a class of object .

Another deficiency of a general AAM as is described above is that by the nature of the statistical model fitting function used in an AAM only input images whose subjects lie within a norm of shape and texture defined by the statistical model fitting function may be aligned to the model image.

For example in the above described face fitting implementations learn model creates model face by generally averaging out all the training images within training library see and defines a statistical model fitting function designed to fit a majority of possible variations which define a norm. Samples outside this norm would be rejected. There will however always be outliers i.e. true examples outside the norm that the statistical model fitting function will not be able to fit. For instance it is explained above that the defined statistical model fitting function will typically be able to fit only 90 to 95 of the training images within the training library from which the statistical model fitting function is defined.

This problem becomes even more acute as the number of training images is expanded. Training library typically consists of less than a couple of hundred training images. If training library were expanded to comprise thousands or millions of training images in an effort to create an AAM capable of recognizing a greater number of true variations the resultant AAM s statistical model fitting function would be able to fit an even smaller percentage of the training images within the expanded training library . This is because the expanded training library would likely include a larger number of outliers i.e. a larger sample of extreme true examples that the statistical model fitting function would be unable to fit. Thus rather than creating a more reliable AAM the result would technically be a less reliable AAM in terms of the percentage of training images within its expanded training library that it would be able to fit.

The following describes an AAM architecture able to handle and successfully learn from an expanded training library preferably consisting of greater than 1000 independent training images i.e. images not obtained from a video sequence and truly not limited by the size of the expanded training library . The following architecture is further able to improve the percentage of images within expanded training library that the AAM can successfully fit to any given minimum percentage up to 100 if desired.

Before describing the presently preferred AAM architecture it is beneficial to first describe a new method of training the preferred AAM. The present method creates a series of statistical model fitting functions each of which is based on a fraction of the training images within an expanded library of training images. Although each statistical model fitting function may be constructed in turn using the same AAM i.e. using the same learn and align modules and for the sake of clarity illustrates an embodiment with series of AAMs   to  . It is to be understood that any number of AAMs may be used in the present invention and that four AAMs are shown purely for illustrative purposes. Each of AAMs   to   will produce a respective distinct model face and corresponding statistical model fitting function which are herein labeled Model though Model corresponding to AAMs   to  .

The entire initial extended library of training images which is preferably comprised of thousands of sample true images is gathered into a first set of training images identified as SET   . Learn Module   within first AAM   accesses SET   to create a first model face and first statistical model fitting function i.e. Model . This first model face and first statistical model fitting function constitute a first statistical fitting pair. Align Module   within AAM   then attempts to fit each and every sample image within SET using the first statistical fitting pair. That is Align Module   attempts to fit and every sample image within SET to the first model face using the first statistical model fitting function. Each sample image that Align Module   fails to fit is output to a second set of images SET . But each fitted image is output as output aligned image .

In the present embodiment however since the current AAM is comprised of a plurality of sub AAMs   to   and all share the same output their respective outputs may go through a multiplexer that selects the output from only the specific sub AAM that is currently outputting a fitted image.

The second set of images SET constitutes a new library of training images i.e. a new sub library and may be submitted to AAM   for reprocessing but for ease of illustration SET is shown applied to second AAM  . Learn Module   within first AAM   accesses SET   to create a second model face and second statistical model fitting function i.e. Model .

Align Module   within AAM   then attempts to fit each and every sample image within SET to the second model face using the second statistical model fitting function. Each sample image that Align Module   fails to fit is output to a third set of images SET   . But each fitted image is output as output aligned image . This second model face and second statistical model fitting function constitute a second statistical fitting pair. The third set of images SET   constitutes a new library of training images and may be submitted to AAM   for reprocessing but for ease of illustration SET is shown applied to third AAM  . Learn Module   within third AAM   accesses SET   to create a third model face and third statistical model fitting function i.e. Model . This third model face and third statistical model fitting function constitute a third statistical fitting pair. Align Module   within AAM   then attempts to fit each and every sample image within SET to the third model face using the third statistical model fitting function. Each sample image that Align Module   fails to fit is output to a fourth set of images SET   . But each fitted image is output as output aligned image .

The fourth set of images SET   constitutes a new library of training images or equivalent a new sub library and may be submitted to AAM   for reprocessing but like before SET is shown applied to fourth AAM   for the sake of illustration. Learn Module   within fourth AAM   accesses SET   to create a fourth model face and fourth statistical model fitting function i.e. Model . This fourth model face and fourth statistical model fitting function constitute a fourth statistical fitting pair. Align Module   within AAM   then attempts to fit each and every sample image within SET to the fourth model face using the fourth statistical model fitting function. Each fitted image is output as output aligned image . Each sample image that Align Module   fails to fit may be discarded. However if further stages of AAMs are desired then they may be output to a fifth set of images for further processing. It is be understood that the number of stages may be increased until the desired percentage of all images within the initial extended library of training images SET   have been fitted.

With reference to where all elements similar to and have similar reference characters and are described above an alternate embodiment may consist of an AAM with multiple Learn Modules   to   sharing a common Align Module . Like before the entire initial extended library of training images which is preferably comprised of thousands of sample true images is gathered into a first set of training images identified as SET   . Learn Module   within AAM accesses SET   to create a first model face and corresponding first statistical model fitting function i.e. Model or equivalently first statistical fitting pair . Align Module then attempts to fit each and every sample image within SET to the first model face using the first statistical model fitting function. Each fitted image is output as output aligned image and each sample image that Align Module fails to fit is output to second set of images SET   .

Also like before second set of image SET constitutes a new library of training images. The second Learn Module   then accesses SET   to create a second model face and second statistical model fitting function i.e. Model or equivalently second statistical fitting pair . Align Module attempts to fit each and every sample image within SET to the second model face using the second statistical model fitting function. Each fitted image may be output as output aligned image and each sample image that Align Module fails to fit is output to third set of images SET   .

The third Learn Module   then accesses SET   to create third model face and third statistical model fitting function i.e. Model or equivalently third statistical fitting pair . Align Module again attempts to fit each and every sample image within SET to the second model face using the second statistical model fitting function and may output the fitted faces. Each sample image that Align Module fails to fit is used to define the fourth set of images SET   .

The fourth set of images SET   constitutes a new library of training images and is submitted to Learn Module   to create a fourth model face and fourth statistical model fitting function i.e. Model or equivalently fourth statistical fitting pair . Align Module then attempts to fit each and every sample image within SET to the fourth model face using the fourth statistical model fitting function. Each fitted image may be output as output aligned image . Each sample image that Align Module   fails to fit may be discarded. But also like before if further stages of Learn Modules are desired then Align Module may output the image that it cannot fit to a fifth set of images for further processing. It is be understood that the number of Learn Modules may be increased until the desired percentage of all images within the initial extended library of training images SET   have been fitted.

A third embodiment is illustrated in where all elements similar to those of and have similar reference characters and are described above. In the present embodiment the multiple models i.e. Model to are created by cycling through application of AAM with a separate model being created during each cycle. Each created model may then be accessed in sequence and preferably in the sequence in which they were created. Since the present example illustrates the creation of four models the structure of would undergo at least four cycles in which each of the four models are accessed individually in sequence and preferably in a fixed predetermined sequence.

As before the entire initial extended library of training images   which is preferably comprised of thousands of samples true images is gathered into a first set of training images identified as SET . AAM is given access to SET for training. The first cycle follows a typical AAM process by having Learn Module access SET and creates a first model face and first statistical model fitting function collectively identified as Model .

As it is to be understood each of Model through Model can fit or align a different number of images from SET to its respective model face using its respective statistical model fitting function. This is true not only because of the differences in each the four models but also because each model is created from a different percentage i.e. a progressively smaller pool of images from extended library  . Preferably the model that can fit the greatest number of images or largest percentage of images of SET is identified as Learn Module and is the first model in the access sequence. The model that can fit the next greatest number of images or next largest percentage of images of SET is identified as Learn Module and is the next model in the access sequence and so on to establish a fixed access sequence. Thus in the present example Learn Module would refer to the last model in the sequence and it would be the model that can fit or align the smallest number of images of SET and Learn Module would refer to the model that can fit the next smallest number of images of SET . In the present case it is assumed that the first cycle would result in the greatest number of aligned images since the size of the library used during this cycle is greatest i.e. includes the entire extended library of training images   . For ease of explanation it is further assumed that the model created during each proceeding cycle is appended to the end of the current access sequence since it can align a smaller number of images than the cycle that preceded it. Therefore Learn Modules and would establish an access sequence correspond to Models and respectively.

Thus during the first cycle Learn Module accesses the entirety of the extended library   i.e. SET and creates a first model face and first statistical model fitting function which is stored as Model . Align Module than uses Model to attempt to align each and every image within SET . Any image that align module fails to align is collected into a NEW Library SET . After Align Module has finished going all the images within SET the next cycle begins.

In this next cycle Learn Module accesses all the images in NEW Library SET . SET is no longer used. Learn Module creates a second model face and second statistical model fitting function which is stored as Model . Align Module than uses Model to attempt to align each and every image within NEW Library SET . Any image that align module fails to align is identified for future use. All images that are aligned may be discarded. Thus at the end the current second cycle all the images that were not successfully aligned during cycle are collected into a NEW Library SET .

It is to be understood that separate identified memory spaces   and for SET and the NEW Library SET are shown for illustrative purposes. If desired the same memory space   corresponding to SET may be used during every cycle as long as each image within SET that failed to be aligned is flagged for use during the next cycle and any image that has already been successfully aligned during a previous cycle is discarded from use in future cycles.

During the next cycle cycle in the current example Learn module again accesses the remaining images that have not been successfully aligned during any of the previous cycles to create a third model face and third statistical model fitting function which collectively saved as Model . Align Module then attempts to align all previously unaligned images using Model . All images that Align Module fails to align are marked for future use and may be collected into NEW Library SET .

The process is repeated during a fourth cycle to create Model . During this fourth cycle Learn Module uses the remaining images that have failed to be aligned during all previous cycles to create a fourth model face and corresponding fourth statistical model fitting function. Align module may then attempt to align the remaining mages in NEW Library SET to determine if any additional cycles are necessary to achieved alignment of the target percentage of images of SET .

That is the cycles may be repeated until a desired percentage of all images within SET are successfully aligned using any of the previously defined models. For example if after four cycles 98 of all the images within SET have been aligned but the target alignment percentage is 99 then additional cycles my be applied until the target percentage of 99 is achieved.

It is noted that during each subsequent cycle the pool of images used in the creation of a model face and its corresponding statistical model fitting function is defined using images having a greater number of outlier features. Thus each subsequently created model face and corresponding statistical model fitting function is better suited for identifying specific true examples of outlier images.

The model that aligned the greatest number of images within SET is designated Learn Module . In the present case it is assumed that Model has the greatest percentage of aligned images and it is therefore designated Learn Module . Assuming that Model achieves the next highest alignment number of images of SET it is designated Learn Module . Similarly Model and Model which align the next two lower numbers of images of SET are designated Learn Module and Learn Module respectively.

This forms a modular or variable learn module n that in operation can select to utilize any of four Learn Modules corresponding to Learn Module or Learn Module or Learn Module or Learn Module . For illustration purposes n may be thought of as variable for indicating which of Learn Modules is being used during any given cycle.

An example of the present AAM in operation is illustrated in where all elements similar to those of and have similar reference characters and are defined above.

In operation a new input image or new test image that is to be submitted to AAM may optionally be preprocess to determined if an object within the class of objects AAM is trained to recognize i.e. a face in the present example is indeed present within the input image . This may be achieved with face detection algorithms as is generally known in the art. This process may optionally add a few landmark points at some of the more easily identifiable characteristic facial features within the input image to create a preprocessed image .

The present embodiment utilizes variable Learn Module n which selects one of a plurality of different Learn Modules in operation. Ideally AAM will try multiple times to align its received image either input image or preprocessed image and variable Learn Module n selects a different one of the available plural Learn Modules during each try. In the present embodiment it is not desirable not to repeat the use of any of Learn Modules and so the number of available Learn Modules determines how many times AAM will attempt to align its received image which is hereinafter assumed to be or preprocessed image .

A counter N i.e. register keeps track of the number of different Learn Modules that AAM has used in attempting to align preprocessed image . To further facilitate its use it assumed that Learn Modules to Learn Module are arranged in order of effectiveness in terms of the number of images within the initial extended library   see that each was able to align. Thus Learn Module will have the greatest chance of aligning preprocessed image Learn Module will have the next greatest chance and so on. Using these assumptions counter N may further be thought of as indicating which of Learn Module or Learn Module or Learn Module or Learn Module is currently being used by AAM .

When AAM first receives preprocessed image counter N is set to N 1 indicating that variable Learn Module n selects Learn Module for use. Align Module thus attempts to align preprocess image using the model face and statistical model fitting equation defined by Learn Module . If the alignment is successful decision point YES then the aligned face is output and the current alignment process ends. If alignment fails decision point NO then counter N is incremented by one N N 1 and it is then determined if counter N has a value greater than a maximum count number decision point . In the present example variable Learn Module n can select from among four different Learn Modules and so the maximum count is preferably set to four. If counter N is greater than 4 this indicates that all of Learn Modules have already been tried and none were successful in aligning preprocess image . The alignment process would then be deemed to failed and the process would end without producing any aligned image.

However if counter N is not greater then the maximum count of 4 then it would indicate the Learn Module next in line to be tried. Variable Learn Module n then selects the Learn Module indicated by counter N and AAM again tries to align preprocessed image . In the present case N would have been incremented to a value of 2 and thus Align Module would use the model face and statistical model fitting function defined by Learn Module to attempt to align preprocessed image . Is alignment is successful then the aligned image is output and the process ends. If alignment is not successful then the process repeats itself by incrementing counter N and selecting the next learn module in line of procession. In the present example N could be incremented to a value of 3 and Variable Learn Module n would select Learn Module in the next attempt.

In this manner Align Module tries each of Learn Modules in turn each time trying to align preprocessed image until an alignment is achieved or until all Learn Modules have been tried. This process is summarized in .

With reference to a first step is to receive a new input image for alignment. The next two steps are optional as is explained above. If desired an initial examination of the new input image may be made in step to determine if the received new input image depicts an object within the class of objects that that the AAM is trained to recognize. In the present example step determines if the received new input image depicts a human face. If it does not then processing may return to step to access the next input image or may terminate. If the received new input image does depict a human face step YES then optional step may place markers on some of the more easily identifiable characteristic features of within the received input image to create a preprocessed image.

Counter N is initialized to 1 in step and step determined if counter N is greater than a predefined maximum count value. As is explained above the maximum count value is preferably equal to the number of available Learn Modules within Variable Learn Module n i.e. equal to the number of models to in the above examples . Since this is the first cycle counter N would not yet be greater than the maximum count value and the process would proceed to step .

In step one of the available Learn Modules preferably Learn Module number N is selected and an alignment module would utilize the model face and statistical model fitting function defined by Learn Module N to attempt to align the preprocessed image to the model face. If alignment is successful as determined in step then the aligned face is output in step and the processed may either end at step or alternatively return to step to access another input image for processing.

If the alignment failed as determined by step then counter N is incremented and step determined if N is now greater than the predefined maximum count value. If N is greater than the predefined maximum count value this would indicate that all the available models to i.e. all the available Learn Modules that Variable Learn Module n is capable of selecting have been tried and none were able to successfully align the preprocessed image. Thus the overall alignment process would be deemed to have failed step and the process may end at step or alternatively return to step to access another input image for processed.

If N is not greater than the maximum count value step NO then the next Learn Module in the line sequence of available Learn Modules would be selected and the align module would use it to attempt the alignment anew.

This process would continue until all the available Learn Modules have been tried i.e. until counter N is incremented to a value greater than the predefined maximum count value or until the alignment module successfully aligns the preprocessed image.

Another novel method of handling a large extended training library of training images in an AAM machine that is capable of aligning a larger number of true outlier examples is to take a divide and conquer approach. A large training library means that the statistical model fitting function created by the learn module will be complicated and not be able to fit a large number of possible true examples considering that a percentage of the training images will not be fitted by the statistical model fitting function . Thus the resultant extensive AAM would typically not be able to align a large number of outlier true examples. Additionally because the statistical model fitting function is relatively more complicated due to it incorporating a greater number or true examples the align module within the extensive AAM would also require more time to optimize the statistical model fitting function when attempting to align an input test image. The present invention seeks to reduce the time required to align an input test image and to successfully accommodate a larger number of outlier true examples.

The present approach replaces a single extensive AAM with multiple smaller AAMs at the expense of a longer setup training phase. Basically the extended library of training images is first divided into a plurality of smaller training sub libraries and a separate AAM is created for each of the smaller training sub libraries. Preferably the training images are grouped according to specified characteristics and each group would constitute a separate training sub library.

By sequential application of select AAMs one may achieve proper alignment of an input test image. That is when the input test image is submitted to a first small AAM the intermediate aligned image produced by the first small AAM is applied to a second small AAM in sequence. If the resultant aligned output image from the second AAM does not achieve sufficient alignment of the input test image then and the resultant aligned output image from the second small AAM is applied to a third small AAM in sequence and so on.

The selection and sequence of AAMs is dependent upon the input test image itself. Preferably the selection and sequence of AAMs used in the alignment of the input test image is such that with each application of a selected AAM the resultant aligned output image incrementally approaches the final aligned image.

With reference to one implementation of an object recognition device in accord with the present invention for recognizing a class of object a human face in the present example portrayed in an input test image would include an input for receiving input test image and an output for outputting an optimized alignment image assuming that a human face has been successfully identified within input test image and fitted to a model image as is explained above in the description of the operation phase of an AAM. That is object recognition device outputs optimized alignment image as a successful recognition of the class of object it is trained to identify i.e. a human face .

Within the training phase of the present embodiment a large extensive library of training images not shown would have been divided into groups of training images. As is explained above each training image in the extensive library training images i.e. the combination of all the images in all the groups of training images would have a true example of a human face and a predefined set of characteristic features of a human face would be identified and labeled within each training image. Preferably the training images within the extensive library of training images are grouped according to some shared trait s in select characteristic feature s so that the images within each group possess a resemblance to each other defined by the specific trait s . For example the training images within a group may have a similar face shape nose shape mouth shape texture tone s in specific areas gaze direction shadowing obscured regions etc. or any combination of features traits. In this manner each group of training images is distinct from another according to each group s defining characteristic traits. That is each group of training images is distinguished by a list of shared traits in select characteristic feature s .

If the sorting of training images into groups is implemented manually then these traits may be subjective as determined by the individual s doing the sorting. This sorting however may alternatively be automated according to predefined criteria.

In the present example object recognition device is shown to include eight active appearance model processing blocks i.e. eight AAMs and . It is to be understood however that any number of AAMs is envisioned within the scope of the present invention. Each AAM processing block would include its own corresponding learn module not shown and corresponding align module not shown . As is explained above within each AAM processing block its corresponding learn module creates a corresponding model image and statistical model fitting function from its corresponding group of training images i.e. its corresponding sub library of training images . As is also explained above within each AAM processing block its corresponding align module attempts to align its corresponding model image to an input image by optimizing its corresponding statistical model fitting function through multiple iterations.

Since the training images within each group share a distinguishing trait in some characteristic feature s the resultant model image and statistical model fitting function of each AAM processing block reflects the specific traits of the group of training images from which it is trained. Thus the model image of each AAM processing block would be different and the different model images would be distinguished from each other by their reflected i.e. highlighted or emphasized characteristic traits.

Each AAM processing block is thus trained to identify its specialized characteristic traits. Basically since true outlier examples of a specific class of object i.e. human face are characterized by shape texture deviations from a norm and since training images having such deviations within the extensive library of training may be grouped together to form their own group i.e. their own training sub library the resultant AAM processing block created from such a group would effectively be trained to identify such deviations in true examples of the object sought. Furthermore since the groups contain a smaller number of training images than the overall extensive library each resultant AAM processing block has a comparatively simplified model image and statistical model fitting function resulting in faster execution of its corresponding align module. Therefore not only is the present invention able to recognize a larger range of true outlier cases of a specific class of object it may achieve faster performance as well.

In the present example the extensive training library would have been divided into eight groups of training images not shown and each of the eight AAM processing blocks and is trained using a corresponding one of the respective eight groups of training images. Consequently each AAM has a distinct model image and statistical model fitting function.

If desired an overall model image may be constructed using all the images in the original extensive library. That is overall model image is constructed using the combination of all the images in all the groups of images used to train all the AAMs processing blocks.

In operation it may be necessary to utilize more than one of the available AAM processing blocks to achieve sufficient alignment of an input test image. In the illustrated example of input test image is submitted to a first AAM processing block selected for having a model image that most closely resembles i.e. matches input test image or for having a statistical model fitting function whose reflected specific traits most closely match the same traits on input test image . This can be determined by comparing the input test image to the model image of each of the AAM processing blocks to identify the AAM whose corresponding model image most closely resembles input test image . A measure of resemblance matching may be obtained by using a measure of misalignment for example as is explained above in reference to .

In the present example it is assumed that AAM is selected from among all of AAMs for having a model image that most closely matches input test image . AAM would output an intermediate aligned image not shown . A determination is then made to resolve whether this intermediate aligned image achieves sufficient alignment.

This determination may be made by obtaining a misalignment measure of this intermediate aligned image and the model image of AAM or alternatively a misalignment measure of this intermediate aligned image and overall model image . If this misalignment measure is not greater than a predefined maximum measure then the alignment is deemed sufficient and processing ends by outputting the intermediate alignment image via output . Processing may also end if a predefined number of AAMs have been accessed in sequence in the attempt to align input test image or if the alignment measure obtained from a current AAM is not better than an alignment measure achieve from a most previously accessed AAM. That is processing may end if an additional application of another AAM does not achieve an improvement in alignment over that achieved by the most previous accessed AAM.

Assuming that none of the conditions for terminating processing have been met and that the alignment measure obtained from the intermediate aligned image output by AAM is greater than the predefined maximum measure then this intermediate aligned image is submitted to another AAM. Preferably it is submitted to the AAM whose model image most closely resembles i.e. matches it as explained above. In the present example it is assumed that the intermediate aligned image output from AAM is submitted to AAM .

The above process then repeats. Again assuming that none of the conditions for terminating processing have been met and that the alignment measure obtained from the intermediate aligned image output by AAM is greater than the predefined maximum measure then the intermediate aligned image output from AAM is submitted to another AAM. In the present example is assumed that the intermediate aligned image output from AAM most closely matches the model image of AAM and it is therefore submitted to AAM for further processing.

Again assuming that none of the conditions for terminating processing have been met and that the alignment measure obtained from the intermediate aligned image output from AAM is greater than the predefined maximum measure then the intermediate aligned image from AAM is submitted to another AAM. In the present example it is assumed that the intermediate aligned image output from AAM most closely matches the model image of AAM and thus it is submitted to AAM for further processing.

The present example assumes that the intermediate aligned image output from AAM has achieved sufficient alignment i.e. its alignment measure is not greater than the predefined maximum measure and thus sends the intermediate aligned image produced by AAM to output and processing ends.

It is to be understood that the AAM selection sequence may be controlled by a data processing module or data control module not shown in . A general data flow implementable by such a data processing module for controlling AAM selection sequence is illustrated in . First an input image to be submitted to a selected AAM is received step . If desired two variables may be set step . A first variable current image indicates which image is currently being processed. Thus the current image is initially set to the input image. Variable cycle count may be used to keep track of how many times one has cycled through step . Since step has not been reached yet cycle count is initially set to zero.

In step an AAM is selected based on which of the many AAMs corresponding model image most closely matches the current image. As explained above this may be determined by comparing a misalignment measure of the current image and each AAM s corresponding model image. Alternatively this determination may be made by identifying the AAM whose corresponding statistical model fitting function is best suited to identify specific traits that most closely match similar traits on the current image. The current image is then submitted to the selected AAM which produces an intermediate aligned image.

Variable cycle count may be incremented step upon finishing processing of step . Step checks if the cycle count has reached a predefined maximum. Basically this places an upper limits on how many times one may continue to resubmit an intermediate aligned image to another AAM. If the maximum count has been reached step YES then the current intermediate aligned image may be output as a successful recognition of the class of object i.e. human face step . If the maximum count has not yet been reached step NO then processing continues to step .

In step the data processing module determines if a misalignment measure of the intermediate aligned image and the selected AAM s corresponding model image or a model image created from a combination of all the groups of images is smaller than a predefined maximum. If it is step YES then processing ends and the intermediate image may be output as the successful recognition of the class of object step . If has not step NO then further processing may be necessary.

Step first determines if any improvement has been achieved in the current cycle as compared with the most previous cycle. If step NO indicating that no improvement or an improvement smaller than a predefined minimum has been realized in the current iteration then processing ends and the current intermediate aligned image may be output as the successful recognition of the class of object step .

However if an improvement has been achieved step YES then variable current image is set to the current intermediate aligned image step and processing returns to step for another cycle.

The approach of may require that at each iteration the current image be compared with the model image of every AAM to determine to which AAM the current image should submitted. If there is a large number of AAMs this selection process may be too time consuming. An alternative approach illustrated in uses a hierarchical tree approach to reduce the number of model images to which the current image should be compared to select a next AAM in a sequence i.e. reduce the number of AAMs that need to be checked .

With reference to in a currently preferred approach a large extend training library of training images is preferably divided into a hierarchical tree structure . This process may be accomplished manually or may be automated. Preferably the hierarchical tree defines link paths between nodes according to similarities in specific predefined characteristic features of the class of object illustrated in the training images. In the present example it is assumed that the class of object is a human face and that specific characteristic features of a human face have been manually identified and mapped within each training image. For illustration purposes a root model image F constructed from the entirety of extended library is shown but the creation of root model image F may be optional as is explained above.

In the construction of hierarchical tree extended training library is first divided into at least two groups of training images and according to similarities or dissimilarities in specific characteristic feature s . For examples the images may be divided according to characteristic features such as face shape nose shape mouth shape texture tone s in specific areas gaze direction shadowing obscured regions etc. or according to any combination of such features. Preferably all groups of training images that constitute a leaf node i.e. a bottom most node in hierarchical tree should not have more than a predefined maximum number of training images. If a group of images is found to have less than the predefined maximum number of training images then it may be designated a leaf node and remain fixed. Other criteria for determining when a group of images should be further divided even if the number of images is already smaller than the predefined maximum number of training images is a variance measure or a max distance from a norm such as root model image F. However if a group is found to have more than the predefined maximum number of training images then it is designated a parent node subject to further division.

Thus after extended library is divided into groups and the number of training images in each of groups and is then checked to determine if either group has fewer training images than the maximum number permissible. If it does then it designated a leaf node. If it has more than the maximum permissible number then it is designated a parent node and additional child nodes are constructed below it.

In an hierarchical tree structure as it is known in the art the root node is the top most node in the hierarchical tree a parent node is a node that has at least one other node below it and linked to it a child node is a node linked to a parent node above it and a leaf node is a node with no child nodes below it. A leaf node is effectively a bottom most node along a link path or branch path downward from the root node. If a created group of training images has more than the permissible maximum number of training images then it will be defined as a new parent node and its training images will be further divided into two new smaller groups that will constitute two child nodes below and linked to this new parent node. This dividing process continues until one has only groups having not more than the permissible maximum number of training images.

For ease of illustration in the example of it is assumed that the maximum number of training images permissible within each final group of training images i.e. each leaf node is 10 training images and it is further assumed that the initial extended training library has 22 total training images. It is to be understood however that these numbers is purely for illustration purposes and that in practice extended training library may in have hundreds or thousands of training images. In a currently preferred practical application of the present invention extended training library would have 1000 independent images i.e. not sequential images obtained from a video sequence .

In the present example the first constructed group has 12 training images and the second constructed group has 10 training images. Since the second group has 10 training images i.e. does not have more than the maximum permissible number of training images it is designated a leaf node and will not be divided any further.

A new AAM is defined using only the images in the second group . As before this is accomplished by means of a learn module not shown that constructs a model face F and a statistical model fitting function using the characteristic features all 10 training images in second group . For ease of explanation model face F will be used interchangeably with the leaf node defined by second group . Thus F defines Leaf Node . An align module not shown within AAM would than make use of this statistical model fitting function to align a received input image as is explained above.

On the other hand first group has more than the maximum permissible number of training images i.e. more than 10 training images . Therefore it is designated to become a parent node and its 12 images are further divided into two new groups and according to the same or according to other characteristic feature s as those used to divide its parent node F.

Like before the 12 images in first group are separated according to similarity such that the training images in each new group and share some similar characteristic feature s . First a new model face F is created combining the characteristic feature of all 12 training images within first group . Again for ease of explanation F is used herein to refer to the parent node defined by first group . Thus new model face F is a new parent node and it is also a child node below root node F.

In the present example the 12 training images within first group are divided into new groups and . Group has 5 training images and group has 7 training images. Since both groups and have less than the maximum permissible training images both become leaf nodes with no further child nodes below either of them. Because both groups and define leaf nodes a separate corresponding AAM is constructed for each of groups and resulting in AAM and AAM respectively.

Second AAM is constructed using only the training images within group and third AAM is constructed using the training images only within group . As before construction of AAM entails a learn module not shown defining a new model image F and new statistical model fitting function using the characteristic features of only the training images in group along with construction of a corresponding align module not shown . Similarly construction of AAM entails construction of a new learn module not shown defining another new model image F and another new statistical model fitting function using the characteristic features of only the training images in group along with construction of another corresponding align module not shown .

Thus by the end of construction of hierarchical tree the initial extended training library will have been divided into multiple smaller groups or sub libraries and and a separate AAM and respectively would have been constructed for each of sub libraries and . Additionally each child node will be defined by a model face F through F constructed from a different subset i.e. group of the training images carved from the original extended training library . As is explained above a model image F for the root node may optionally be constructed from the entirety extended training library .

Once hierarchical tree and all three the AAMs and each having a one to one relationship with a corresponding leaf node F F and F respectively are complete hierarchical tree may be used to align an input image as follows.

In the present example it is assumed that input test image is more similar to F and thus the path down hierarchical tree proceeds to node F. Since F is not a leaf node the image currently being process i.e. input test image is compared with F s two child nodes F and F. That is input test image is compared with model images F and F to determine which of the two model images input test image more closely resembles. Presently it is assume that input test image more closely matches model image F and progress down hierarchical tree to node F.

Since node F is a leaf node i.e. it has no child node below it input test image is submitted to AAM i.e. the AAM associated with node F . AAM attempts to align input test image as described above and outputs a first aligned image . It is now determined if first aligned image output by AAM provides sufficient alignment of input test image or if further processing is required. This determination may be made by verifying if AAM deemed its alignment successful or by checking the similarity i.e. misalignment of first aligned image with F or alternatively with F . If sufficient alignment has been achieved then processing ends and first aligned image is output as the overall aligned image. If the alignment is deemed not to be sufficient i.e. a measure of the alignment is not within predefined specifications then first aligned image is resubmitted to hierarchical tree for a second interrelation.

In this second iteration first aligned image is compared with F and F to determine which of the two model images it more closely matches i.e. resembles . In the present example it is assumed that first aligned image has a closer alignment with F than with F and thus progress down hierarchy tree proceeds to node F. Because node F is a leaf node first align image is submitted to AAM for alignment. AAM outputs a second aligned image which is then checked to determine if sufficient alignment has been achieved or if further processing is required. Like before this determination may be made by checking whether AAM deemed second aligned image valid or may be determined by obtaining a measure of the similarity or misalignment i.e. mismatch of second aligned image with model image F or with model image F . If sufficient alignment has been achieved or if the measure of alignment has not improved from the most previous iteration or if a predefined number of iterations have been executed then processing ends. If the alignment is deemed not be sufficient i.e. a measure of the alignment is not within predefined specifications then second aligned image is resubmitted to hierarchical tree for a third interrelation.

Like before this third iteration begins at the top of hierarchical tree by comparing the misalignment of second aligned image with model image F and with model image F. In the present example it is assumed that second aligned image more closely matches model image F and progress down hierarchical tree proceeds to node F. Since node F is not a leaf node second aligned image is then compared to F s child nodes F and F. That is second aligned image is compared with model image F and with model image F to determine which of these two model images it most closely matches i.e. is more aligned . In the present example it is assumed that second aligned image more closely aligns with model image F and thus progress down hierarchical tree proceeds to node F.

At node F second aligned image is submitted to AAM which is the AAM associated with node F. Like before AAM attempts to align second aligned image with its model image F and if it succeeds in aligning second align image AAM will output a third aligned image not shown . Like before a determination may be made to determine if sufficient alignment has been achieved. Also like before this determination may be made based on whether AAM deems its output third align image a successful alignment or by a measure of the misalignment between the third align image and model image F or model image F . If sufficient alignment has been achieved or if the measure of alignment has not improved from the most previous iteration or if a predefined maximum number of iterations have been executed then processing ends. Otherwise the third aligned image may be resubmitted to hierarchical tree for a fourth interrelation and so on.

Although in the present example three iterations were described which effectively made use of information from all 22 of the original training images of extended library this is purely for illustration purposes. In a more practical application extended library may have thousands of independent true sample images and the maximum number of images limited to each leaf node may be a 100 images. In practice it has been found that five to ten iterations is typically sufficient to properly align an input test image including test images of true outlier examples. Since each comparatively small AAM in each leaf node is much less complicated than a single extensive AAM constructed from the entirety of all the training library in extended training library processing time is decreased and accuracy in aligning a larger number of true outlier images is increased.

An overview of the process for training a hierarchical AAM such as illustrated in is shown in . A first step is to access a training library of true training images each having characteristic features of a class of object i.e. human face labeled and identified. Preferably this training library is an extended training library having a large number of training images. Next the hierarchy tree is constructed in step . Basically the training images in the extended training library are arranged into a hierarchical tree structure according to the similarity for example according to one or more similarity or dissimilarity measure of predefined specific characteristic feature s of the training images. The hierarchical tree structure is constructed to have a root node i.e. topmost node a plurality of inner nodes i.e. nodes with at least a parent node above them and a child node below them and a plurality of leaf nodes i.e. terminal nodes or bottom most nodes with no child nodes below them . The inner nodes define link paths from the root node to each of the leaf nodes. At each non leaf node the training images are divided into at least two groups if images according to some similarities in characteristic feature s and each of the at least two groups defines a child node. The number of leaf nodes is selected such that the number of sample images at each leaf node is not greater than a predefined maximum number. Finally in step a separate AAM is created for each leaf node using only the training images associated with each respective leaf node.

Although a description of a preferred construction of a hierarchical tree is provided above with reference to an alternate description for implementing step i.e. constructing a hierarchical tree is shown in .

With reference to in an initial step a root node is defined and the entirety of the extended training library of training images is associated with it. A couple of variables may be initiated in step . A first variable current node points to the current node being worked with and it is initially set to the root node since it is the only node currently constructed. As is explained above in reference to the hierarchical tree may have multiple levels of inner nodes in a path from the top most node i.e. the root node down to each bottom most node i.e. each leaf node . In a hierarchical tree the term depth may be used to describe a specific level traversed downward from the root node. Therefore a second variable current node depth may be used to identify the depth level down from the root node in which the current node lies. Since the root node is the only node yet constructed variable current node depth is initially set to the node depth of the root node.

In step the current node is processed which means that if the number of training images associated with the current node are too many for it to be classified as a leaf node then the training images associated with the current node are divided into two groups according to similarities in specific characteristic feature s . The processing further includes determining if the number of training images in either of the two newly created groups is greater than the predefined maximum number. If the number of training images in a group is not greater than the maximum number then that group is designated a leaf node under the current node. If the number of images in a group is greater than the maximum number then that group is designated a non leaf child node of the current node.

After processing the current node one may move laterally to process another node at the same depth as the current node. In this manner all the nodes at a common level are processed before proceeding downward to a next level in the hierarchical tree. To do this step first determines if there are any other nodes at the current depth level that have not yet been processed according to step . If not all nodes at the current depth level have been processed step NO then step reassigns current node to the next node at the current level that has not yet been processed and returns to step to process that next node. In this manner steps cycles until all the nodes at a current depth level have been applied to the processing of step .

When all the nodes at a current depth level have been processed step Yes then step checks if there are any non leaf child nodes at the next depth level below the current node. If there are step Yes then one proceeds to the next lower depth level of the hierarchical tree in step by incrementing current node depth to the next lower depth level. Processing then proceeds to step where current node is assigned to a node not yet processed within the current node depth.

However if there are no non leaf nodes below the current node step NO then the hierarchical tree is complete and the process ends step .

An example of an implementation of the processing used in step is described above in reference to but another description is provided in . Initial step first determines if the number of training images associated with the current node is greater than the maximum number of permissible images i.e. greater than max image count . If it is not step NO then the current node is a leaf node and an AAM is constructed using the training images associated with that leaf node in step . Alternatively if step NO one may still check if a variance measure of a model image created with training images associated with the current node or if a maximum distance of this created model image is greater than a maximum distance from mean model image to determine if it should be further split into multiple nodes. However assuming that these alternate criteria are not being used then processing of step ends and processing could proceed to step of .

Alternatively if step YES meaning that the number of sample images associated with the current node is greater than max image count then a new model image is created using the training images associated with the current node step . Additionally the current node s associated sample images are sub divided into at least first and second groups of sample images according to similarities or dissimilarities in characteristic feature s of the training images step which may be pre specified if desired.

If only first and second groups of sample images are created then a first child node under and linked to the current node is created and the first group of sample images is associated with this first child node step . Similarly a second child node is created under and linked to the current node and the second group of sample images is associated with the second child node step .

Alternatively if more than first and second groups of sample images are created then a separate child node is created per created group of sample images. Each created child node is created under and linked to the current node and the group of sample images from which it was created is associated with the created child node.

The use of the hierarchical tree in operation to align an input test image is described above in reference to but for ease of explanation a second description is provided in .

With reference to a new input test image i.e. new input image is received and a memory pointer i.e. variable current image is made to point to the newly received input test image step . As before variable current node may be used to point to the node currently being processed. Since progress through the hierarchical tree start at this root node current node is initially set to the root node step . Since the current node is the root node it is assumed that there are at least two child nodes below the current node in this first iteration. For convenience the two child nodes below the current node are identified as a left child node and a right child node but it is to be understood that if more than two child nodes were below the current node then another suitable naming convention may be used.

In step the current image is compared with the model images associated with each of its child nodes and the next processing step would proceed to the child node that is most similar to i.e. better matches or is aligned more closely with the current image. In the present example it is assumed that only two child nodes are used and so if the current image more closely matches the left child node step LEFT then progress through the hierarchical tree would proceed to the next lower level and current node is set to the left child node step . Conversely if the current image more closely matches the right child node step RIGHT then progress through the hierarchical tree proceeds to the next lower level but the current node is set to the right child node step .

At this point step it is determined if the current node is a leaf node i.e. a bottom most node . If the current node is not a leaf node step NO then there is at least one more hierarchical level below the level of the current node and processing returns to step to compare the current image with the model images associated with the left and right child nodes below the current node. However if the current node is a leaf node step YES then processing proceeds to step where the current image is submitted to the AAM associated with the current node which creates a new aligned image output from the associated AAM.

As is explained above there are multiple methods for determining when sufficient alignment of the new input test image has been achieved. Four methods or combination of these are described above with reference to . A first method is to limit the number of iterations to a maximum number of cycles such as five although in practice five to ten cycles have been shown to be sufficient. A second method is to establish a minimum acceptable measure of misalignment and to end the cycling through the hierarchical tree when the minimum acceptable measure of misalignment with the current leaf node s model image or alternatively with the root node s model image has been achieved. A third method is to end the cycling through the hierarchical tree when no further reduction in the misalignment is achieved after a current iteration as compared with the most previous iteration. A fourth method is to incorporate the leaf node s associated AAM s determination of whether it had successfully aligned its input image into the decision of whether to proceed with further iterations. These methods may be combined to create a more robust determination of when alignment has been achieved within a reasonable processing time. As an illustration the example of incorporates the first three methods into its determination of whether another cycle through the hierarchical tree is warranted.

In step one determines if the number of cycles through the hierarchical tree has reached the maximum permissible number of cycles. If it has step YES then processing ends step and the current image may be output as the overall aligned imaged. But if the current cycle count has not exceeded the maximum number then processing proceeds to step .

In step a measure of the misalignment of the new aligned image and the model image of the current leaf node or of the root node is compared with a predefined maximum misalignment measure. If it is greater step YES then processing continues to step otherwise step NO processing ends step and the current image may be output as the overall aligned imaged.

In step it is determine if a predefined minimum improvement in alignment has been achieved in the current cycle since the most previous cycle. If no minimum improvement has been achieved step NO then processing ends step and the current image may be output as the overall aligned imaged. But if a minimum improvement has been achieved step YES then in step the current image variable is updated to point to the current new aligned image and this new current image is submitted to the top of the hierarchical tree at step to start a new cycle through the hierarchical tree.

As is the case of hierarchical tree of the tree structure naturally clusters similar faces. Thus the sample training faces are clustered during the AAM learning process to train a separate specialized AAM at each leaf node. Each leaf node s AAM is specialized since it is trained with a corresponding group of training image having some common characterization trait s . In operation the hierarchical tree is searched to find the closest matching AAM model image to an input test image and the input test image is submitted to the found AAM. If the resultant aligned image does not achieve sufficient alignment the resultant aligned image is submitted anew to the hierarchical tree for continued processing. This may require multiple cycle searches through the hierarchical tree. Optionally extracted face texture or an error image can be used to identify the closest matching AAM model face.

An illustration of a practical search of a hierarchical tree is illustrated in . In this example three iterations are required to achieve the overall alignment output of an input test image . A first iteration follows a path from root node down six levels to leaf node LN and application of its associated AAM AAM A produces a first intermediate aligned image . Since first intermediate aligned image does not provide sufficient alignment first intermediate aligned image is submitted to root node for a second iteration.

This second iteration follows a path from root node down five levels to leaf node NL and application of its associated AAM AAM B which produces a second intermediate aligned image . Again because second intermediate aligned image does not provide sufficient alignment second aligned intermediate image is submitted to root node for a third iteration.

This third iteration follows a path from root node down six levels to leaf node NL and application of its associated AAM AAM C produces a third intermediate aligned image not shown . In this case the third intermediate aligned image satisfies predefined criterion for sufficient alignment and it is deemed the overall output aligned image.

While the invention has been described in conjunction with several specific embodiments it is evident to those skilled in the art that many further alternatives modifications and variations will be apparent in light of the foregoing description. Thus the invention described herein is intended to embrace all such alternatives modifications applications and variations as may fall within the spirit and scope of the appended claims.

