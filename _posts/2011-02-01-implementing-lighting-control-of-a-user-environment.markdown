---

title: Implementing lighting control of a user environment
abstract: A system and method for controlling lighting conditions in a user environment whereby bandwidth consumption may be managed is disclosed. An inner frame area and an outer frame area adjust certain lighting conditions in the user environment in response to certain lighting conditions detected by the image capture device as those conditions affect bandwidth consumption during transmission of the image capture data. The frame areas may be dynamically controlled as to affect the brightness and/or color of the particular user environment.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08243089&OS=08243089&RS=08243089
owner: Sony Computer Entertainment Inc.
number: 08243089
owner_city: Tokyo
owner_country: JP
publication_date: 20110201
---
The present application is a continuation and claims the priority benefit of U.S. patent application Ser. No. 11 744 816 filed May 4 2007 now U.S. Pat. No. 7 880 746 and entitled Bandwidth Management Through Lighting Control of User Environment Via a Display Device which is a continuation in part and claims the priority benefit of U.S. patent application Ser. No. 11 624 886 filed Jan. 19 2007 and entitled Lighting Control of a User Environment via a Display Device which claims the priority benefit of U.S. provisional patent application No. 60 798 112 filed May 4 2006 and entitled Lighting Control of a User Environment via a Display Device. The disclosure of each of the aforementioned applications is incorporated herein by reference.

The present invention generally relates to the generation of visual data through an image capture device during an audio visual session such as an audio visual chat session or during video game play. More specifically the present invention relates to control of lighting conditions in a user environment whereby the bandwidth consumed by transmission of image data generated and or captured during such audio visual sessions may be effectively managed.

With the increased processing capabilities of various computing systems new methods for interacting with those computer systems have become available. For example a variety of input devices employing video image capture allow user control of or interaction with objects on a graphical display such as a video monitor.

Such video input devices often are responsive to the movement or position of a user in the field of view of an image capture device. Video image processing translates the movement of the user that has been captured as a sequence of video images into signals that may be used for example to control a character or avatar in a video game. Alternatively image processing may generate a video image to be displayed in a chat session in a manner similar to a video conference.

An image capture device typically scans a field of view in which a user may be present e.g. a user environment such as an office game room living room or the like . The captured video image may be applied to a video digitizer that provides digital output to a processor that analyzes and processes the digital information received from the digitizer. Based upon the position or movement of the participant in the field of view the processor produces signals that are used by the graphics generating system to move objects on the display. Similarly the system may generate an image of the user for transmission to another user in a chat session.

The output of the devices on graphical displays can be significantly affected by a variety of factors especially lighting conditions in the user environment. The computer processing time required for image processing in an ideal user environment may be extensive and complex and tends to require substantial computing and or temporal resources. A user environment that is overexposed or underexposed as to particular light sources only complicates such processing activities in that the system must compensate for the adverse lighting conditions thereby resulting in slower computing operations and affecting any real time interactions. In some instances the lighting conditions are so adverse that a computing system cannot compensate for the particular environment conditions and inaccurate data if any is generated thereby resulting in incorrect game control or the generation of poor chat session video.

Similarly lighting conditions may contribute to the amount of bandwidth consumed by transmission of a captured video image or images . This may be especially true in the context of real time full motion video as may be generated in the context of a video chat session. Video signals by their very nature consume large amounts of bandwidth notwithstanding the application of a variety of compression techniques e.g. lossy compression as are known in the art. An overwhelming presence of a certain color or colors in a particular environment e.g. as might be generated by bright lights of a particular color may be captured by an image capture device. Transmission of that image and its excessive color saturation may increase an overall file size and lend to excessive bandwidth consumption. Excessive bandwidth consumption may in turn contribute to a degraded conferencing experience e.g. jitter .

There is a need for an image capture device whereby the lighting conditions of various user environments can be automatically and dynamically controlled subject to the particular requirements of the capture device or hardware and software related thereto. Additionally there is a need for lessening the computational burdens of an image processing system coupled to such a device whereby the system may function substantially in real time thus providing the user with a natural interaction experience with regard to a game chat session or any other interaction involving the aforementioned image capture device. Further still there is a need in the art to reduce bandwidth consumption that may occur as a result of the capture of certain image data that increases overall transmission file size.

In an embodiment a system for managing bandwidth consumption through control of lighting conditions in a user environment is disclosed. An image capture device captures image data in a user environment which is then transmitted over a communications network. A computing device may be coupled to the communications network to measure consumption of bandwidth related to transmission of the captured image data over the communications network. A display device may display an inner frame area and an outer frame. The inner frame area and the outer frame area control at least one lighting condition in the user environment in response to the consumption of bandwidth as measured by the computing device.

In another embodiment of the present invention a method for managing bandwidth consumption through control of lighting conditions in a user environment is disclosed. Image data is captured and transmitted over a communications network. Consumption of bandwidth related to transmission of the captured image data over the communications network is measured. An inner frame area and an outer frame area may be generated on a display device in the user environment. At least one lighting condition in the user environment may be controlled via the inner frame area and the outer frame area in response to the consumption of bandwidth as measured by the computing device.

A video conference system includes a first image capture device and a second image capture device. Each device is configured to capture user environment image data in a respective user environment and for transmission over a communications network. A conference management server receives the first user environment image data and the second user environment image data and measures consumption of bandwidth related to transmission of the first user environment image data and the second user environment image data over the communications network. A first user client computing device and a second user client computing device are each associated with a respective image capture device. The first and second user client computing devices receive lighting control instructions from the conference management server in response to the consumption of bandwidth as measured by the conference management server. The lighting control instructions received from the conference management server include generating an outer frame area and an inner frame area on a display device at both the first user client computing device and second user client computing device the outer frame area and inner frame area collectively controlling at least one lighting condition in the respective user environment.

The client computing device may be implemented as a PlayStation 3 from Sony Computer Entertainment Inc. It should be noted however that the client computing device and its processor functionality may be implemented in other types of computing devices such as personal computers workstations laptop computers wireless computing devices portable media devices or any other type of computing device that may be capable of receiving and processing graphical image data.

Video display device may be any device configured for the display of video data such as a television or computer monitor. In one embodiment video display device receives graphical image data from client computing device via an AV MULTI OUT connector that may be coupled to an integrated audio video cable and the requisite video and audio connectors. Various other connection mechanisms may also be used for example S VIDEO an RFU adaptor component video input Y C PC P and HDTV input Y PP as well as the High Definition Multimedia Interface HDMI and Digital Visual Interface DVI . In some embodiments such as a portable media device the client computing device and video display device may be integrated as is the case in a PlayStation Portable from Sony Computer Entertainment Inc.

Image capture device may be in one embodiment of the present invention a color digital camera device with functionality similar to that of a webcam. Image capture device may be coupled to client computing device via a USB cable. In some embodiments image capture device may utilize a wireless transmission protocol to exchange data with the client computing device e.g. 802.11x . Image capture device may also include commercially available dedicated video conferencing products such as those manufactured by Polycom Inc. of Pleasanton Calif.

Image capture device extracts specific information from captured multi dimensional image data for subsequent presentation to a user of the device e.g. a color image on video display device or for transmission to another user over a network as in below . For example captured image data may be integrated into a video game or other user centric application e.g. a workout or training video . Captured image data may also be utilized in a video conference or audio visual chat session wherein the captured data may be transmitted to another user s computing device for display.

Image capture device may be capable of capturing and mapping in three dimensions in addition to normal two dimensional video imagery. Similar to normal cameras image capture device captures two dimensional data for a plurality of pixels that comprise the video image. These values are color values for each pixel generally red green and blue RGB values. In this manner objects captured by the image capture device appear as two dimensional objects on a monitor.

Unlike a conventional camera however image capture device may also capture depth values in a particular field of view e.g. a particular user environment . That is image capture device may capture the x and y components of an environment using RGB values for each pixel in the environment in addition to a z component which represents a depth value for the environment. i.e. the z axis .

In operation a z value may be captured for each pixel of the scene each z value representing a distance from the camera to a particular object in the scene corresponding to the related pixel. A maximum detection range may be defined beyond which depth values will not be detected. Through the use of z value capture each object can be tracked in three dimensions whereby the z values along with the two dimensional pixel data can be processed to create an enhanced three dimensional interactive environment for the user.

An input image processor not shown at client computing device translates the captured video images and depth data into signals that are delivered to an output image processor not shown at the client computing device . The output image processor may be programmed to effect movement and status of virtual objects on the video display device in response to signals received from the input image processor. In some embodiments input and output image processors may be an integrated part of the hardware and software configuration of the image capture device . In other embodiments such processing functionality may be partially distributed over a network like that shown in such processing taking place at for example a conferencing management server. Some embodiments of the image capture device may also be configured for the capture and subsequent processing of visual data in high definition.

Various image processing techniques allow a user to interact with the image capture device using motion color detection and in some embodiments sound through a built in microphone or other audio input device not shown coupled to the image capture device or client computing device . Certain interaction techniques are disclosed in U.S. patent publication number US 2004 0207597 A1 for a Method and Apparatus for Light Input Device and U.S. Pat. No. 7 102 615 for a Man Machine Interface Using a Deformable Device. A prop input device is disclosed in U.S. patent publication number US 2004 0239670 A1 for a System and Method for Providing a Real Time Three Dimensional Interactive Environment as well as U.S. Pat. No. 6 795 068 for a Method for Mapping an Object from a Two Dimensional Camera Image to a Three Dimensional Space for Controlling Action in a Game Program. The disclosures of all of the aforementioned applications and patents are incorporated herein by reference.

As disclosed in incorporated U.S. Pat. No. 6 795 068 a user may hold a prop object in front of a digital video camera for causing an action to occur in a video game. The prop may comprise a stick like object which is made up of a handle. The user may stand in front of a video camera which may comprise a USB webcam or a digital camcorder connected to an input output port of a game console. As the user moves the object in front of the camera the features of the object are picked up by the camera and processing is performed in order to isolate and discriminate a pixel group.

A three dimensional description of the object including its position and orientation in three dimensional space is calculated and this description is correspondingly stored in the main memory of the game console. Then using rendering techniques known in the art the three dimensional description of the object is used to cause action in a game program which is displayed on the display screen of the monitor.

For example a virtual object can be moved throughout the scene of the game corresponding to the movements of the real object made by the user. As the user changes the position and orientation of the object by moving it the three dimensional description of the object in the memory and a corresponding rendering of the object in the rendering area of image memory are continuously updated so that the position and orientation of the virtual object or torch on the monitor changes as well.

As disclosed in incorporated U.S. patent publication number US 2004 0239670 video image processing has been used to translate the movement of the user that has been captured as a sequence of video images into signals for game control. Based upon the position or movement of the participant in the field of view a processor produces signals that are used by a graphics generating system to move objects on the display.

In one embodiment of the present invention the image capture device may be compact in design allowing for placement on top of a video console or television. Image capture device may comprise a pivot thereby allowing for positioning of the device and its related field of view. The image capture device may further comprise a rotational ring around the camera lens for manual focus control. Some embodiments of the image capture device may provide for automated positioning and focusing through the use of a directional sensitive microphone that tracks a source of audio e.g. an individual who is speaking and the focus of the image capture device may be subsequently adjusted according to the position of the audio source relative to the image capture device .

Referring now to a block diagram of one embodiment of a client computing device or client is illustrated. Client computing device may be used to aid in the generation of real time three dimensional interactive environment data. The client may be communicatively coupled to image capture device in order to generate the aforementioned environment data.

The client may comprise but is not limited to a main memory a central processing unit CPU vector processing units VU and VU a graphics processing unit GPU all of which may be coupled via a bus to an input output processor IOP . The client may also comprise an IOP memory a controller interface a memory card a Universal Serial Bus USB interface and an IEEE 1394 interface . The client may further include an operating system read only memory OS ROM a sound processing unit SPU an optical disc control unit and a hard disc drive HDD all of which may be connected via a bus to IOP .

Some embodiments of the client may also include a network adaptor which may offer an Ethernet connection and or telephony connection . The client in one embodiment may be an electronic gaming console although client or portions thereof may also be implemented as a general purpose computer a set top box a hand held gaming device or in a mobile device such as a cellular phone. It should further be noted that various other system architectures may be utilized within the scope of the present invention such as the computer architecture and high speed processing model disclosed in U.S. patent publication number 2002 0138637 for a Computer Architecture and Software Cells for Broadband Networks the disclosure of which is incorporated herein by reference.

The CPU the VU0 the VU1 the GPU and the IOP communicate via a system bus . The CPU communicates with the main memory via a dedicated bus . The VU1 and the GPU may also communicate with one another via a dedicated bus . The CPU executes programs stored in the OS ROM and the main memory . The main memory may contain pre stored programs and may also contain programs transferred via the IOP from a CD ROM DVD ROM or other optical disc not shown using the optical disc control unit . The IOP controls data exchanges between the CPU the VU0 the VU1 the GPU and other devices of the client computing device such as the controller interface or from other such systems via the network adaptor .

The GPU executes drawing instructions from the CPU and the VU to produce images for display on a display device not shown . The VU transforms objects from three dimensional coordinates to two dimensional coordinates and sends the two dimensional coordinates to the GPU . The SPU executes instructions and processes data to produce sound signals that are output on an audio device not shown .

A user of the client provides instructions to the CPU via a controller coupled to the controller interface . Controller may be any control device for example a joystick a set of directional buttons and or other control buttons. An exemplary controller is illustrated in . A user may instruct the CPU to store certain information on the memory card which may be removable e.g. a flash memory or other non volatile memory card or may instruct a character in a game to perform some specified action. Other devices may be connected to the client computing device via the USB interface and the IEEE 1394 interface . As previously noted the image capture device may be coupled to the client utilizing a USB connector or in another example a wireless Ethernet network through Ethernet connection .

In that regard some embodiments of the client comprise a network adaptor that provides the hardware functionality necessary for the client to connect to a network. The network adaptor may comprise for example a system connector that operates to connect the network adaptor to the client computing device through an expansion bus connector . The network adaptor may also comprise a power connector and data connector to allow for the provisioning of power from the client to the network adaptor and the exchange of data between the client and the network adaptor . Network adaptor may be fully integrated with the client or may be a detachable hardware device that may be implemented in older legacy client computing devices .

In some embodiments of the present invention the network adaptor may also require the installation of certain software on the client to allow for identification and connection to a particular IP address and or dial up to a particular Internet Service Provider. Software may also provide other functionalities such as the creation and maintenance of user profiles in addition to functional interaction between the client and the network adaptor . Such software or data related to such functionality may be embodied on CD ROMs for games or applications requiring a network connection stored on memory card or part of a firmware upgrade.

The network adaptor may also comprise an Ethernet connection . Through the Ethernet connection a network cable e.g. a 100 Base TX or 10 Base T may be coupled to the network adaptor for connection to a network. The network cable may for example be communicatively coupled to a DSL or cable modem. The network cable may also be communicatively coupled to for example a router via a LAN port the router may then be coupled to a DSL or cable modem through a WAN port. In further embodiments the Ethernet connection may allow for a network cable to be connected to a wireless Ethernet bridge. The wireless Ethernet bridge may be communicatively coupled to a wireless router utilizing for example an 802.11x protocol. The wireless router may be further communicatively coupled to a cable or DSL modem.

The network adaptor may also comprise a telephony connection . Through the telephony connection a standard telephone line with for example an RJ 11C telephone connector may be connected to the network adaptor and a telephone wall jack. In this regard the network adaptor may further comprise modem functionality such that the client computing device may communicate data over the public switched telephone network via the telephony connection .

Inner frame area and outer frame area are artificial boundaries that may be created by client computing device as the result of drawing instructions from the CPU being executed by GPU . The dimensions of these areas may be determined by or in light of a particular software title being executed e.g. a video game title utilizing an image capture device or by a server component as might be utilized in an audio visual chat session as is discussed in further detail in . In some embodiments for example in the case of a 4 3 game shown on a 16 9 display the outer frame area may be the extra dead space on the sides of a widescreen display.

Referring to the size of outer frame area is larger than that of the corresponding outer frame area in . Accordingly the inner frame area of is smaller than that of the corresponding inner frame area in . The inner frame area and outer frame area may also be subject to particular user configurations or settings that may be saved on memory card or some other memory device coupled to the client computing device . Inner frame area and outer frame area may be adjusted in response to certain determinations made by client computing device or in response to certain instructions received from another computing device over a network.

In one embodiment of the present invention video game data will be displayed in the inner frame area . This could include image data of the user as might be generated by the image capture device or a derived visual game state based upon the image data of the user. For example the image capture device may capture an image of the user for insertion into a game environment in the form of an avatar. Similarly the image capture device may generate data used to determine whether the user came into contact with a particular portion of the game environment by grabbing at an object or providing input data through a prop device. This real world activity or interaction may be reflected in the game environment as a result of the user for example swinging at a baseball with a baseball bat prop device in an interactive baseball game. An image capture device tracks and captures the swinging of the baseball bat prop device and through the necessary image processors translates that real world activity into on screen display data.

The inner frame area may also be used to display chat session data such as the image of a remote participant communicating with the user. The inner frame area may also display multi media data generated by the remote participant and transmitted to the present user in the form of a textual instant message or a short video clip. Various types of interactive data may also be displayed in the inner frame area such as an interactive game e.g. chess or checkers or a collaborative document e.g. a report that is being concurrently edited by one or more parties .

As has been previously noted image capture device may require certain light levels or light conditions in order for the image capture device to function properly or optimally. If the environment in which the image capture device is operating in lacks sufficient light certain data e.g. user interactions or prop input data may not be detected because the image capture device cannot properly discern various x y z position values color differentiations or otherwise detect motion of a user or object. Image capture device in conjunction with software and or hardware operating internally to the image capture device at the client computing device and or by an intermediate server as is discussed in will determine whether there is proper light present in the environment to properly capture data e.g. with respect to a target histogram . Similar determinations may be made with regard to for example the presence of too much light if the image capture device or a client computing device coupled to the image capture device is configured with an infrared IR receiver to receive commands from a remote control e.g. camera on camera off . Various other spectral emissions may be subject to such user environment light control.

In the context of managing bandwidth consumption as discussed further herein determinations may be made with respect to the presence of too much light or over saturation with respect to a particular color. These excesses may result in spikes in bandwidth consumption when transmitting image or video data captured and or generated by image capture device . Spikes in bandwidth consumption may result in a less than optimal conferencing experience especially in constricted bandwidth environments.

Image capture device in conjunction with the aforementioned software and or hardware operating internal to the image capture device at the client computing device and or by an intermediate server as discussed in may determine for example that too much red light is present in the environment. This light may come from an external source such as natural sunlight through a window proximate the user environment from an artificial lighting source in the user environment e.g. an overhead lamp or from the display device itself. Utilizing the various display and frame adjustment techniques discussed herein certain colors may be muted countered or otherwise cancelled through additive e.g. mixing of red green and blue and subtractive e.g. subtracting a hue out of a color scheme by adding more of another color techniques as are known in color theory.

In the event that there is a determination that insufficient light exists to properly capture image data or that too much light or a particular hue of light exists and is adversely affecting bandwidth consumption the outer frame area may be used to provide additional light to the user environment such that the video display device operates as an artificial light source e.g. certain RGB values of individual pixels in the display display are adjusted as to average a necessary user environment light level . That is the outer frame area will become visibly brightened with a particular color and or intensity of light such that the video display device lights the environment proximate to the image capture device whereby image data may be properly captured for subsequent processing.

For example a user may be utilizing the image capture device to play the aforementioned simulated baseball game with a prop device. As such the user may find an avatar of themselves inserted into the home plate video game environment and displayed in the inner frame area of . If the image capture device and related processing utilities determine that there is insufficient light in the scene environment to properly track the prop device or any other aspect of the user the video game software operating at client computing device may via CPU cause the execution of rendering instructions by the GPU that causes the rendering on the display device of a white filler in the outer frame area i.e. the execution of drawing instructions that causes the individual pixels within the outer frame area to display a particular luminance and or shading . The inner frame area would continue to display the baseball video game and related information while simultaneously becoming surrounded by a white halo in the outer frame area .

This white halo displayed by the video display device will spill into the real world environment of the user that is the light emitted by the display and measured in candelas per meter squared cd m whereby the video display device actually becomes an alternative light source. This additional light generated by the video display device will result in the generation of sufficient additional light to allow for the image capture device to properly capture image data for processing. The intensity of the halo emitted by the outer frame area can be controlled in part by the particular rendering instructions from GPU that is how white what shade of white and how bright the intensity thereof .

Similarly if a particular environment exhibits too much of a particular hue of light such that it is degrading transmission of image data i.e. consuming excess bandwidth the color and or intensity of the halo of the outer frame area and or the inner frame area may be adjusted and manipulated to compensate for the same. In the context of the Munsell color system excess saturation also referred to as chroma of one particular hue red may be countered by a hue of the opposite color blue green . The particular saturation hue combination may be wholly opposite slightly opposite or substantially opposite the excess saturation depending on particular network conditions.

In some embodiments of the present invention the particular hardware configuration of the display device may be taken into account such that the GPU may optimize the resources at its disposal with regard to manipulating the outer frame area and the light emitted by the same. These configurations may be automatically detected by the client computing device or provided to the client computing device through user input as to particular configurations the brand and model of the display device which in turn corresponds to particular operating specifications and so forth. In some embodiments client computing device may consult a look up table or other data store either locally or over a network to identify particular operating capabilities e.g. bit depth for a particular display model if those capabilities are not immediately identified by the user or through certain plug and play PnP functionality.

For example a liquid crystal display LCD in a flat screen television comprises a certain resolution i.e. the number of dots of color pixels on the display referenced by a horizontal axis rows and vertical axis columns . A wide aspect 22 inch LCD monitor may conform to the WUXGA Wide Ultra Extended Graphics Array standard and comprise a resolution of 1920 1200 whereas a smaller device such as a 15 inch LCD monitor may only conform to the XGA Extended Graphics Array standard and comprise a resolution of 1024 768. While an LCD display device is referenced the present invention is equally as applicable to a CRT based display.

Additionally the particular display mode of a video display device determines how many colors that video display device can display. For example a display that is configured to operate in SuperVGA mode can display 16 777 216 colors also known as true color the result of a 24 bit long description of a pixel the bit depth . For example in 24 bit bit depth eight bits are dedicated to each of the three additive primary colors RGB . The bit depth therefore determines the number of colors that can be displayed at one time. To create a single colored pixel an LCD for example uses three sub pixels with red green and blue filers. Subject to the control and variation of the voltage applied the intensity of each sub pixel can range over 256 shades. Combining the sub pixels produces a possible palette of 16.8 million colors 256 shades of red 256 shades of green 256 shades of blue .

The brightness of the light emitted into the user environment can also be affected by the size of the outer frame area relative the inner frame area . Returning to by filling the outer frame area with white image data a certain degree of luminance may be created. Identical white image data i.e. the same intensity and shade in however will create a greater degree of luminance in that the outer frame area of is larger than that of . Thus the amount of light that is generated by the video display device though a halo may be dynamically controlled during the use of image capture device .

For example the image capture device and related client computing device may be in a room with a window in the late afternoon. While there may be sufficient natural light to support image data capture at the time game play commences as the afternoon continues and the natural light source begins to disappear i.e. the sun sets there may be insufficient light for the image capture device to properly continue to capture image data. The outer frame area may at that point be illuminated as a white halo to provide the additional light necessary to allow for game play to continue. The intensity of the light as noted may be controlled by the client computing device that may be running game software that has been calibrated with the image capture device to determine when the proper amount of light is present to allow for the game to function as intended. In that regard requisite light settings may be predetermined or calibrated based on the particular game and or user environment.

As natural light continues to disappear throughout the course of the day the intensity of the artificial light source emitted from the display device may be gradually increased. For example a dull gray light source in the outer frame area may provide sufficient light at 4 00 PM but a flat white emission may be required from the outer frame area at 6 00 PM. The intensity of the light may also be increased e.g. the brightness of the light . At some point the limitations of the video display device may be such that even the most intense white available does not provide sufficient artificial light to allow game play to continue. At that point the GPU may cause for the size of the inner frame area to decrease and the outer frame area to increase thereby providing additional artificial light i.e. additional individual pixels in the screen display utilized for illumination purposes versus the display of game data . The dynamic adjustments described above and in the context of maintaining proper lighting conditions in a user environment are equally applicable in the context of bandwidth management.

In some instances particular portions of the user environment may be subject to insufficient lighting conditions. For example the right side of a room may have an open window whereby sufficient light may be provided to allow for image data capture. The left side of the room however may have window shades drawn such that no natural light may be entering that portion of the user environment. The orientation of the inner frame area and outer frame area may be adjusted such that the inner frame area may be moved to the far right hand side of the video display device whereby the inner frame area may be off center but providing a larger focused outer frame area on the left side of the display such that additional artificial light may be generated by the video display device . The positioning and centering of the frame areas and may be dynamically adjusted as use of the image capture device continues.

Alternatively particular gradations of color from one side of the display to another may be implemented wherein the orientation of the inner frame area and the outer frame area may remain constant. In the aforementioned example where the left side of a room is darker than the right the portion of the outer frame area relative the left side of the room may emit a white light while the right side of the outer frame area displays a neutral background color in that sufficient natural light is present on the right side of the room. A gradual gradation of color from white to black between the left side of the outer frame area to the right side may bridge the two sides of the outer frame area .

Particular portions of the outer frame area or other frame areas in the case of multiple frames surrounding the inner frame area may be subdivided into various sub sections. Each of those sub sections may be subject to various lighting controls. For example the outer frame area may be sub divided into four quadrants an upper right upper left lower right and lower left quadrant. Each of those individual quadrants may be subject to various lighting controls e.g. the upper right and lower left corner of the frame may be illuminated while the upper left and lower right are not . These various controls include color luminance and any other condition that may be controlled by the various systems and methods disclosed herein.

The various sub divisions may also be subjected to various shapes for both functional and aesthetic reasons. For example instead of squares and rectangles various triangle or other polygonal configurations may be implemented. Various circular or elliptical patterns may also be used. These and any other shape or design capable of being displayed e.g. lines squiggles waves dots splotches etc. may be uniformly or randomly displayed as a group or with a variety of shapes and each object subject to lighting control. Various shapes and patterns may also be subject to strobing i.e. regular controllable series of high power flashes rather than continuous light for a variety of effects.

For example strobing may be used to create a strobe light feature in the user environment or similarly to counter an effect caused by natural or other artificial light conditions in the user environment. Certain video games or television programs that may cause epileptic fits feelings of vertigo and the like and that might be displayed in the inner frame area may be countered through a counter strobe effect in the outer frame area . In that regard the presently described lighting controls systems and methods may also be implemented with traditional television programming in addition to chat sessions and video games.

As noted certain calibrations may take place through the image capture device . The image capture device may at start up sample the user environment to determine various lighting conditions and the effect those conditions will have on image capture over a particular operating range e.g. lowest possible range of capture to an optimal range of capture . The image capture device in conjunction with the various lighting controls discussed herein as implemented by various hardware and or software operations may then adjust certain user environment lighting conditions through inner frame area and outer frame area lighting manipulations e.g. size brightness orientation color . During the course of these adjustments the image capture device may re sample the environment to determine what environmental control condition will allow for a particular operation of a game or chat session in light of the particular environment.

The client computing device in conjunction with particular chat or video game software may make that determination or such a determination may come as a result of a management server determination as is described in the context of . Similarly the determination of a particular user environment condition may come from a user in another environment if that particular user is unable to properly view the first user in a chat session. That decision by a second user may be made by selecting an available environment setting in light of several environmental control conditions.

For example during the start up calibration the first user environment may be subject to three different intensities of a particular color of light three different colors of light and three different frame area sizes. The image capture device may capture an image of each of those nine possible environments. The effect of that particular environment control may then be displayed to the second user in the form of a still frame or even a short e.g. 5 second video clip. The second user may then select the particular environment control based on the image or clip that appears best. A user operating in a solo environment e.g. playing a video game may select a particular environmental control in a similar fashion.

These calibrations or adjustments may occur at start up of a game or chat session or may occur dynamically during the session. For example adjustments may occur automatically during game play or at breaks such as between levels. Adjustments may further occur in response to a user action wherein a query may be made such as during a pause. In some embodiments a particular frame of data e.g. an I frame may indicate the propriety and need to readjust lighting conditions in the user environment.

Similarly particular frames of data may be recognized during the decoding process as likely to cause certain changes in the user environment. For example incoming image data of a conference remote participant may consist of a bright white background that will spill into the user environment thereby causing an unintended change in user environment lighting conditions. These environment changing conditions may be identified in advance such that when the actual image data may be rendered that video display device will have already adjusted an inner frame area and or outer frame area as may be appropriate such that no adverse affect or change to the user environment occurs.

It should be noted that in some embodiments of the present invention the outer frame area may always be present but simply unutilized i.e. a neutral background color such as black . The frame area may then be filled as needed in response to GPU executing a drawing instruction from the CPU . In other embodiments the actual graphic images to be displayed may occupy the majority of the game screen and as such only the inner frame area may be displayed. If and when an artificial light emission is necessary from a halo generated by the outer frame area the software executed by the CPU and otherwise controlling the display of the frame areas and and interacting with the image capture device may cause the GPU to reconfigure the game environment e.g. re size the game environment to fit in a small inner frame area such that the outer frame area may now be displayed and emit the appropriate halo of artificial light.

The re sizing of the various frame areas may occur during the course of game play e.g. the re sizing occurs as game play progresses . Alternatively the re sizing may occur only during pauses in game action such as to avoid the size of the environment and various characters changing while game play is occurring i.e. to avoid a vertigo type effect . Additionally re sizing may actually cause an automatic pause in game play with a query issued to the user as to whether re sizing is permitted. In these instances the amount of natural light may be sufficient to allow game play to continue but not without some processing errors. If game play deteriorates to the point that additional light is necessary the user may be asked whether they wish to activate the illumination control feature of the present invention. If not e.g. the user does not wish to minimize the size of the actual game environment in the inner frame area the user may manually provide another source of artificial light through for example an overhead lamp or other light source in the actual user environment. Various user input may be provided through for example controller in addition to other inputs such as voice recognition.

In some embodiments different colors or shades of colors may also be utilized to maximize the color balance of a particular user environment. For example a user may have different light sources offering different colors of light. These varying colors may cause difficulty with the image capture device processing environment information especially with regard to color differentiation. In these instances the image capture device may identify irregularities or processing difficulties in the environment in a manner similar to the identification of a lack of sufficient light. The outer frame area may used in a similar manner as to produce different colors and intensity of light to counterbalance certain overexposures in the particular environment. In some embodiments additional frame areas may be used e.g. a third fourth or fifth frame area such that combinations of certain colors e.g. yellow and blue individual halos to create an overall green appearance may be implemented.

In the outer frame area has been filled such that it now reflects white light halo as referenced in the context of . The inner frame area has also been reduced in that the lighting conditions in the environment of the user receiving the present image have made it necessary to increase the amount of light emitted into that environment. As such the outer frame area was expanded at the expense of the inner frame area .

In some embodiments of the present invention the inner frame area may need to be reduced in that the graphic data in the inner frame area is inadvertently creating excess light and thereby over saturating the user environment. For example in the aforementioned baseball game example if the user hits a home run the image displayed may pan upward to the sky to follow the path of the baseball as it travels toward the outskirts of the ballpark. As the scene pans toward the sky the screen display will become predominantly white and gray i.e. colors of the sky and clouds . These bright colors may spill into the user environment which may cause image data capture difficulties. In response to such a situation the inner frame area may decrease in size to reduce the amount of secondary light spillage into the user environment. Additionally the outer frame area may be darkened to help counter suddenly excess bright light being emitted from the inner frame area .

In step an image capture device may attempt to capture image data from a user environment. In step a determination may be made whether adverse lighting conditions are inhibiting the processing of the image capture data or the actual capture of the data. If there are no adverse conditions present and the image data is captured and processed without incident image data capture proceeds as necessary followed by subsequent processing of the data.

If it is determined in step that adverse lighting conditions do exist an attempt may be made to adjust display intensity in step . This may occur through various adjustments whereby the outer frame area may be filled with a particular color and intensity of light as discussed in the context of and A and B above. If the adjustment as to display intensity is not sufficient then in step frame image boundaries may be enlarged or reduced as is appropriate in order to increase or decrease the total amount of artificial light projected into the user environment.

While step and the adjustment of frame boundaries is recited as following step and the adjustment of light intensity this is not to suggest the necessity of a step by step process. Both adjustments may occur concurrently or frame adjustment may occur prior to intensity adjustment in that is an exemplary embodiment only. Regardless of the order following the adjustment of image intensity and or frame boundaries further attempts at image capture and or image data processing occur as the method repeats or continues as is appropriate in step .

As discussed in U.S. patent application Ser. No. 11 624 886 the control of lighting conditions in a user environment may be associated with bandwidth and processing availability. In MPEG compression images are represented in YUV color space YCbCr wherein 24 bits per pixel are present 8 bits for luminance Y and 8 bits for each of the two chrominance U V elements. The chrominance information in the YUV color space data may be sub sampled in both the horizontal and vertical direction. All of the luminance information may be retained however as the human eye is more sensitive to luminance information rather than chrominance information. Frames of video are subsequently divided into 16 16 macro blocks consisting of four 8 8 luminance blocks and two 8 8 chrominance blocks 1 U and 1 V .

Each frame of video data may then be encoded as one of three types of frames intra frame I frames forward predicted frame P frames and bi directional predicted frames B frames . In the case of an I frame the frame may be encoded as a single image with no reference to past or future frames. Further with the exception of data quantization following the encoding of each 8 8 block from a spatial domain to a frequency domain utilizing the Discrete Cosine Transform DCT and the aforementioned sub sampling there is no lossy compression in an I frame especially with regard to luminosity. The other frame types P frames relative a past reference frame and B frames relative a past reference frame a future reference frame or both refer to the I frame. Thus decreasing certain luminosity information in the I frame would represent savings with regard to the all of the frames in a stream of video data.

In this regard the image data captured from the user environment could be accepted at the lowest possible operating condition. That is lighting controls would illuminate a user environment no more so than necessary in order to reduce the amount of luminosity data being captured compressed and subsequently transmitted over a network. This decreased luminosity data represents not only savings in bandwidth at a transmitting computing device a receiving computing device and over the network backbone but can also recognize a savings with regard to processing cycles at a computing device perform digitization and compression following image capture.

Similarly certain colors captured from a particular user environment may be captured and or cancelled out by adjusting display emissions and or frame boundaries as discussed above. For example in the context of a YUV 4 4 4 environment where Y pertains to luminance brightness and U and V are chrominance color components each channel is expressed with 8 bits 256 possible values and uses the same amount of space. As noted above the human eye is most sensitive to luminance the black and white information in picture detail. Less sensitive areas of the human eye fill in color. That is color information may be reduced without the human eye noticing the same. Thus the chrominance components U and V may be reduced without the human eye adversely noticing the same. Bandwidth consumption may be reduced by adjusting chrominance information.

For example the environment may be effectively captured at or manipulated to conform to the equivalent of 4 2 2 format whereby the chroma components are sampled at half the rate of luma thereby reducing bandwidth of the signal by as much as one third with little or no perceptible visual difference. Specifically red and blue channels of the video signal may be half the bandwidth of the luminance information. For example green may be cancelled out as green can be calculated from red and blue chrominance information in the context of luminance information.

A utility related to preservation of bandwidth and processing power vis vis the image capture device and or related hardware or software may be manually implemented by a user. For example a user may recognize that their particular computing device lacks accelerated processing power or may be coupled to a low bandwidth network or similarly that a recipient of data captured by the image capture device suffers from similar limitations. In these instances the user may activate such a utility to avoid bottlenecks of data.

Similarly this preservation utility may be implemented on an as needed basis the need being recognized by a network congestion monitoring utility like ping which utilizes the Internet Control Message Protocol ICMP and trace route which utilizes the Uniform Datagram Protocol UDP to measure network response time. These and other network utilities may be implemented in various network devices e.g. switches or routers or through large scale platforms like the Network Application Performance Analysis Solution NAPAS for Cisco Systems. Indicia of network congestion generated by these applications and solutions may be provided to a computing device operating certain software related to image capture e.g. a client computing device or a conference management server such that bandwidth and or processor preservation may be activated through the manipulation of lighting conditions that are not optimal but otherwise sufficient to allow for continued image data capture.

In certain embodiments wherein one end of a video data exchange degrades a particular lighting condition for the purposes of improved processing or transmission time the recipient of that data may adjust the incoming video data such that it does not appear as lesser quality image data. For example the incoming video data may be pre processed such that luminance that was degraded by the sender of the data may be artificially amplified by the recipient through editing or video pre processing editing software that automatically adjusts the data as it is decoded and rendered.

In step the bandwidth being consumed by image capture data transmitted over a network as may occur in the context of a video chat session like that described in below is made. A determination of bandwidth may be made utilizing for example the aforementioned NAPAS or simpler methodologies such as ping and trace route. The determination may occur at the transmitting computing device at the receiving computing device or at some intermediate computing device or at some other point in a communications network. The information may then be provided to the transmitting device such that it may adjust its image capture operations as is appropriate and is discussed in the context of steps and . Alternatively another device may make certain determination as to bandwidth consumption and provide instructions to the transmitting computing device such that it may responsively adjust its image capture operations as may occur through screen and or frame adjustment.

In step a determination is made as to whether image capture data that is being transmitted over a network exceeds a particular bandwidth limitation. The particular bandwidth may be a static predetermined amount e.g. a target threshold . That static threshold may be manually set by a user or network administrator. The static threshold may also be identified at the outset of a chat session and remain constant throughout the session. Alternatively the amount may be determined in the context of a particular video chat session and may change during the course of the chat session. That is as network conditions change from the beginning to the end of the session and at various points in between the target threshold may be adjusted subject to those changing network conditions.

In one example two users chatting over a dedicated corporate network for such communications may be unlikely to encounter other users or applications attempting to utilize the same finite amount of bandwidth in the network. As such even if captured image data consumes large amounts of bandwidth the availability of large amounts of network overhead may obviate the need to otherwise adjust network traffic consumption. On the other hand if two users are chatting over a public network shared by other users at a peak traffic time even image capture data that is normal under the circumstances may exceed a particular bandwidth allotment or may otherwise encounter transmission difficulties due to other users and applications sharing the network. Further if a chat session commences amongst a group of fifteen participants bandwidth consumption may initially be high with respect to the group and available resources. As participants drop out of the conference e.g. their presence is no longer required the total bandwidth consumption may decease and what constitutes an excessive use of bandwidth for any one user may change as additional resources become available to the session.

If a determination is made that image capture data does not exceed a particular bandwidth either predetermined or determined in a dynamic fashion then measurement continues in step . Measurement of bandwidth consumption may occur at predetermined times during the chat session e.g. every five minutes . Measurement may also occur upon the occurrence of a particular event for example transmission of the I frame or every nI frame. When and how often measurement occurs may also be set by the user or a network administrator.

If it is determined that image capture data being transmitted over the network exceeds a particular bandwidth limitation adjustment of display intensity and frame boundaries may occur in steps and These particular adjustments may be similar with respect to the display and frame adjustments that occurred in steps and in the context of . Like adjustment of display intensity and frame boundaries are not necessarily a step by step process. Both adjustments may occur concurrently or frame adjustment may occur prior to intensity adjustment. Further only one particular adjustment i.e. frame but not display may occur.

Lighting adjustment sources other than or in addition to the screen and a frame area within the screen may be utilized in the context of managing bandwidth consumed by image capture data. For example an external light source may be coupled to a device controlling lighting emissions e.g. client computing device of . This coupling may occur in the context of a USB connection or other data connection. The external lighting device may be proximate to or otherwise remote from the actual image capture device and related computing device so long as the light source may be configured to result in some influence of the lighting conditions of a particular user environment. Some lighting control hardware may be integrated with particular display device such as a backlight or other ambient light projector.

Systems may comprise an exemplary system like that disclosed in . In that regard such a system may comprise an image capture device a video display device and a client computing device having processor functionality. Systems would be placed in the context of a user environment such as a living room or a conference room which would be located within the field of view of the image capture device.

Systems may each be running software for facilitating a video conference or video chat session or otherwise related to a particular video game involving image data capture. The exchange of data between systems may be limited to video images and accompanying audio. The session may further comprise additional ancillary data such as textual exchanges e.g. closed captioning various in conference applications such as an enterprise application allowing for collaborative development between multiple users e.g. a word processing document or presentation slide video games that may be played on line during the session or other multi media applications e.g. a media player . These data exchanges are in addition to various session protocols related to establishing and maintaining the exchange of conferencing and other related data.

Through the aforementioned software which may be accessed through optical disk control unit the network adaptor may initiate a conferencing session through for example Ethernet connection over the aforementioned network . Image data and related audio data may be captured through the aforementioned image capture device which may be coupled to the system via for example USB interface . GPU in turn executes various drawing instructions related to not only the actual conferencing data e.g. user images but also the inner frame area and outer frame area and related illumination control commands e.g. filling the outer frame with a particular intensity and color whereby lighting conditions of a particular environment may be controlled. Instructions related to control of lighting conditions in the particular environment may be a part of the video conferencing software executed by each system or at server .

Systems may also be configured to manage bandwidth consumption based on certain bandwidth measurements taken by each system . Bandwidth measurements may also be taken by a third party application or remote computing device e.g. server and reported to each system . Systems may adjust certain lighting conditions through screen and frame adjustments in response to local determinations made with respect to network conditions and bandwidth consumption. Alternatively systems may be configured to receive instructions from a remote computing device such as server or another conference participant s computing device and adjust certain user environment lighting conditions in response to the same.

In some embodiments of the present invention address book data may be stored on a removable data storage device as may be accessed through memory card interface . This address book data may be related to other users of the present video conferencing chat system . The conferencing software may also include certain security features or parental controls to ensure that under age children do not access the system or are limited to sessions with particular pre approved conferees. Such information may also be stored on the aforementioned memory device. Conferencing software may further facilitate the generation of video mail such as a 30 second full motion video. Software may further facilitate entry into various chat rooms or interaction with certain applications such as video games.

Communications network comprises various communications facilities and mediums e.g. telephony wireless satellite cable optic and so forth as may be provided by telecommunications companies and Internet Service Providers. Communications network may be a geographically widespread network e.g. a Wide Area Network WAN like the Internet that depends upon the aforementioned communications facilities to link various network segments. In that regard a WAN may ultimately be comprised of smaller linked communications networks such as Local Area Networks LANs . A LAN is typically comprised of a group of computers and other devices dispersed over a relatively limited area and connected by for example a variety of broadband communications links. LANs may take on a variety of configurations including server client peer to peer peer groups or a combination of the same. Communications network may also be a closed proprietary network.

In some embodiments of the present invention a conferencing management server may be utilized to conduct various video conferences or other user interactions. For example system may actually connect with server server will then create a connection with system and a chat session may commence. Server may provide various network controls such as connection acceptance session initiation and termination bandwidth management conference recording e.g. recording the conference session or a transcript of the same for future access managing chat rooms or group sessions e.g. sessions involving more than two participants facilitating certain data exchanges ancillary to the actual conference e.g. documents presentations video games and also ensuring proper control of lighting conditions in a particular user environment.

In the latter example the server may monitor lighting conditions in the conferencing environment of each system and adjust certain frame settings through the necessary drawing instructions such that proper lighting conditions are maintained at both ends of the conference. In this regard server may actually provide the drawing instructions for execution by the appropriate system to fill a frame or adjust the size of the same. Server may also receive various indications from each system concerning the quality of lighting conditions at the other system and facilitate adjustments as is appropriate by communicating the various indications to various participant devices.

Server may also manage bandwidth consumption in a similar fashion through the control of lighting conditions in various user environments. Server may include a bandwidth measurement application for measuring such conditions and responding in an according fashion i.e. adjusting lighting conditions in a user environment through screen and or frame adjustments . Server may alternatively receive information from each system or a third party application in the communications network concerning various network conditions and bandwidth consumption of the same. Measure of bandwidth conditions may occur over a network at the origin and or destination of video conference chat information at the server as well as at and between various hops in network . Server may adjust lighting conditions to allow for bandwidth consumption control in response to a measurement at one or more points in the network as may be deemed appropriate in response to certain measurement information.

Server may also host the necessary software for the conference to take place. In such an instance the systems may comprise only minimal application data necessary to contact the server to indicate the desire to participate in a conference session. Critical conferencing architecture software and execution of the same may then occur at the server which may have considerably more processing power than the end user device e.g. an entertainment system . By leaving heavy processing to the more powerful conferencing server like server conferencing exchanges do not slow down or experience jitter due to processing delays at the various end users and their related computing devices. In some embodiments of the present invention like those utilizing a high speed processing model as disclosed in U.S. patent publication number 2002 0138637 for a Computer Architecture and Software Cells for Broadband Networks server may also manage various distributed computing operations.

While the present invention has been described with reference to exemplary embodiments it will be understood by those skilled in the art that various changes may be made and equivalents may be substituted for elements thereof without departing from the true spirit and scope of the present invention. In addition modifications may be made without departing from the essential teachings of the present invention. Various alternative systems may be utilized to implement the various methodologies described herein and various methods may be used to achieve certain results from the aforementioned systems. Certain methodologies and benefits discussed in the context of lighting control of a user environment for detection of user interactions may be equally as applicable to controlling bandwidth consumption with respect to captured and transmitted image data and vice versa.

The steps of the processes disclosed herein and various alternatives of the same may be embodied in hardware or software. Such embodiments may include a computer readable medium such as an optical disc memory card carrier waves and the like. Such mediums may include instructions executable by the processor of a computing device.

