---

title: Network-network interface
abstract: In one embodiment, a method includes receiving at a first portal of a first node data for communication from a first network to a second network that belong to a particular one of a first set of service classes of the first network; determining at the first portal a particular one of a second set of service classes of the second network for the data; and directing the data from the first portal to a second portal of a second node residing at least in part in the second network.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08850015&OS=08850015&RS=08850015
owner: Cisco Technology, Inc.
number: 08850015
owner_city: San Jose
owner_country: US
publication_date: 20110126
---
This application claims the benefit under 35 U.S.C. 119 e of U.S. Provisional Patent Application No. 61 298 455 filed 26 Jan. 2010 which is incorporated herein by reference.

Separate providers networks commonly referred to as clouds are interconnected via Network Network Interfaces NNIs to create networks spanning vast geographic areas so that providers may offer services that cannot be offered by any single provider. In order to achieve the fastest reaction to node or link failures some form of protection switching is common. Buffer networks are networks whose physical topology configuration enable it to guarantee even in the face of some number of node or link failures to proved connectivity among all of its NNIs.

In one embodiment a method includes receiving at a first portal of a first node data for communication from a first network to a second network that belong to a particular one of a first set of service classes of the first network. The first node resides at least in part in the first network and includes a first edge and the first portal. The first edge includes a logical or physical partition of the first node configured to provide network resources for the first network. The first portal includes a logical or physical partition of the first node configured to provide network resources for a buffer network between and logically or physically separate from the first and second networks. The first node terminates in the first network one of two or more links between the first network and the second network. The buffer network includes two or more of the links between the first and second network. The method also includes determining at the first portal a particular one of a second set of service classes of the second network for the data. The method also includes directing the data from the first portal to a second portal of a second node residing at least in part in the second network. The second node includes a second edge and the second portal. The second edge includes a logical or physical partition of the second node configured to provide network resources for the second network. The second portal includes a logical or physical partition of the second node configured to provide network resources for the buffer network. The second portal of the second node is designated to carry into the second network through the second edge data belonging to the particular one of the second set of service classes.

In another embodiment a method includes for each of two or more links connecting a first network and a second network with each other identifying a first node terminating the link in the first network and a second node terminating the link in the second network. The first network has a first set of service classes and the second network has a second set of service classes. The method also includes for each of the first and second nodes identifying an edge that includes a first logical or physical partition of the first or second node configured to provide first network resources for the first or second network and a portal that includes a second logical or physical partition of the first or second node configured to provide second network resources for a buffer network between the first and second network. The buffer network includes two or more of the links between the first and second network. The method also includes establishing the buffer network with the portals. The buffer network is logically or physically separate from the first and second networks and is configured to receive at a portal of one of the first nodes data for communication from the first network to the second network that belong to a particular one of the first set of service classes determine a particular one of the second set of service classes for the data and direct the data to a particular one of the portals of a particular one of the second nodes that is designated to carry into the second network through its corresponding edge data belonging to the particular one of the second set of service classes.

Service providers may require interfaces between their networks called Network Network Interfaces NNIs so that data transport services can be sold jointly or by subcontract that may not be offered by any single provider. For example a service connecting Paris Caracas and San Diego may require the joint efforts of several providers. In particular embodiments the problems in defining an NNI may relate to one or more of the following 

In particular embodiments there may be any number of schemes for NNIs mostly based on particular transport technologies. However these schemes may suffer from one of the following issues 

In particular embodiments this disclosure may refer to a link a node a portal a terminus a cloud and a NNI. In particular embodiments a link may include a single physical link connecting two or more nodes. For example a link may connect two nodes. In particular embodiments a link may belong to two networks but in that case both ends may be in both networks and any packet on that link may exit the link on the same network on which it entered. For example a link may be physical or logical and may belong to exactly one network and a node in two networks may connect to another node in the same two networks with a single physical link that is two logical links one in each network. In particular embodiments a link may not interconnect two networks. In particular embodiments a node may include a switch or router connected to other nodes via links belonging to either one or two networks and either zero or one portals. In particular embodiments a portal may include a collection of one or more nodes each of which may belong to the same two networks and which may be configured together as a portal and known as such to each of the networks. For example a portal may be shared by exactly two networks at least one of which may be an NNI not a cloud. In particular embodiments a terminus may include the point at which a service makes the transition from one network to the other in a node in a portal. In particular embodiments a cloud may include a service provider s network. The network may have links and nodes. In particular embodiments any given node may belong to one portal and thus may belong to a second network. In particular embodiments there may be no assumptions about the data transport technology routing technology if any or protection switching technology if any used by the cloud. For example such considerations may be by definition opaque to the NNI. However in particular embodiments the cloud may provide certain guarantees and may interact with the routing protocol s running the NNI.

In particular embodiments a NNI may include a cloud that consists of exactly two portals with all nodes in portals. For example an NNI can thus connect together two clouds. In particular embodiments the requirements for an NNI are a strict subset of the requirements for a cloud. In particular embodiments some of the NNI s nodes belong to one cloud and the rest belong to the other cloud. In particular embodiments there can be links among the nodes of one portal that belong to the NNI and there can be links between nodes belonging to different portals also belonging to the NNI. In particular embodiments the NNI runs a protection switching or routing protocol which may provide certain critical guarantees.

In particular embodiments any number of clouds may be stitched together by NNIs. Chains of NNIs may be possible. A service can be configured as a path from endpoint to cloud to NNI to cloud to NNI where to cloud to NNI may be repeated any suitable number of times to cloud to endpoint. In particular embodiments this may be perfectly equivalent to defining a service in terms of a linear chain portals. In particular embodiments this may be applied in point to point services or any other suitable services. In particular embodiments a multipoint to multipoint service may be a tree of clouds and NNIs or equivalently a tree of portals.

In particular embodiments this disclosure may enable one to provision a service as a single linear sequence or tree of clouds and NNIs or portals rather than as a set of multiple end to end paths that may provide fault isolation in all three senses 

In particular embodiments the guarantees that a network can provide may be split into two classes one for the cloud and one for the NNI. Furthermore the interaction required between the clouds routing protocols and the NNIs routing protocols may be defined. In particular embodiments aspects of this disclosure may be centered around the difference between the terminus and the portal.

In particular embodiments a cloud may guarantee to provide continuity and QoS etc. for each service even in the event of some number of failures of nodes or links from some terminus in each configured portal to some service in each other configured portal and to any endpoints in the cloud . In particular embodiments when responding to a failure a cloud may have to move one or more termini from one node within a portal to another node within that same portal. For example the cloud may control the assignment of termini to nodes within a portal.

In particular embodiments an NNI may guarantee to provide connectivity for each service from terminus to terminus even in the event of some number of failures of nodes or links or reassignment of termini to nodes by its attached clouds.

In the four nodes with two links guarantee delivery from network to network even if one of NPIs and fail. In particular embodiments protection switching such as for example by IEEE methods like IEEE MAC in MAC or IETF methods like IETF VPLS may involve pre provisioning a set of alternate paths among endpoints. In order to guarantee connectivity against any single failure in a network connecting N endpoints N N 1 2 pre provisioned paths may be required. In a network with P portals each averaging D nodes per portal O D P 2 paths may be required. In particular embodiments reducing the problem to saying that the cloud only has to interconnect portals and may result in a reduction to 2 paths in this example NPIs and . However the arrangement in couples failures of a single NPI to both networks. illustrates this problem.

In particular embodiments if all networks and NNIs were made this way a failure of red network in a cloud would trigger all services to shift to blue network . All services both red and blue would be routed through blue network and NPI . However the red terminus must change in both network cloud and network cloud . Accordingly this may require the adjacent NNI to use only its blue network and this would ripple through until all networks were using only the blue half. In particular embodiments there would be no fault isolation at all.

In an NNI O D P 2 paths may be required to guarantee connectivity among all nodes. In particular embodiments P 2 and there are no terminal nodes to account for. So the number of paths can be quite manageable such as for example 8 for two nodes per portal . In particular embodiments reassigning termini may be an added complexity when the left cloud reassigns a terminus to another node this fact may be signaled to the nodes in the other portal so that they can switch paths. In particular embodiments this may not increase the number of required pre provisioned paths but may add the requirement for a a terminus moved signal to be used by the NNI s routing protocol and b a means for the cloud s routing protocol to signal the terminus change to the NNI s routing protocol. Clearly this may take some small additional time but that may be as far as the chain of consequences from a fault recovery action can go. In particular embodiments this may result in a requirement being put on the NNI that has a very high per node cost and a high interconnectivity requirement but may restrict the NNI to a small number of nodes so that cost is not too high. Furthermore a greatly relaxed requirement may be put on the NNI which it can meet in spite of having a large number of portals. In particular embodiments the NNIs may serve as fault insulators between the clouds.

In particular embodiments large complex provider networks running relatively cheap fault recovery protocols clouds may be interconnected using small simple networks running relatively expensive fault recovery protocols NNIs by introducing the ability of the cloud to move the cloud NNI handover point terminus from one network node to another. In particular embodiments this may allow a service to span a global network of provider clouds with all the advantages of fault isolation but without the issues inherent in constructing alternative end to end multi network paths.

In particular embodiments the routing mechanism added by buffer network is the ability of a portal node in buffer network to be told by the adjacent network that the NNI connecting them is not the preferred NNI for a bundle of services and for that information to be relayed to other portals so that all involved portal nodes can change segments. For example if a bundle is using the NNI odd numbered services and for reasons not apparent to any node in buffer network network elects to move that bundle to the NNI perhaps due to failure or congestion . Whether network notifies portal node that its NNI is the new choice or whether it notifies portal node of that fact or both notifications take place node or node or both must somehow inform node and node of that change. Each bundle moved in network can affect a number of bundles in buffer network .

In particular embodiments a portal node can multicast a notification in the data plane to all portal nodes in buffer network through one or more control paths reserved for that purpose and repeat it to ensure delivery. In particular embodiments each portal node could flood frequent updates either in the data plane or hop by hop through portal nodes giving its opinion of all bundle NNI bindings. In particular embodiments some combination of techniques to ensure both long term synchrony of the NNI bundle information and provide fast fault reaction such as hop by hop updates along with the data plane multicasts of events.

In particular embodiments each node in buffer network exchanges connectivity check messages with all other nodes in buffer network . The connectivity check messages allow each node to know the state of each segment so that every node is aware when a segment has failed. In particular embodiments the connectivity check messages CCMs used to diagnose the connectivity of buffer network s segments carry information about NNI usage.

In particular embodiments fault recovery reconciliation is solved by providing a mechanism for networks to make NNI primitives for communication between buffer networks and networks. In particular embodiments failure propagation is limited in that although failure in a network can cause that network to alter NNI assignment within one or more portals and thus cause a recovery action in the adjacent buffer network those buffer networks cannot propagate the failure action any further because they cannot alter the NNI assignments. In particular embodiments the use of buffer network allows each network to decide how to apportion bundles of services to an NNI within each portal and forcing buffer network to rebundle services so that each service in a buffer network bundle is the same bundle in each of the attached networks. In particular embodiments buffer network is jointly managed by network providers providing network and . In particular embodiments buffer network obtains its NNI bundlings from networks and themselves. In particular embodiments buffer network is managed by only one of the network owners providing networks and .

This disclosure contemplates any suitable number of computer systems . This disclosure contemplates computer system taking any suitable physical form. As example and not by way of limitation computer system may be an embedded computer system a system on chip SOC a single board computer system SBC such as for example a computer on module COM or system on module SOM a desktop computer system a laptop or notebook computer system an interactive kiosk a mainframe a mesh of computer systems a mobile telephone a personal digital assistant PDA a server a tablet computer system or a combination of two or more of these. Where appropriate computer system may include one or more computer systems be unitary or distributed span multiple locations span multiple machines span multiple datacenters or reside in a cloud which may include one or more cloud components in one or more networks. Where appropriate one or more computer systems may perform without substantial spatial or temporal limitation one or more steps of one or more methods described or illustrated herein. As an example and not by way of limitation one or more computer systems may perform in real time or in batch mode one or more steps of one or more methods described or illustrated herein. One or more computer systems may perform at different times or at different locations one or more steps of one or more methods described or illustrated herein where appropriate.

In particular embodiments computer system includes a processor memory storage an input output I O interface a communication interface and a bus . Although this disclosure describes and illustrates a particular computer system having a particular number of particular components in a particular arrangement this disclosure contemplates any suitable computer system having any suitable number of any suitable components in any suitable arrangement.

In particular embodiments processor includes hardware for executing instructions such as those making up a computer program. As an example and not by way of limitation to execute instructions processor may retrieve or fetch the instructions from an internal register an internal cache memory or storage decode and execute them and then write one or more results to an internal register an internal cache memory or storage . In particular embodiments processor may include one or more internal caches for data instructions or addresses. This disclosure contemplates processor including any suitable number of any suitable internal caches where appropriate. As an example and not by way of limitation processor may include one or more instruction caches one or more data caches and one or more translation lookaside buffers TLBs . Instructions in the instruction caches may be copies of instructions in memory or storage and the instruction caches may speed up retrieval of those instructions by processor . Data in the data caches may be copies of data in memory or storage for instructions executing at processor to operate on the results of previous instructions executed at processor for access by subsequent instructions executing at processor or for writing to memory or storage or other suitable data. The data caches may speed up read or write operations by processor . The TLBs may speed up virtual address translation for processor . In particular embodiments processor may include one or more internal registers for data instructions or addresses. This disclosure contemplates processor including any suitable number of any suitable internal registers where appropriate. Where appropriate processor may include one or more arithmetic logic units ALUs be a multi core processor or include one or more processors . Although this disclosure describes and illustrates a particular processor this disclosure contemplates any suitable processor.

In particular embodiments memory includes main memory for storing instructions for processor to execute or data for processor to operate on. As an example and not by way of limitation computer system may load instructions from storage or another source such as for example another computer system to memory . Processor may then load the instructions from memory to an internal register or internal cache. To execute the instructions processor may retrieve the instructions from the internal register or internal cache and decode them. During or after execution of the instructions processor may write one or more results which may be intermediate or final results to the internal register or internal cache. Processor may then write one or more of those results to memory . In particular embodiments processor executes only instructions in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere and operates only on data in one or more internal registers or internal caches or in memory as opposed to storage or elsewhere . One or more memory buses which may each include an address bus and a data bus may couple processor to memory . Bus may include one or more memory buses as described below. In particular embodiments one or more memory management units MMUs reside between processor and memory and facilitate accesses to memory requested by processor . In particular embodiments memory includes random access memory RAM . This RAM may be volatile memory where appropriate Where appropriate this RAM may be dynamic RAM DRAM or static RAM SRAM . Moreover where appropriate this RAM may be single ported or multi ported RAM. This disclosure contemplates any suitable RAM. Memory may include one or more memories where appropriate. Although this disclosure describes and illustrates particular memory this disclosure contemplates any suitable memory.

In particular embodiments storage includes mass storage for data or instructions. As an example and not by way of limitation storage may include an HDD a floppy disk drive flash memory an optical disc a magneto optical disc magnetic tape or a Universal Serial Bus USB drive or a combination of two or more of these. Storage may include removable or non removable or fixed media where appropriate. Storage may be internal or external to computer system where appropriate. In particular embodiments storage is non volatile solid state memory. In particular embodiments storage includes read only memory ROM . Where appropriate this ROM may be mask programmed ROM programmable ROM PROM erasable PROM EPROM electrically erasable PROM EEPROM electrically alterable ROM EAROM or flash memory or a combination of two or more of these. This disclosure contemplates mass storage taking any suitable physical form. Storage may include one or more storage control units facilitating communication between processor and storage where appropriate. Where appropriate storage may include one or more storages . Although this disclosure describes and illustrates particular storage this disclosure contemplates any suitable storage.

In particular embodiments I O interface includes hardware software or both providing one or more interfaces for communication between computer system and one or more I O devices. Computer system may include one or more of these I O devices where appropriate. One or more of these I O devices may enable communication between a person and computer system . As an example and not by way of limitation an I O device may include a keyboard keypad microphone monitor mouse printer scanner speaker still camera stylus tablet touchscreen trackball video camera another suitable I O device or a combination of two or more of these. An I O device may include one or more sensors. This disclosure contemplates any suitable I O devices and any suitable I O interfaces for them. Where appropriate I O interface may include one or more device or software drivers enabling processor to drive one or more of these I O devices. I O interface may include one or more I O interfaces where appropriate. Although this disclosure describes and illustrates a particular I O interface this disclosure contemplates any suitable I O interface.

In particular embodiments communication interface includes hardware software or both providing one or more interfaces for communication such as for example packet based communication between computer system and one or more other computer systems or one or more networks. As an example and not by way of limitation communication interface may include a network interface controller NIC or network adapter for communicating with an Ethernet or other wire based network or a wireless NIC WNIC or wireless adapter for communicating with a wireless network such as a WI FI network. This disclosure contemplates any suitable network and any suitable communication interface for it. As an example and not by way of limitation computer system may communicate with an ad hoc network a personal area network PAN a local area network LAN a wide area network WAN a metropolitan area network MAN or one or more portions of the Internet or a combination of two or more of these. One or more portions of one or more of these networks may be wired or wireless. As an example computer system may communicate with a wireless PAN WPAN such as for example a BLUETOOTH WPAN a WI FI network a WI MAX network a cellular telephone network such as for example a Global System for Mobile Communications GSM network or other suitable wireless network or a combination of two or more of these. Computer system may include any suitable communication interface for any of these networks where appropriate. Communication interface may include one or more communication interfaces where appropriate. Although this disclosure describes and illustrates a particular communication interface this disclosure contemplates any suitable communication interface.

In particular embodiments bus includes hardware software or both coupling components of computer system to each other. As an example and not by way of limitation bus may include an Accelerated Graphics Port AGP or other graphics bus an Enhanced Industry Standard Architecture EISA bus a front side bus FSB a HYPERTRANSPORT HT interconnect an Industry Standard Architecture ISA bus an INFINIBAND interconnect a low pin count LPC bus a memory bus a Micro Channel Architecture MCA bus a Peripheral Component Interconnect PCI bus a PCI Express PCI X bus a serial advanced technology attachment SATA bus a Video Electronics Standards Association local VLB bus or another suitable bus or a combination of two or more of these. Bus may include one or more buses where appropriate. Although this disclosure describes and illustrates a particular bus this disclosure contemplates any suitable bus or interconnect.

Herein reference to a computer readable storage medium encompasses one or more non transitory tangible computer readable storage media possessing structure. As an example and not by way of limitation a computer readable storage medium may include a semiconductor based or other integrated circuit IC such as for example a field programmable gate array FPGA or an application specific IC ASIC a hard disk an HDD a hybrid hard drive HHD an optical disc an optical disc drive ODD a magneto optical disc a magneto optical drive a floppy disk a floppy disk drive FDD magnetic tape a holographic storage medium a solid state drive SSD a RAM drive a SECURE DIGITAL card a SECURE DIGITAL drive or another suitable computer readable storage medium or a combination of two or more of these where appropriate. Herein reference to a computer readable storage medium excludes any medium that is not eligible for patent protection under 35 U.S.C. 101. Herein reference to a computer readable storage medium excludes transitory forms of signal transmission such as a propagating electrical or electromagnetic signal per se to the extent that they are not eligible for patent protection under 35 U.S.C. 101. A computer readable non transitory storage medium may be volatile non volatile or a combination of volatile and non volatile where appropriate.

This disclosure contemplates one or more computer readable storage media implementing any suitable storage. In particular embodiments a computer readable storage medium implements one or more portions of processor such as for example one or more internal registers or caches one or more portions of memory one or more portions of storage or a combination of these where appropriate. In particular embodiments a computer readable storage medium implements RAM or ROM. In particular embodiments a computer readable storage medium implements volatile or persistent memory. In particular embodiments one or more computer readable storage media embody software. Herein reference to software may encompass one or more applications bytecode one or more computer programs one or more executables one or more instructions logic machine code one or more scripts or source code and vice versa where appropriate. In particular embodiments software includes one or more application programming interfaces APIs . This disclosure contemplates any suitable software written or otherwise expressed in any suitable programming language or combination of programming languages. In particular embodiments software is expressed as source code or object code. In particular embodiments software is expressed in a higher level programming language such as for example C Perl or a suitable extension thereof. In particular embodiments software is expressed in a lower level programming language such as assembly language or machine code . In particular embodiments software is expressed in JAVA. In particular embodiments software is expressed in Hyper Text Markup Language HTML Extensible Markup Language XML or other suitable markup language.

Links couple servers and clients to network or to each other. This disclosure contemplates any suitable links . As an example and not by way of limitation one or more links each include one or more wireline such as for example Digital Subscriber Line DSL or Data Over Cable Service Interface Specification DOCSIS wireless such as for example Wi Fi or Worldwide Interoperability for Microwave Access WiMAX or optical such as for example Synchronous Optical Network SONET or Synchronous Digital Hierarchy SDH links . In particular embodiments one or more links each includes an intranet an extranet a VPN a LAN a WLAN a WAN a MAN a communications network a satellite network a portion of the Internet or another link or a combination of two or more such links . Links need not necessarily be the same throughout network environment . One or more first links may differ in one or more respects from one or more second links .

This disclosure contemplates any suitable servers . As an example and not by way of limitation one or more servers may each include one or more advertising servers applications servers catalog servers communications servers database servers exchange servers fax servers file servers game servers home servers mail servers message servers news servers name or DNS servers print servers proxy servers sound servers standalone servers web servers or web feed servers. In particular embodiments a server includes hardware software or both for providing the functionality of server . As an example and not by way of limitation a server that operates as a web server may be capable of hosting websites containing web pages or elements of web pages and include appropriate hardware software or both for doing so. In particular embodiments a web server may host HTML or other suitable files or dynamically create or constitute files for web pages on request. In response to a Hyper Text Transfer Protocol HTTP or other request from a client the web server may communicate one or more such files to client . As another example a server that operates as a mail server may be capable of providing e mail services to one or more clients . As another example a server that operates as a database server may be capable of providing an interface for interacting with one or more data stores such as for example data stores described below . Where appropriate a server may include one or more servers be unitary or distributed span multiple locations span multiple machines span multiple datacenters or reside in a cloud which may include one or more cloud components in one or more networks.

In particular embodiments one or more links may couple a server to one or more data stores . A data store may store any suitable information and the contents of a data store may be organized in any suitable manner. As an example and not by way or limitation the contents of a data store may be stored as a dimensional flat hierarchical network object oriented relational XML or other suitable database or a combination or two or more of these. A data store or a server coupled to it may include a database management system or other hardware or software for managing the contents of data store . The database management system may perform read and write operations delete or erase data perform data deduplication query or search the contents of data store or provide other access to data store .

In particular embodiments one or more servers may each include one or more search engines . A search engine may include hardware software or both for providing the functionality of search engine . As an example and not by way of limitation a search engine may implement one or more search algorithms to identify network resources in response to search queries received at search engine one or more ranking algorithms to rank identified network resources or one or more summarization algorithms to summarize identified network resources. In particular embodiments a ranking algorithm implemented by a search engine may use a machine learned ranking formula which the ranking algorithm may obtain automatically from a set of training data constructed from pairs of search queries and selected Uniform Resource Locators URLs where appropriate.

In particular embodiments one or more servers may each include one or more data monitors collectors . A data monitor collection may include hardware software or both for providing the functionality of data collector collector . As an example and not by way of limitation a data monitor collector at a server may monitor and collect network traffic data at server and store the network traffic data in one or more data stores . In particular embodiments server or another device may extract pairs of search queries and selected URLs from the network traffic data where appropriate.

This disclosure contemplates any suitable clients . A client may enable a user at client to access or otherwise communicate with network servers or other clients . As an example and not by way of limitation a client may have a web browser such as MICROSOFT INTERNET EXPLORER or MOZILLA FIREFOX and may have one or more add ons plug ins or other extensions such as GOOGLE TOOLBAR or YAHOO TOOLBAR. A client may be an electronic device including hardware software or both for providing the functionality of client . As an example and not by way of limitation a client may where appropriate be an embedded computer system an SOC an SBC such as for example a COM or SOM a desktop computer system a laptop or notebook computer system an interactive kiosk a mainframe a mesh of computer systems a mobile telephone a PDA a netbook computer system a server a tablet computer system or a combination of two or more of these. Where appropriate a client may include one or more clients be unitary or distributed span multiple locations span multiple machines span multiple datacenters or reside in a cloud which may include one or more cloud components in one or more networks.

Herein or is inclusive and not exclusive unless expressly indicated otherwise or indicated otherwise by context. Therefore herein A or B means A B or both unless expressly indicated otherwise or indicated otherwise by context. Moreover and is both joint and several unless expressly indicated otherwise or indicated otherwise by context. Therefore herein A and B means A and B jointly or severally unless expressly indicated otherwise or indicated otherwise by context.

This disclosure encompasses all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend. Similarly where appropriate the appended claims encompass all changes substitutions variations alterations and modifications to the example embodiments herein that a person having ordinary skill in the art would comprehend. Moreover reference in the appended claims to an apparatus or system or a component of an apparatus or system being adapted to arranged to capable of configured to enabled to operable to or operative to perform a particular function encompasses that apparatus system component whether or not it or that particular function is activated turned on or unlocked as long as that apparatus system or component is so adapted arranged capable configured enabled operable or operative.

