---

title: Methods and systems for efficient API integrated login in a multi-tenant database environment
abstract: Methods and systems for efficient API integrated login in a multi-tenant database environment and for decreasing latency delays during an API login request authentication including receiving a plurality of API login requests at a load balancer of a datacenter, where each of the plurality of API login requests specify a user identifier (userID) and/or an organizational identifier (orgID), fanning the plurality of API login requests across a plurality of redundant instances executing within the datacenter, assigning each API login request to one of the plurality of redundant instances for authentication, and for each of the respective plurality of API login requests, performing a recursive query algorithm at the assigned redundant instance, at one or more recursive redundant instances within the datacenter, and at a remote recursive redundant instance executing in a second datacenter, as necessary, until the login request is authenticated or determined to be invalid.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08676979&OS=08676979&RS=08676979
owner: salesforce.com, inc.
number: 08676979
owner_city: San Francisco
owner_country: US
publication_date: 20110215
---
This application is related to and claims priority to the provisional utility application entitled METHODS AND SYSTEMS FOR GENERATING A DYNAMIC WORKFLOW IN A MULTI TENANT DATABASE ENVIRONMENT filed on May 18 2010 having an application No. 61 345 983 the entire contents of which are incorporated herein by reference.

A portion of the disclosure of this patent document contains material which is subject to copyright protection. The copyright owner has no objection to the facsimile reproduction by anyone of the patent document or the patent disclosure as it appears in the Patent and Trademark Office patent file or records but otherwise reserves all copyright rights whatsoever.

Embodiments of the invention relate generally to the field of computing and more particularly to methods and systems for efficient API integrated login in a multi tenant database environment and for decreasing latency delays during an API login request authentication.

The subject matter discussed in the background section should not be assumed to be prior art merely as a result of its mention in the background section. Similarly a problem mentioned in the background section or associated with the subject matter of the background section should not be assumed to have been previously recognized in the prior art. The subject matter in the background section merely represents different approaches which in and of themselves may also correspond to embodiments of the claimed inventions.

An Enterprise Service Provider may use an Application Programming Interface API as an authentication mechanism to handle login requests e.g. requests received by a datacenter or computing center operated or controlled by a particular business Enterprise . However previously known API login models fail to provide adequate scalability and responsiveness as the size and complexity of a datacenter increases.

For example incoming authentication requests received at a web domain such as a www or world wide web domain must be processed and authenticated by systems within the receiving organization. When the number of incoming requests are small and the infrastructure of the receiving organization is simple e.g. processing the incoming requests as they arrive this technique and other previously known models is straight forward but does not scale well. As the number of incoming requests to be processed or authenticated increases the system processing the incoming requests can become overwhelmed and can become a single point of failure. Additionally as the complexity of the receiving organization increases the computational load placed upon the authenticating system also increases eventually making it difficult if not impossible for the authenticating system to keep up with demand. As the authenticating system becomes overwhelmed latency increases as does the risk of an improperly denied authentication request.

One such complexity placed upon the authentication system is handling incoming login requests which do not strictly conform to an HTML based model and therefore require special handling. API login requests for example require specialized handling due to the nature of the interface for the request which is further complicated by Enterprise Service Provider s data center infrastructure which is scaled to handle larger volumes of requests and transactions.

The present state of the art may benefit from the methods and systems for efficient API integrated login in a multi tenant database environment and for decreasing latency delays during a login request authentication as described herein.

Described herein are systems devices and methods for efficient API integrated login in a multi tenant database environment and for decreasing latency delays during an API login request authentication. For instance the systems devices and methods include the appropriate mechanisms to receive a plurality of API login requests at a load balancer of a datacenter where each of the plurality of API login requests specify a user identifier userID and or an organizational identifier orgID . In this instance the load balancer fans e.g. via a fanning distribution algorithm the plurality of API login requests across a plurality of redundant instances executing within the datacenter assigning each API login request to one of the plurality of redundant instances for authentication. For each of the respective plurality of API login requests a lookup request is performed on the userID and or the OrgID specified by the respective API login request via the assigned redundant instance the lookup request is proxied to one or more recursive redundant instances when the lookup request fails at the assigned redundant instance and the lookup request is proxied to a remote recursive redundant instance executing in a second datacenter when the lookup request fails at the one or more recursive redundant instances within the first datacenter.

For example if an API login request is processed by a redundant instance that cannot locate the userID and or the OrgID via the datastore resources available to it the redundant instance may then manage a recursive query algorithm amongst other redundant instances within the datacenter that are associated with different datastore resources within the datacenter which have not yet been queried. Should the other datastores within the datacenter similarly be unable to locate the userID and or the OrgID specified by the API login request the recursive query algorithm may be extended to one or more other datacenters such as datacenters that are located in a geographically distinct region e.g. a USA based datacenter exhausts its datastore resources and then an Asia region datacenter is referenced etc. .

In one embodiment the redundant instance within a first datacenter manages and directs a recursive query algorithm in parallel among other redundant instances within the first datacenter when necessary but hands off responsibility for managing parallel search within a second datacenter to a redundant instance local to the second datacenter so as to minimize cross datacenter boundary transactions. In such a way cross datacenter boundary references and transactions may be minimized which may in turn improve the efficiency and decrease latency delays during an API login request authentication such as authenticating an API login request.

The systems devices and methods described herein improve API login request and API login authentication mechanisms especially where a submission of invalid user identifiers userIds and or organization identifiers OrgIDs or the submission of userIds and or OrgIDs not fully synchronized throughout the host organization cause conventional login request mechanisms to make multiple round trips across datacenter boundaries where each trip represents a communication with a remote computing device or computing center and has an associated latency e.g. greater than 300 ms latency . Such round trips may increase the overall response times for the login request during which client connections associated with the login request can potentially time out thus frustrating the end user or business partner responsible for triggering the login request. Moreover conventional login requests mechanisms yield inconsistent results and may appear to an end user as seemingly working or failing depending on how a particular login request happens to be routed within the host organization. Practicing the systems and methods described herein may reduce overall latency by for example reducing the number of cross datacenter boundary transactions e.g. round trips between datacenters .

In the following description numerous specific details are set forth such as examples of specific systems languages components etc. in order to provide a thorough understanding of the various embodiments. It will be apparent however to one skilled in the art that these specific details need not be employed to practice the disclosed embodiments. In other instances well known materials or methods have not been described in detail in order to avoid unnecessarily obscuring the disclosed embodiments.

In addition to various hardware components depicted in the figures and described herein embodiments further include various operations which are described below. The operations described in accordance with such embodiments may be performed by hardware components or may be embodied in machine executable instructions which may be used to cause a general purpose or special purpose processor programmed with the instructions to perform the operations. Alternatively the operations may be performed by a combination of hardware and software.

Embodiments also relate to a system or apparatus for performing the operations herein. The disclosed system or apparatus may be specially constructed for the required purposes or it may comprise a general purpose computer selectively activated or reconfigured by a computer program stored in the computer. Such a computer program may be stored in a non transitory computer readable storage medium such as but not limited to any type of disk including floppy disks optical disks CD ROMs and magnetic optical disks read only memories ROMs random access memories RAMs EPROMs EEPROMs magnetic or optical cards or any type of media suitable for storing non transitory electronic instructions each coupled to a computer system bus. In one embodiment a computer readable storage medium having instructions stored thereon causes one or more processors within a multi tenant database environment to perform the methods and operations which are described herein. In another embodiment the instructions to perform such methods and operations are stored upon a non transitory computer readable medium for later execution.

The algorithms and displays presented herein are not inherently related to any particular computer or other apparatus nor are embodiments described with reference to any particular programming language. It will be appreciated that a variety of programming languages may be used to implement the teachings of the embodiments as described herein.

In one embodiment each of the separate and distinct customer organizations A C may be remotely located from the host organization that provides services to the customer organizations A C via datacenter having the multi tenant database system executing therein. Alternatively one or more of the customer organizations A C may be co located with the host organization such as within the same organization that hosts and provides the multi tenant database system upon which underlying data is persistently stored. Where the customer organizations A C are remote host organization provides remotely implemented cloud computing services.

In one embodiment the hardware software and logic elements of the multi tenant database system include at least a non relational data store and a relational data store which operate in accordance with the hardware software and logic elements that implement the database functionality and code execution environment within the host organization . Host organization may further receive API login requests from one or more of the plurality of customer organizations A C via the network. For example an incoming login request may be a login request received at login domain or may correspond to a request for services or a request to retrieve or store data on behalf of one of the customer organizations A C.

In accordance with one embodiment datacenter receives a plurality of login requests at a load balancer of the datacenter in which each of the plurality of login requests specify a user identifier userID and or an organizational identifier orgID . For example each login request may specify the userID and or the OrgID from which the login request originates such as a userID and or OrgID corresponding to one of customer organizations A C or a user within one of the customer organizations A C.

In such an embodiment load balancer then fans the plurality of login requests across a plurality of redundant instances executing within the datacenter . For example each of the plurality of login requests may be randomly or systematically distributed e.g. fanned dispersed etc. amongst redundant instances executing within the depicted pods A D. In such a way each login request is assigned to one of the plurality of redundant instances for authentication.

For each of the respective plurality of login requests received and fanned dispersed amongst the plurality of redundant instances a lookup request is performed on the userID and or the OrgID specified by the respective login request . For example the lookup request is performed via an assigned redundant instance as a result of the load balancer fanning the multiple received login requests the assigned redundant instance being the redundant instance among the plurality of available redundant instance that receives or is assigned the login request from the load balancer as a result of the fanning operation.

A lookup request performed within a given pod A D by an assigned redundant instance may not necessarily locate the requested data. This may be a result of a bad request a malformed request an incorrectly specified userID and or OrgID a malicious attack based login request or a result of synchronization lag. Synchronization lag is possible where a datastore resource within one pod e.g. A has userIDs and or OrgIDs that are not available in other pods e.g. B D or where userIDs and or OrgIDs are stored only at one datacenter and not at another datacenter. Synchronization lag may occur when a new user is introduced to the system and then a login request is submitted before data associated with the new user is distributed throughout the datacenters or throughout multiple datacenters within a host organization . Synchronization lag may also be deliberate such as where data is stored at one datacenter and not another as a result of policy or stored within some pods and not others as a result of policy designation or system design.

Accordingly when an initial lookup request fails within the assigned redundant instance the assigned redundant instance proxies the lookup request to one or more recursive redundant instances. For example if the lookup request fails within pod 1 at A the lookup request may be proxied to pods 2 through N e.g. B C and D in search of the specified userIDs and or OrgIDs. In such an embodiment the lookup request is additionally proxied to a remote recursive redundant instance executing in a second datacenter when the lookup request fails at the one or more recursive redundant instances within the first datacenter. For example when all resources within the first datacenter are determined to have been exhausted the assigned redundant instance may extend its search to a second datacenter which may have resources to locate the specified userIDs and or OrgIDs.

In one embodiment an assigned redundant instance executes within a first pod A having a first subset of the plurality of redundant instances executing within the first datacenter A. For example although pod 1 A has 8 redundant instances shown may act as an assigned redundant instance for a particular login request assigned to it dispersed to it or delegated to it via a fanning algorithm performed by load balancer A.

In one embodiment one or more recursive redundant instances operate in a second one or more pods e.g. pods 2 through N at elements B and C where each of the second one or more pods B and C have a second one or more subsets of the plurality of the redundant instances executing within the first datacenter A. Thus in datacenter A there are multiple pods A through C each having a subset of the multiple redundant instances within the datacenter A.

Redundant instances may be for example Java Virtual Machines JVMs executing on hardware within the various pods A C individual computing nodes forming a grid or cluster of computing nodes within the pods A C computing blades within blade servers executing within the pods A C or other computing architecture capable of performing the various operations and methodologies described herein.

In one embodiment the first pod A and each of the second one or more pods B C each have a datastore e.g. A B and C respectively having a plurality of userIDs and or OrgIDs stored therein. In such an embodiment the datastore A C of each pod A C is accessible to the respective subset of redundant instances operating within the same pod. In alternative embodiments userIDs and or OrgIDs may additionally or alternatively be stored within the multi tenant database system communicatively interfaced with the pods A C. In yet another embodiment userIDs and or OrgIDs may additionally or alternatively be stored upon a global caching layer accessible via the various pods A C.

In one embodiment the assigned redundant instance operates within the first pod A and a lookup request is determined to have failed at the assigned redundant instance when the userID and or the OrgID specified by the respective login request cannot be located within the datastore A of the first pod A.

In one embodiment each one or more recursive redundant instances operates within one of the second one or more pods B though C without overlap. For example where an assigned redundant instance determines that one or more recursive redundant instances must be leveraged to perform recursive lookup requests each of the one or more recursive redundant instances are located within the remaining pods e.g. not the pod to which the assigned redundant instance belongs . In one embodiment only one recursive redundant instances is referenced in each of the remaining pods B and C and thus there is no overlap between the one or more recursive redundant instances referenced. For example in one embodiment there is no overlap because each redundant instance resides within only one pod A C or is exclusive to one such pod.

In one embodiment a lookup request is determined to have failed at the one or more recursive redundant instances when the userID and or the OrgID specified by the respective login request cannot be located within the respective datastore e.g. B and C within any of the second one or more pods e.g. B and C .

Where appropriate lookup requests within the first datacenter exhaust all possible resources e.g. datastores A C in accordance with one embodiment a look up request is proxied to a second datacenter B. In one embodiment datacenter B includes a load balancer B and a login domain B. In an alternative embodiment datacenter B lacks a login domain B and all login requests for the host organization are received at login domain A of the first datacenter and then relayed to the second datacenter only when necessary. Datacenter B may additionally include a multi tenant database system which may be a replication of the multi tenant database system in datacenter A or may be a similar architecture but house data or persistently store data that is specific to datacenter B such as data stored for customer organizations that are associated with datacenter B for their storage needs and or accounts. Datacenter B further includes its own pods e.g. pod 1 at D and pod N at E each of which have their own subset of redundant instances . Each pod D and E within datacenter B further includes a datastore e.g. D and E respectively .

In one embodiment proxying a lookup request to a remote recursive redundant instance executing in the second datacenter B includes the assigned redundant instance proxying the lookup request to the remote recursive redundant instance upon a determination that all pods A C located within the first datacenter A have been checked for the userID and or the OrgID. In such an embodiment the lookup request proxied to the remote recursive redundant instance within the second datacenter B crosses the datacenter boundary .

In accordance with one embodiment a new userID and or a new OrgID for a new account is entered into a datastore e.g. D within the second datacenter B. For example new account data is depicted as being entered into datastore D within datacenter B.

In such an embodiment the new userID and or the new OrgID associated with new account data is not synchronized to one or more datastores A C within the first datacenter A when one of the plurality of login requests is received at the first datacenter A specifying the new userID and or the new OrgID associated with new account data . For example the new userID and or the new OrgID may be unavailable within the datastores A C of the first datacenter A due to a synchronization lag between the datastore D within the second datacenter and the one or more datastores within the first datacenter A C.

In such an embodiment the assigned redundant instance may proxy a lookup request or send a proxied lookup request to a remote recursive redundant instance executing in the second datacenter B in an effort to locate the new userID and or the new OrgID associated with new account data . Accordingly in such an embodiment the assigned redundant instance receives a response from the remote recursive redundant instance within the second datacenter B indicating the login request specifying the new userID and or the new OrgID has been authenticated. For example depicts the assigned redundant instance sending a proxied lookup request to the remote recursive redundant instance and then receiving an appropriate response indicating successful authentication.

Similarly where the assigned redundant instance sends or proxies a lookup request to a recursive redundant instance within the same datacenter an appropriate response may be received from the recursive redundant instance as depicted.

In one embodiment a reference link is returned to the originator of the login request . For example such a reference link may direct the originator of the login request to direct subsequent requests for services to the one of the plurality of redundant instances having authenticated the corresponding login request . For example the reference link may specify future requests for services such as a database access to be transacted against the multi tenant database system to be directed to whichever of the various redundant instances authenticated the login request . Thus in accordance with the depiction set forth at the reference link may point to assigned redundant instance recursive redundant instance or remote recursive redundant instance depending on which eventually authenticates the login request .

In alternative embodiments a returned reference link identifies a pod e.g. one of A E that hosts the authenticating redundant instance rather than a specific redundant instance. In other embodiments subsequent requests for services are fed to the load balancer which then fans or distributes the computational load required to process the service requests amongst the various redundant instances without regard to which redundant instance or pod authenticated a preceding login request .

In one embodiment a lookup request is indicated to have failed at the assigned redundant instance when the userID and or the OrgID specified by the respective login request cannot be located within a datastore accessible via the assigned redundant instance . For example datastore A is accessible to assigned redundant instance but the userID and or the OrgID may not be present thus triggering the failure.

In one embodiment a lookup request is indicated to have failed at the one or more recursive redundant instances e.g. and within the first datacenter A when the userID and or the OrgID specified by the respective login request cannot be located within any datastore B and C accessible via the one or more recursive redundant instances and e.g. the information is not accessible through any of the remaining pods instances or datastores B C .

In one embodiment a lookup request is indicated to have failed at the remote recursive redundant instance when the userID and or the OrgID specified by the respective login request cannot be located within the datastore D accessible via the remote recursive redundant instance . Alternatively a lookup request is indicated to have failed at the remote redundant instance when the userID and or the OrgID specified by the respective login request cannot be located within any datastore D E within the second datacenter B e.g. where the remote redundant instance locally initiates its own recursive search through local pods D E within its local datacenter B .

In one embodiment a response is returned to the assigned redundant instance indicating the userID and or the OrgID cannot be located. For example response may simply indicate a failed proxied lookup request. In one embodiment the assigned redundant instance receives multiple such responses for example one response associated with each pod to which a proxied lookup request was sent.

In one embodiment each of the plurality of login requests is an Application Programming Interface API login request received from one of a separate and distinct remote organization an organizational group within a host organization that operates the first and second datacenters A B a business partner or a customer organization e.g. A C . In such an embodiment each of the plurality of redundant instances implements API login request functionality to validate and authenticate login credentials provided via the plurality of login requests received.

API login request functionality may include support for an XML RPC eXtended Markup Language Remote Procedure Call discovery call to resolve a username identifier and or organizational identifier to a redundant instance or a corresponding discovery call on behalf of another redundant instance such as an assigned redundant instance .

API login request functionality may include support for forwarding the login request as is and without modification e.g. a byte for byte copy of the payload including any post data received from the client in an un altered form e.g. as is or via byte for byte replication forwarding .

For example in one embodiment proxying the lookup request to the one or more recursive redundant instances includes transmitting all post data associated with the API login request in an un altered form to the one or more recursive redundant instances within the proxied lookup request. For instance the post data may be replicated and injected into the proxied lookup request or encoded into the proxied lookup request when such a request is generated or created. In such an embodiment transmitting all the post data in the un altered form may include proxying the lookup request via a byte for byte replication forwarding mechanism . A byte for byte replication forwarding mechanism depicted at may reside within each of the various pods e.g. within each of pods A through E may be available as a common use module within each datacenter e.g. each of A and B or as a functional logical unit locally available within each of the redundant instances .

Post data and payload data may include information provided by an end user of a client device which is interfacing with the host organization. For example such an end user may enter information such as login credentials e.g. UserID OrgID password etc. or other necessary information into an interface at the client device which is then encoded into an API login request received by the host organization as payload data and or post data. When proxying a request such as a proxied login request or a proxied lookup request a replication forwarding mechanism may provide the byte for byte copying so that payload data and or post data originating from a client device may be received by a targeted proxy location in an as is and un altered form.

API login request functionality may include support for returning a response e.g. from an application server e.g. from a redundant instance or an associated pod to be returned or directed to the client as is e.g. as a byte for byte copy of the payload of response . For instance in one embodiment proxying the lookup request to the one or more recursive redundant instances further includes receiving at the assigned redundant instance a response from one of the one or more recursive redundant instances indicating a successful authentication responsive to the proxied lookup request. For instance the assigned redundant instance may proxy out multiple lookup requests to the various alternative pods e.g. A C available within datacenter A or proxy a lookup request to a pod e.g. D E within a remote datacenter B. Notwithstanding the multiple lookup requests sent proxied some of the proxied requests may fail authentication due to an inability to locate the necessary data. Nevertheless where at least one response e.g. indicates successful authentication the others may be disregarded. When a successful authentication is indicated via at least one response returned from either a recursive redundant instance e.g. or or a remote recursive redundant instance e.g. the assigned redundant instance may transmit the response indicating the successful result to a client device having originated the respective API login request and discard the responses indicating failure. Moreover transmitting the response from the receiving datacenter back to an end user client device or other requesting entity may include sending the response via a byte for byte replication forwarding mechanism to such a client device resulting in the originating client device receiving an identical byte for byte copy of a payload of the response received at the assigned redundant instance indicating the successful authentication. Stated differently a response sent to an originating client device may exhibit an identical structure and payload regardless of whether authentication succeeds at an assigned redundant instance or at any proxy location e.g. at one of instances or .

API login request functionality may include support for an XML RPC that is compatible with both old soap variants v2.0 and new soap variants v2.5 and up support for an XML RPC and old soap WWW domain supported following non login service requests as well e.g. requested database transactions a request to validate a login a request for version information a request for session information or a request to authenticate an email or an email address .

Where an API login request lands at or is received at a World Wide Web WWW webserver the login request may be forwarded to a load balancer directly or to a login domain A B and then to a load balancer A B. In other embodiments the WWW webserver is eliminated from the login request path and thus a WWW load balancer or a login domain load balancer will receive the initial incoming API login request without first having to traverse through or communicate with a WWW webserver.

API login request functionality may include support for a load balancer A B to forward login requests using an API URL e.g. API Uniform Resource Locator configuration parameter stored in for example a serverpools.xml for a particular redundant instance . Such an API URL may be provided directly to an application server pool e.g. a pod or group of pods within the host organization implementing the API login request functionality. API login requests may be handled directly by the application servers or redundant instances having special purpose servlets e.g. LoginProxyServlets capable of performing discovery e.g. lookup requests and authentication and proxy functions e.g. proxying lookup requests or sending proxied lookup requests .

API login request functionality may include support for discovery logic in which requests are proxied to the appropriate destination after the discovery thus eliminating thrashing or needless round trips between data centers and may further include diverse implementation logic associated with distinct Enterprises customer organizations or business partners.

In one embodiment load balancer operates at or within a login domain of the host organization . For example load balancer A may operate at or within login domain A within the first datacenter A to receive the plurality of incoming login requests from a plurality of customer organizations A C of the host organization . Alternatively load balancer may operate separately from but in conjunction with login domain .

In one embodiment load balancer receives a plurality of service requests from the plurality of customer organizations where each service request specifies transactions to be executed against the multi tenant database system s operated by the host organization .

In some embodiments flags may be utilized to track and control the API integrated login request authentication processes. For example in one embodiment the load balancer injects a new request flag into each of the plurality of login requests received. The new request flag may indicate an associated login request is not yet assigned to one of the plurality of redundant instances . One of the plurality of redundant instances may then become the assigned redundant instance for any login request assigned to it having the new request flag present. In such a way when any one of the multiple executing redundant instances available receives a login request the redundant instance can ascertain based on the new request flag that it is the first redundant instance to receive the login request and thus it is correspondingly the assigned redundant instance for processing the login request .

In one embodiment proxying a lookup request to one or more recursive redundant instances e.g. and or when the lookup request fails at the assigned redundant instance includes the assigned redundant instance injecting a proxy flag into the proxied lookup request . Such a proxy flag may indicate to any of the one or more recursive redundant instances and or remote recursive redundant instance that receiving the proxied lookup request that the assigned redundant instance is managing a recursive discovery algorithm within the first datacenter A to locate the userID and or the OrgID specified by the respective login request . The proxy flag may further uniquely identify the assigned redundant instance for the respective login request . The proxy flag may further direct any of the one or more recursive redundant instances e.g. or receiving the proxied lookup request not to initiate a recursive discovery algorithm within the first datacenter A given that the assigned redundant instance is already doing so.

In one embodiment when the userID and or the OrgID specified by the respective login request cannot be located within a datastore accessible via the assigned redundant instance the assigned instance initiates the recursive discovery algorithm. The recursive discovery algorithm may include 1 exhausting by executing in parallel the proxied lookup request against all datastores within a plurality of pods A C operating within the first datacenter A or all remaining pods B and C within the first datacenter A e.g. all pods in a datacenter which are not associated with the assigned redundant instance . In one embodiment the pods within the first datacenter have non overlapping subsets of the plurality of redundant instances allocated thereto and operating therein e.g. each redundant instance is associated with exactly one pod . The recursive discovery algorithm may further include 2 exhausting all datastores within a plurality of pods D and E operating within the second datacenter B by executing the proxied lookup request against the second datacenter B and 3 repeating the proxied lookup request against any remaining one or more additional datacenters by executing the proxied lookup request against each of the second datacenter B and the one or more additional datacenters in serial. In alternative embodiments the proxied lookup request is sent to all remaining datacenters e.g. all datacenters within host organization except for the first datacenter in parallel.

In one embodiment all invalid user names received are cached at the login domain e.g. at login.host organization.com . For example where all resources are exhausted at all datacenters and a login request triggers a bad username or authentication failure message the failed login credentials may be cached at the login domain so that future login requests having the same improper login credentials do not require a work flow that flows through the available pods in multiple datacenters . Instead a failure message may be returned based on the cache entry with minimal processing. In one embodiment a reply to an invalid login request is delayed based on an average response time for all login requests so as to reflect normal login response time and prevent rapid or quick succession logins such as those submitted via a systematic attack.

In one embodiment proxying the lookup request to the remote recursive redundant instance executing in the second datacenter B includes injecting the proxy flag into the proxied lookup request where the proxy flag indicates to the remote recursive redundant instance receiving the proxied lookup request that the assigned instance is managing a recursive discovery algorithm from the first datacenter A and further directing the remote recursive redundant instance to return a reference link to the assigned instance specifying which of a plurality of remote redundant instances e.g. or any of redundant instances within the pods D and E of the second datacenter B has authenticated the corresponding login request .

In some embodiments the assigned redundant instance sends the proxied lookup request to a second load balancer B operating within the second datacenter B. For example rather than sending the proxied lookup request directly to a redundant instance within the second datacenter B e.g. remote recursive redundant instance the proxied lookup request having the proxy flag injected therein is instead sent to load balancer B where the second load balancer responsively fans the proxied lookup request across the plurality of redundant instances executing within the second datacenter B. The proxied lookup request may be distributed fanned along with a plurality of login requests received at the second load balancer B of the second datacenter including incoming login requests that have not yet been processed at either datacenter A B.

Whether the proxied lookup request is sent to a redundant instance of the second datacenter or to a load balancer of the second datacenter a redundant instance of the second datacenter may be assigned to manage parallel execution of lookup requests and or proxied lookup requests within the second datacenter. In such an embodiment although a redundant instance is assigned to perform such a function because the proxy flag is present within the proxied lookup request the assigned redundant instance within the second datacenter B e.g. redundant instance acting as a remote recursive redundant instance may responsively return or send a response from the second datacenter back to the assigned redundant instance within the first datacenter indicating authentication of the corresponding login request was successful and uniquely identifying one of the plurality of redundant instances within the second datacenter that authenticated the login request e.g. based on a received proxied lookup request . In one embodiment a special header such an API LOGIN PROXY header or an equivalent identification header indicates that the login request is being proxied as a proxied lookup request and thus performs the function of the proxy flag.

In one embodiment multiple data elements are injected into a header of each of the plurality of login requests received by a load balancer . For example load balancer may inject a client Internet Protocol Identifier clientIP into each header to store a value corresponding to the actual IP address of an originating client having sent each respective login request . For example the IP address of a client computing device within one of the customer organizations A C may be injected. Load balancer may inject a load balancer flag into each header indicating the load balancer has processed the respective incoming login request the load balancer flag injected into a header may function as a new request flag .

In one embodiment each of the plurality of redundant instances processing an assigned fanned login request injects the proxy flag indicating the respective login request is being proxied across a datacenter boundary geographically separating the first datacenter A from a separate and distinct second datacenter B when the userID and or the orgID associated with the respective login request is not locatable within the first datacenter A.

When incoming API login requests flow through multiple external facing VIPs Virtual Internet Protocol addresses the value added by the first VIP e.g. an actual ClientIP may be lost within an un altered header using ordinary packet routing. Support is therefore provided for the API login request to flow through multiple external facing VIPs between multiple proxy hops so that requests flowing through different load balancers do not cause the actual client IP address to be lost. For example where a WWW domain to an application server redundant instance hop is performed requests proxied from a WWW domain level load balancer may go directly to an application server pool and not through a login sub domain e.g. or corresponding load balancer . In one embodiment a new header entry is injected to a proxied lookup request or proxied login request to carry forward the actual client IP address e.g. a LOGIN PROXY CLIENT IP header entry ACTUAL CLIENT IP header entry or equivalent header identification . When such a client IP address header is present and the routable IP address indicated by such a proxied request is pointing to an IP address within the host organization s own data center implementing the API login request functionality the remote address of the client e.g. the client IP address can nevertheless be derived from the client IP header thus allowing the host organization to properly route any response to the requesting client using the client s actual original IP address e.g. which may otherwise be lost due to the proxying mechanism . Support may additionally be provided for forwarding a whitelisted set of headers.

In some embodiments to distinguish service requests from login requests the presence of a special HTTP header is checked. For example checking for a LOGIN LOAD BALANCER header or equivalent entry in the HTTP header may indicate the presence of a login request which requires the API integrated login authentication methodologies described herein compared to service request which may request an ordinary database transaction . In one embodiment load balancer inserts the special header for all requests landing on a login sub domain to distinguish such requests from incoming service requests. For example all requests may be sent to a common or shared application server pool for processing via redundant instances and thus the header flags appropriately identify a request type.

In accordance certain embodiments a fanning or an equivalent distribution algorithm references a leader identifier leaderId element indicating a leader pod or a leader redundant instance to be referenced first within a particular datacenter B. For example the entity specified by such a leaderID will be tried first e.g. will become an assigned instance or will become the first referenced recursive redundant instance and within remaining pods in a datacenter or will become the first referenced remote recursive redundant instance within a second datacenter so as to optimize the proxied lookup requests .

In an alternative embodiment a leaderId is not referenced so as to avoid checking all servers redundant instances in the same order which may lead to a lack of distribution across the instances in particular data center implementations. For example specified redundant instances corresponding to the leaderID may be over utilized. Other distribution schemes may force cross instance calls in which the cross instance calls have to obtain a lock amongst the redundant instances e.g. in a particular datacenter or among a subset of redundant instances in a particular pod and in which the number of locks are limited so as to prevent mitigate DOS Denial Of Service attacks. Although such a locking scheme forces contention in which both good e.g. legitimate users and bad e.g. attacking users contend for the limited pool of locks and connections potential damage from attacks can be minimized.

In one embodiment a login request is directed toward a specific instance e.g. assigned instance which is not load balanced. Such login requests may be directed toward a login sub domain by passing server pool load balancing or directed toward a particular instance or pod directly. In such an embodiment SOAP XML RPC OldSoap protocol based servlets forward a proxied login request or a proxied lookup request to corresponding proxy servlets after checking special headers such as the LOGIN LOAD BALANCER or API LOGIN PROXY type headers described above to determine if the login request being processed is a direct login request e.g. a first instance or a proxied recursive login request or lookup request. For example a first instance may have the LOGIN LOAD BALANCER inserted but it would not have an API LOGIN PROXY header entry as the first instance request would not have undergone proxying to any redundant instance.

Discovery may be performed in which a lookup by username or organizational ID is performed directly from a users table or an organizations table for example a table listing all respective users and or customer organizations known to the host organization. When a match is discovered e.g. the lookup request or lookup operation is complete the request may then be proxied to a specific end point directly where it is handled by for example a SOAP stack XML RPC stack Axis etc. to perform and complete authentication. When a match is not discovered via an initial lookup request the request is proxied in a loop to local redundant instances without fanning e.g. with a special header API LOGIN PROXY so that the proxy servlets handle the proxied request on behalf of another instance such as assigned redundant instance . When a match is still not discovered via the proxied lookup request the request is proxied in a loop to remote instances at remote datacenters. In a particular embodiment the proxy loop to remote instances is limited to only one redundant instance maximum per remote non local data center with a special header again such as API LOGIN PROXY with a fanning request. The remote instance will then try all instances local to the remote instance when it sees the fanning request header.

In one embodiment system includes a memory and a processor or processors . For example memory may store instructions to be executed and processor s may execute such instructions. System includes bus to transfer transactions and data within system such as login requests and API login requests among a plurality of redundant instances communicably interfaced with bus . System further includes web server for example to receive requests return responses and otherwise interface with remote clients such as client devices located within customer organizations A C and a byte for byte replication forwarding module to provide a true or exact copy of post data and or payload data received at system within an incoming request e.g. such as within an API login request received via login domain .

System further includes a global caching layer to provide caching services to communicably interfaced devices and systems and in particular provide caching of failed logins and other login request data shared amongst redundant instances or pods e.g. meta data etc. . System is further depicted as having login domain designed receive login requests either directly or as directed from another landing within system such as from a WWW domain implemented by for example web server . Login domain may inject special flags or header entries into received login requests. Login domain forwards login requests either directly to an assigned redundant instance or to an appropriate load balancer.

For example distinct within system is hardware based load balancer which includes request processor flag analyzer flag injector and fanning module . In accordance with one embodiment request processor receives login requests forwarded or passed from login domain for distribution amongst available redundant instances for processing and authenticating the login requests. Request processor further coordinates with flag analyzer to check for and interpret any available flags within the login request. For example the login request may be a proxied login request or a proxied lookup request to be processed on behalf of another redundant instance rather than a new login request. Request processor further coordinates with flag injector to introduce inject flags and header entries into login requests so that they may be proxied and routed through the API integrated login authentication mechanism appropriately e.g. a proxy flag may be introduced to indicate to a recursive redundant instance or a remote redundant recursive instance that the login request is a proxied login request or a proxied lookup request rather than a new login request not yet assigned to a redundant instance . Fanning module implements fanning logic to distribute login requests and or proxied login requests amongst available redundant instances for processing including referencing and utilizing a leaderID when available.

Method begins with processing logic receiving a plurality of login requests at a load balancer of a datacenter block . At block processing logic injects a new request flag into each of the plurality of login requests received.

At block processing logic fans e.g. distributes load balances etc. the plurality of login requests across a plurality of redundant instances executing within the datacenter and at block processing logic assigns each login request to one of the plurality of redundant instances for authentication processing.

At block processing logic within an assigned redundant instance performs a lookup request on a userID and or a OrgID specified by the respective login request. At block processing logic injects a proxy flag into a lookup request to be proxied.

At block processing logic proxies the lookup request to one or more recursive redundant instances when the lookup request fails at the initially assigned redundant instance. At block processing logic proxies the lookup request to a remote recursive redundant instance executing in a second datacenter when the lookup request fails at one or more recursive redundant instances within the first datacenter.

At block processing logic receives a response at the initially assigned redundant instance within the first datacenter from a remote recursive redundant instance within the second datacenter indicating a proxied login request has been authenticated.

At block processing logic returns a reference link to an originator of the login request the reference link directing the originator to submit subsequent requests for services to a specified datacenter to a specified domain to a specified pod or to a specified redundant instance.

The exemplary computer system includes a processor a main memory e.g. read only memory ROM flash memory dynamic random access memory DRAM such as synchronous DRAM SDRAM or Rambus DRAM RDRAM etc. static memory such as flash memory static random access memory SRAM volatile but high data rate RAM etc. and a secondary memory e.g. a persistent storage device including hard disk drives and persistent multi tenant data base implementations which communicate with each other via a bus . Main memory includes header flags to indicate for example a request type e.g. login request or services request whether a login request is a new login request or a proxied login request proxied lookup request etc. Main memory further includes global cache layer such as a system wide accessible global caching layer to provide meta data and other information exchanged between multiple redundant instances and or pods. Main memory and its sub elements e.g. and are operable in conjunction with processing logic and processor to perform the methodologies discussed herein.

Processor represents one or more general purpose processing devices such as a microprocessor central processing unit or the like. More particularly the processor may be a complex instruction set computing CISC microprocessor reduced instruction set computing RISC microprocessor very long instruction word VLIW microprocessor processor implementing other instruction sets or processors implementing a combination of instruction sets. Processor may also be one or more special purpose processing devices such as an application specific integrated circuit ASIC a field programmable gate array FPGA a digital signal processor DSP network processor or the like. Processor is configured to execute the processing logic for performing the operations and functionality which is discussed herein.

The computer system may further include a network interface card . The computer system also may include a user interface such as a video display unit a liquid crystal display LCD or a cathode ray tube CRT an alphanumeric input device e.g. a keyboard a cursor control device e.g. a mouse and a signal generation device e.g. an integrated speaker . The computer system may further include peripheral device e.g. wireless or wired communication devices memory devices storage devices audio processing devices video processing devices etc. The computer system may further include a Hardware based load balancer to implement a fanning algorithm or other distribution scheme and to additionally evaluate and inject where necessary appropriate header flags and entries into login requests to be processed by computer system .

The secondary memory may include a non transitory machine readable storage medium or more specifically a non transitory machine accessible storage medium on which is stored one or more sets of instructions e.g. software embodying any one or more of the methodologies or functions described herein. The software may also reside completely or at least partially within the main memory and or within the processor during execution thereof by the computer system the main memory and the processor also constituting machine readable storage media. The software may further be transmitted or received over a network via the network interface card .

While the subject matter disclosed herein has been described by way of example and in terms of the specific embodiments it is to be understood that the claimed embodiments are not limited to the explicitly enumerated embodiments disclosed. To the contrary the disclosure is intended to cover various modifications and similar arrangements as would be apparent to those skilled in the art. Therefore the scope of the appended claims should be accorded the broadest interpretation so as to encompass all such modifications and similar arrangements. It is to be understood that the above description is intended to be illustrative and not restrictive. Many other embodiments will be apparent to those of skill in the art upon reading and understanding the above description. The scope of the disclosed subject matter is therefore to be determined in reference to the appended claims along with the full scope of equivalents to which such claims are entitled.

