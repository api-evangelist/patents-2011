---

title: Methods and systems for processing a video for stabilization and retargeting
abstract: Methods and systems for processing a video for stabilization and retargeting are described. A recorded video may be stabilized by removing shake introduced in the video, and a video may be retargeted by modifying the video to fit to a different aspect ratio. Constraints can be imposed that require a modified video to contain pixels from the original video and/or to preserve salient regions. In one example, a video may be processed to estimate an original path of a camera that recorded the video, to estimate a new camera path, and to recast the video from the original path to the new camera path. To estimate a new camera path, a virtual crop window can be designated. A difference transformation between the original and new camera path can be applied to the video using the crop window to recast the recorded video from the smooth camera path.
url: http://patft.uspto.gov/netacgi/nph-Parser?Sect1=PTO2&Sect2=HITOFF&p=1&u=%2Fnetahtml%2FPTO%2Fsearch-adv.htm&r=1&f=G&l=50&d=PALL&S1=08531535&OS=08531535&RS=08531535
owner: Google Inc.
number: 08531535
owner_city: Mountain View
owner_country: US
publication_date: 20110208
---
The present application claims priority to U.S. provisional patent application Ser. No. 61 407 630 filed on Oct. 28 2010 the entire contents of which are herein incorporated by reference as if fully set forth in this description.

Image stabilization includes many techniques used to reduce blurring associated with motion of a camera during exposure. Image stabilization techniques may compensate for pan and tilt angular movement of a camera or other imaging device. With still cameras camera shake can be problematic at slow shutter speeds or with long focal length telephoto lenses and image stabilization techniques can be used to improve a still picture.

Similarly video stabilization techniques may be used to improve recorded videos. With video cameras camera shake can cause visible frame to frame jitter in a recorded video. For example handheld camera or handheld video recording is a film and video technique in which a camera is held in the camera operator s hands and a handheld recorded video may be perceptibly shakier than a video recorded using a tripod mounted camera or other stabilization equipment such as camera dollies or steady cams due to motion of the operator holding the camera during recording. However recording videos using handheld video recording may enable more opportunities for filming.

Video stabilization techniques may be used to create a stable version of a casually shot video e.g. a video recorded on a device with little or no stabilization equipment . Video stabilization techniques generally attempt to render the recorded video as the video would have been recorded from a smooth or stable camera path.

The present application discloses embodiments of systems and methods for processing a video for stabilization and retargeting. In one aspect a method for processing a video is described. The method may comprise estimating an original motion path of a camera that recorded a video. The method may also comprise determining at each time t a substantially constant path a substantially constant velocity or a substantially constant acceleration of the original motion path of the camera. The method also may comprise determining a modified motion camera path of the original motion path of the camera including for each time t the substantially constant path the substantially constant velocity or the substantially constant acceleration of the original motion path of the camera. The method may further comprise based on the modified motion camera path and the original motion path of the camera determining a crop window transform that describes how to modify the original motion path of the camera to the modified motion camera path and the crop window transform may be determined according to at least one constraint limiting changes to the original motion path of the camera. The method may further comprise applying the crop window transform to the video to recast the video from a viewpoint of the original motion path of the camera to a viewpoint of the modified motion camera path.

In another aspect a non transitory computer readable medium having stored therein instructions executable by a computing device to cause the computing device to perform functions is described. The functions may comprise estimating an original motion path of a camera that recorded a video. The function may further comprise determining at each time t a substantially constant path a substantially constant velocity or a substantially constant acceleration of the original motion path of the camera. The functions also may comprise determining a modified motion camera path of the original motion path of the camera including for each time t the substantially constant path the substantially constant velocity or the substantially constant acceleration of the original motion path of the camera. The functions further may comprise based on the modified motion camera path and the original motion path of the camera determining a crop window transform that describes how to modify the original motion path of the camera to the modified motion camera path the crop window transform determined according to at least one constraint limiting changes to the original motion path of the camera. The functions further may comprise applying the crop window transform to the video to recast the video from a viewpoint of the original motion path of the camera to a viewpoint of the modified motion camera path.

In still another aspect a camera path translation system is provided that comprises a camera path estimation engine a video stabilization and retargeting engine and a video translation engine. The camera path estimation engine may be configured to receive a video and to estimate an original motion path of a camera that recorded the video based on motion of objects within the video. The video stabilization and retargeting engine may be configured to determine a crop window transform that describes how to modify the original motion path of the camera to a modified motion camera path and the crop window transform may be determined according to at least one constraint limiting changes to the original motion path of the camera. The video translation engine may be configured to apply the crop window transform to the video to recast the video from a viewpoint of the original motion path of the camera to a viewpoint of the modified motion camera path.

The foregoing summary is illustrative only and is not intended to be in any way limiting. In addition to the illustrative aspects embodiments and features described above further aspects embodiments and features will become apparent by reference to the figures and the following detailed description.

The following detailed description describes various features and functions of the disclosed systems and methods with reference to the accompanying figures. In the figures similar symbols identify similar components unless context dictates otherwise. The illustrative system and method embodiments described herein are not meant to be limiting. It may be readily understood that certain aspects of the disclosed systems and methods can be arranged and combined in a wide variety of different configurations all of which are contemplated herein.

This disclosure may disclose inter alia systems and methods for stabilizing and retargeting recorded videos. For example a recorded video may be stabilized by removing at least a portion of shake introduced in the video and a video may be retargeted by modifying the video to fit to a different aspect ratio. The disclosure describes examples for stabilizing and retargeting recorded video by imposing constraints that require a modified video to contain valid pixels from the original recorded video and or to preserve salient regions and objects for example.

In one example a video may be stabilized by performing post processing techniques. The video may be processed to estimate an original path e.g. motion of a camera that recorded the video to estimate a new steady smooth camera path and to recast the video from the original path to the smooth camera path. In one example to estimate a new camera path a virtual crop window of a pre defined scale less than one with respect to an original frame size can be designated. A difference transformation between the original and smooth camera path can be applied to the recorded video using the crop window to recast the recorded video as if the video had been recorded from the smooth camera path to remove shake from the recorded video for example. If the crop window does not fit in the original frame in one example undefined areas may be filled using motion in painting. In another example constraints can be imposed to prevent undefined areas from occurring.

Referring now to a block diagram of a camera path translation system is illustrated. The camera path translation system includes a camera path estimation engine a video stabilization and retargeting engine and a video translation engine . The camera path translation system may be configured to receive a video and to perform video stabilization processes on the video. For example the camera path estimation engine may estimate a path of a camera that recorded the video based on motion of objects within the received video. The video stabilization and retargeting engine may then estimate a new steady smooth camera path and the video translation engine may recast the received video from a viewpoint of the smooth camera path determined by the video stabilization and retargeting engine .

One or more of the described functions or components of the system may be divided up into additional functional or physical components or combined into fewer functional or physical components. In some further examples additional functional and or physical components may be added to the examples illustrated by . Still further any of the camera path estimation engine the video stabilization and retargeting engine and or the video translation engine may include or be provided in the form of a processor e.g. a micro processor a digital signal processor DSP etc. configured to execute program code including one or more instructions for implementing logical functions described herein. The system may further include any type of computer readable medium non transitory medium for example such as a storage device including a disk or hard drive to store the program code. In other examples the camera path translation system may be included within other systems.

Turning to the individual entities illustrated on each client A N may be used by a user to request video hosting services. For example a user can use the client A to send a request for uploading a video for sharing or playing a video. The clients A N can be any type of computer device such as a personal computer e.g. desktop notebook tablet laptop computer as well as devices such as a mobile telephone personal digital assistant or IP enabled video player. The clients A N may include a processor a display device or output to a display device and a local storage such as a hard drive or flash memory device to which the clients A N store data used by the user in performing tasks and a network interface for coupling to the video hosting service via the network .

The clients A N may include a video player A N e.g. the Flash player from Adobe Systems Inc. or a proprietary one for playing a video stream. The video player A N may be a standalone application or a plug in to another application such as a network or Internet browser. Where the client A N is a general purpose device e.g. a desktop computer mobile phone the player A N may be implemented as software executed by the computer. Where the client A N is a dedicated device e.g. a dedicated video player the player A N may be implemented in hardware or a combination of hardware and software. The player A N may include user interface controls and corresponding application programming interfaces for selecting a video feed starting stopping and rewinding a video feed. Also the player A N can include in a user interface a video display format selection configured to indicate a video display format e.g. a standard definition TV or a high definition TV . Other types of user interface controls e.g. buttons keyboard controls can be used as well to control the playback and video format selection functionality of the player A N.

The network enables communications between the clients A N and the video hosting service . In one embodiment the network is the Internet and uses standardized internetworking communications technologies and protocols known now or subsequently developed that enable the clients A N to communicate with the video hosting service . In another embodiment the network may be a wireless cellular network that enables wireless communication between the clients A N and the video hosting service .

The video hosting service comprises the camera path translation system a video server an ingest server and a video database . The video server may be configured to serve videos from the video database in response to user video hosting service requests. The ingest server may be configured to receive user uploaded videos and store the videos in the video database . The video database may be configured to store user uploaded videos and videos processed by the camera path translation system . In one embodiment the video database stores a large video corpus.

The camera path translation system may include a camera path estimation engine a video stabilization and retargeting engine and a video translation engine . The camera path translation system may be configured to receive user uploaded videos from the ingest server and to perform video stabilization of the videos.

In one example the camera path estimation engine may estimate a path of a camera that recorded the video based on motion of objects or images within the received video. A camera path may be estimated by extracting trackable features in frames of the video matching features and performing local outlier rejection to remove spurious matches that may distort motion estimation. Linear motion models e.g. translation similarity affine may be fit to the tracked features to estimate a motion of the camera between two frames and the motion models can be transformed to a common coordinate system and concatenated to yield an estimated original camera path over all frames of the video.

The video stabilization and retargeting engine may then estimate a new steady smooth camera path based on constraints. For example a base vertical line may be established for desired vertical camera path motion and constraints can be established to allow a camera path to be modified by a constrained amount e.g. if camera motion moves downward pixels in images are moved upward to align with a previous frame and bottom row s of pixels can be removed or cropped out to an extent as allowed by the constraints .

A smooth camera path can be estimated using minimization of derivatives of the original camera path as estimated by the camera path estimation engine . For example a constant path may represent a static camera 

In one example to estimate a camera path P t comprising segments of constant linear and parabolic motion an optimization may be performed as a constrained L1 minimization solution. For example an N dimensional vector norm of order p is defined as

In addition a camera path P t can be determined that minimizes the above derivatives while satisfying constraints. A variety of constraints may be used such as an inclusion proximity and saliency constraints. An inclusion constraint requires a crop window transformed by the path P t to always or substantially always be contained in an original frame rectangle transformed by C t the camera path. A proximity constraint includes a new camera path P t preserving or substantially preserve the original intent of the movie e.g. if the original path contained segments of zooming the new camera path may follow this motion. A saliency constraint includes salient points e.g. obtained by a face detector or general mode finding in a saliency map within all or a part of a crop window transformed by P t . Many other constraints may be used as well.

The video translation engine may recast the received video from a viewpoint of the smooth camera path determined by the video stabilization and retargeting engine by applying a transformation to the video to produce a cropped video with less shake for example. Thus in one embodiment video stabilization may be performed by 1 estimating per frame motion transforms F 2 determining an optimal camera path P CB where Cis based on the motion transforms Fand Bis a crop window transform estimated as described below and 3 stabilizing the video by warping according to B.

In addition for the method and other processes and methods disclosed herein the flowchart shows functionality and operation of one possible implementation of present embodiments. In this regard each block may represent a module a segment or a portion of program code which includes one or more instructions executable by a processor for implementing specific logical functions or steps in the process. The program code may be stored on any type of computer readable medium for example such as a storage device including a disk or hard drive. The computer readable medium may include a non transitory computer readable medium for example such as computer readable media that stores data for short periods of time like register memory processor cache and Random Access Memory RAM . The computer readable medium may also include non transitory media such as secondary or persistent long term storage like read only memory ROM optical or magnetic disks compact disc read only memory CD ROM for example. The computer readable media may also be any other volatile or non volatile storage systems. The computer readable medium may be considered a computer readable storage medium a tangible storage device or other article of manufacture for example.

In addition for the method and other processes and methods disclosed herein each block in may represent circuitry that is wired to perform the specific logical functions in the process.

At block a recorded video is received. At block trackable feature matches in frames of the video are extracted. For example trackable features in each frame of the video are extracted or trackable features in substantially all frames of the video are extracted. Trackable features in frames of the video may be extracted using feature tracking software such as the pyramidal Lucas Kanade feature tracking as implemented in OpenCV. Features may be tracked from frame to frame using any number of methods. Example features for extracting include corners of an image in which intensity changes along the x and y dimension of an image. In another example trackable features between two frames may be extracted by extracting a number of features in a first video frame e.g. based on x and y location and tracking the extracted features in a next video frame. For example if the video is a sequence of images I I . . . I video frame pairs may be I I and feature pairs between video frames may be extracted e.g. for each feature x in frame I a corresponding feature y at the same point in space as the feature x is found in frame I . With small intra frame motions and changes in illumination brightness values of a small image patch e.g. 7 7 pixels centered around the feature point x in Iand its matching point y in Imay be nearly identical. For each feature x in I a displacement vector d may be determined such that the I x I x d and therefore x d y using the previous notation e.g. that is feature matches xy . This expression can be linearized by Taylor Series expansion around x yielding DI x d I x I x which is linear in the unknown displacement vector d. An over determined linear system of equations may be determined of the form A d b that can be then solved by using normal equations i.e. solving the symmetric linear system AA d Ab by Gaussian Elimination where Adenotes the transpose of A . This process may be referred to as pyramidical Lucas Kanade Tracking.

During feature tracking from one frame to the next frame errors may accumulate. To detect potentially poor feature matches images in a window around the feature in the current frame can be monitored to determine if the images are similar to the images around the feature in the first frame. Features may be tracked over many frames and the image content can change. For a consistency verification translational mapping that is used for feature tracking from frame to frame may be performed in addition to a similarity or an affine mapping.

This process may be performed for all video frames of the video to determine multiple pairs of feature correspondences i.e. each pair corresponding to a feature location in a first and a second frame respectively.

At block local outlier rejection may performed to remove spurious extracted feature matches or feature pairs that may distort motion estimation rather than or in addition to global outlier rejection to account for multiple independent motion layers . Some of the feature pair matches between video frames may be incorrect and can be removed. To remove feature pairs matches that may have been incorrectly identified as a corresponding pairs an algorithm such as random sample consensus RANSAC may be used. The algorithm may identify outliers within a set of observed data. For example all feature pairs may be initialized as inliers i.e. data whose distribution can be explained by a set of model parameters. An average mathematical translation e.g. moving every point a constant distance in a specified direction can be computed based on inlier pairs. Pairs whose translation differs from the average translation by more than a threshold amount can be removed from the inlier set and classified as outliers that are data that do not fit the model. The threshold amount may be determined based on observed results. A smaller threshold can be used to remove a larger number of feature pairs and a larger threshold can be used to remove a smaller number of feature pairs. The algorithm may be performed iteratively e.g. with a fixed number of iterations by determining an average mathematical translation of feature pairs that were not removed from the inlier set.

In another example to perform local outlier rejection to remove spurious feature matches a model may be fit to the feature pairs. The model may be formed by a mathematical translation or other linear transformations as well. If a feature pair fits the model the feature pair is considered an inlier. The model may be reasonably sufficient if a number of points have been classified as inliers. The model can be reestimated from all feature pairs that are now considered inliers. This procedure can be repeated a fixed number of times and each time may produce either a model which is rejected because too few points are classified as inliers or a refined model together with a corresponding error measure.

To account for independent moving objects the local outlier rejection can be performed by leveraging per frame segmentation and imposing a local 2D translation motion model on each region for each feature pair. To reduce overhead introduced by using per frame segmentation an estimation mode may be used that replaces segmentation regions with square regions of similar block sizes onto each frame for example.

In addition feature pairs can be removed from moving objects in a foreground region. For example local outlier rejected feature pairs can be classified into independent moving foreground and static background regions by estimating a fundamental Matrix F using RANSAC from the feature pairs where the fundamental matrix F is a 3 3 matrix that relates corresponding points in stereo images e.g. with homogeneous image coordinates x and x of corresponding points in a stereo image pair Fx describes a line an epipolar line on which the corresponding point x on the other image lies . Regions that adhere to the fundamental matrix constraint can be labeled background regions and regions that violate the constraint can be labeled foreground regions.

In still another example to perform local outlier rejection to remove spurious feature matches features may be discretized into a grid of 50 50 pixels and RANSAC may be performed on each grid cell to estimate a translational model in which matches that agree within a specific threshold distance e.g. 

In still another example to perform local outlier rejection neighboring features may be required to have similar displacement vectors. This can be achieved by partitioning an image into regions e.g. using grid based regions or perceptually homogeneous regions obtained from image segmentation . For each region R a random displacement vector d is selected that falls into this region and a number of displacement vectors in R that are within a specified distance e.g. 2 pixels to the selected vector d can be determined referred to as inliers . This process can be repeated several times and a largest inlier set. This process can be applied to each region for example.

At block two dimensional 2D linear motion models e.g. translation similarity affine can be fit to the trackable feature matches to describe motion of the camera between video frames or between two consecutive video frames. For example the video may be a sequence of images I I . . . I and each frame pair I I can be associated with a linear motion model F x modeling the motion of feature points x from Ito I. A least square fit can be determined for a linear transform that maps feature matches from one frame to the next e.g. to describe motion of pixels between frames such as feature moved 10 pixels to the right equivalent to movement of the camera to the left by 10 pixels . For a mathematical translation the least square fit can be an average of translations for each feature pair match.

As one example an estimate of the original camera path C t can be determined by fitting linear motion models to the tracked feature pair matches resulting in a linear transform for each feature pair e.g. a linear transform describing motion of the feature of the matched feature pair from one video frame to the next video frame . Features in a first frame may be denoted as x . . . x and corresponding features in a second frame may be denoted as x . . . x . A linear transform F can be found such that Equation 1 

Equation 4 can be solved for a number of linear motion models for each of the video frames of the video or for any number of the video frames of the video . Many linear motion models may be used such as a translation model F x t x t a similarity model F x t a b a b b a x t and an affine model F x t a b c d a b c d x t. In one example Equation 4 may be written in matrix from as

Additional methods for determining two dimensional 2D linear motion models e.g. translation similarity affine for the trackable feature matches are also possible. For example a parametric motion model can be fit to the locally outlier rejected feature matches i.e. a motion that can be described by a set of parameters or degrees of freedom DOF such as a translation 2 DOF similarity 2 DOF translation 1 DOF scale 1 DOF rotation affine 6 DOF or a homography 8 DOF . A linear model can be expressed as matrix multiplication with a location x i.e. y A p x with A being a matrix and p the parameterization. For example for a similarity p dx dy s scale r cos of rotation and A p would be the 3 3 matrix

In one example unreliable motion models may be detected by requiring at least a certain number of feature matches per frame pair e.g. N 30 otherwise the frame may be flagged as unreliable . In another example estimates from lower to higher dimension motion models e.g. similarity homography may be performed using matches for the higher dimension model that agree with the lower dimension within a threshold e.g. 4 pixels to detect unreliable motion models. In still another example if a highest dimension motion model is deemed unreliable e.g. too much rotation scale or perspective other computed models may be flagged as unreliable. A heuristic may be used that labels each frame s motion model as reliable or unreliable. Unreliable motion models can be discarded and set to identity. Additional hard constraints can be added to the optimal L1 camera path estimation to force the path to be stationary in the vicinity of unreliable frame motion models for example. In those instances the optimized camera path is identical with the original shaky path in these segments. In these instances if parts of video data are too corrupted that reliable motion estimation is not possible or is not determined the original shaky video data can be used for this portion of the video for example.

At block the linear motion models F for each feature pair are transformed to a common coordinate system and are concatenated to yield an estimate of the original camera path. For example concatenation of all linear motion models for each feature pair may describe motion between each of the frames of the video resulting in an estimate of the original camera path. A camera path is a cumulative path and thus if a camera path moved to the left by 10 pixels between two successive frames and so on by the time a fifth frame is reached the camera may have moved 50 total pixels in distance for example.

An inverse of the transform F between feature pairs of video frames Iand I G F can be used as a coordinate transform. Note that the transform Gcan be computed with respect to the coordinate system defined by frame ITherefore to transform each Gto a common coordinate system to be able to concatenate all linear motion models a coordinate system can be arbitrarily chosen such as the coordinate system of G for example.

An estimate of the original camera path can then be obtained by concatenating the frame pair transforms G G . . . G where m denotes the number of frames. The camera path C C . . . C can be iteratively estimated as and Equation 5 An estimation of per frame linear motion models can lead to an accumulation of error over time and thus each frame can be tracked with respect to a previous N frames where N is fixed e.g. N may be about 3 to about 5 for a speed vs. accuracy trade off . In another example all parameters can be estimated for all frames jointly.

Thus C t is an estimate of the original camera path and is described by a parametric linear motion model at each instance of time. For example the video may be a sequence of images I I . . . I and each frame pair I I may be associated with a linear motion model F x modeling the motion of feature points x from Ito I.

Using the method in an estimate of the original motion of the camera or original camera path for the video recording can be made. Following an estimate of a new steady or smooth camera path can be determined. The steady or smooth camera path may dampen high frequency jitter and remove low frequency distortions that occur during handheld panning shots or videos recorded by a person walking.

At block an estimate of the original camera path motion is received. At block constraints limiting changes to the original camera path motion are received. Example constraints include an inclusion constraint that requires a frame in the smooth motion to always be contained in a frame of the original camera path motion a proximity constraint that requires the smooth camera path motion to preserve an original intent of the recorded video e.g. if the original camera path motion contained segments of zooming the smooth camera path motion may also contain zooming and a saliency constraint that requires salient points e.g. obtained by a face detector or general mode finding in a saliency map may be included within all or a portion of a new frame in the smooth camera path motion. As another example the constraints may indicate that the updated camera path motion results in a video frame window that fits inside a video frame window of the original camera path motion at all times.

At block a cost function is received and minimization is performed. For example the smooth or optimal camera path P can be partitioned into three segments where only one may be present at each time t a constant path representing a static camera i.e. 

In one embodiment weights of the cost function in Equation 7 can be preset. Alternatively values of the weights may be determined from professional footage. For example professional videos have different kinds of camera motions and if jitter is added to the motion the video stabilization algorithm may be performed to retrieve an original smooth camera path. Weights that result in a close match to the original path can be determined.

As another example to determine weights for the cost function in Equation 7 if only one of the three derivative constraints is minimized the original path can be approximated by either constant non continuous paths linear paths with jerks or smooth parabolas with non zero motion. illustrate example graphs of an optimal camera path determined based on a synthetic original camera path . illustrates the optimal camera path including constant non continuous paths with weights chosen such that a 1 and b c 0. illustrates the optimal camera path including linear paths with abrupt changes with weights chosen such that a c 0 and b 1. illustrates the optimal camera path including smooth parabolas and non zero motion using weights chosen such that a b 0 and c 1.

In one embodiment all three objectives in Equation 7 can be minimized simultaneously. Twitching motions may be noticeable in stabilized video and can be minimized when weight c is chosen to be an order of magnitude larger than a maximum of weights a and b. For example illustrates the optimal camera path with weights chosen such that a 10 b 1 and c 100. Further a choice of the underlying linear motion model has an effect on the stabilized video. Using affine transforms instead of similarities for example has a benefit of two added degrees of freedom but may introduce errors in skew that lead to effects of non rigidity. However similarities like affine transformation may not be able to model a non linear inter frame motion or rolling shutter effects which may result in noticeable residual wobble.

The known frame pair transforms Fare represented by linear motion models. For example Fcan be given as six degrees of freedom DOF affine transformation

Using linear programming constraints can be imposed on the optimal camera path so that Equation 7 is minimized subject to constraints. Recall that prepresents the parameterization of the crop window transform B t which is the transform of the crop window centered in the frame rectangle. The crop window transform B t can be constrained so as to limit how much B t can deviate from the original camera path motion to preserve an intent of the original video. Therefore strict bounds can be placed on the affine portion of the parameterization p which according to one example of Equation 14 may include 1 0.9 1.1 2 0.1 0.1 3 0.05 0.05 4 0.1 0.1 Equation 15 The first two constraints in Equation 15 limit a range of change in zoom and rotation and the latter two constraints in Equation 15 give the affine transform rigidity by limiting an amount of skew and non uniform scale. Therefore for each p e.g. affine translation etc. there is an upper bound ub and lower bound lb that can be written as lowerbound Up upperbound for suitable linear combinations specified by U e.g. U is a notation placeholder which in the example in Equation 15 lowerbound would be the vector 0.9 0.9 0.1 0.1 0.05 0.1 and U is a matrix

In one example the upper bound and lower bound for the translation parameterization may be as shown below in Equation 16 

As another example to achieve the inclusion constraint all four corners c c c i 1 . . . 4 of the crop window transformed by the crop window transformation B t can be required to reside inside the original frame rectangle. illustrates an example video frame rectangle and a crop window rectangle. As shown in all four corners of the crop rectangle transformed by B t are within the original frame rectangle of coordinates 0 w by 0 h .

Additional constraints may be imposed for smoothness constraints on similarity and affine linear motion model transformations. For example in a similarity transform a combination of scale rotation and translation can be used. A smoothness constraint can be imposed on P t using weights a and b for the similarity transformation F x t a b a b b a x t . While t corresponds to translation scale and rotation are related to a b as Scale square root over Equation 17 Rotation angle tan Equation 18 While constraining smoothness on a b rotation and scale may not remain smooth. Since imposing smoothness constraints on s and theta may be non linear the estimated camera path can be used to ensure that s and theta do not deviate too much. For example constraints on scale and rotation may be as follows scale low

In one embodiment hard constraints can be modeled in a form of transformed points in convex shape . For example for an affine parameterization of p constraints may be as shown below in Equation 25 

Referring back to the method in at block a crop window transformation B t of a pre defined scale less than one with respect to the original frame size is determined subject to the constraints and minimizations of the residuals. In one example P t C t B t as shown in Equation 6 above and B t is the crop window transform. The crop window transform may be determined by minimizing ce with respect to the parameterization vector p where Equation 26 where e is the upper and lower bound as shown in Equation 14 and w are weights. To minimize the L1 norm of the residual the L1 norm of the slack variable e can be minimized. In vector form for example the minimization can be written as the dot product of c e or ce with c being the vector of all 1. In other examples c may contain the weights a b c from Equation 7 for the corresponding components.

The function ce may be minimized subject to various constraints such as Smoothness 2 0 Equation 27 Proximity lowerbound Up upperbound Equation 28 Inclusion 0 0 Equation 29 In one example although the objective ce is minimized in a linear program all variables in the constraints may be determined a linear combination of values according to smoothness proximity and inclusion may be modeled via slack variables . Therefore for each frame t corresponding parameters pcan be determined and B t A x p as in Equation 12 .

At block after determining the crop window transformation B t the crop window transformation is applied to the original video to reformat the video or to stabilize the video. For example the crop window transform may be applied to a crop window of fixed size within domain or frame size of the original video. By copying the pixel within the crop window that is applying the crop the original video is recast from a viewpoint of the smooth camera path. In other examples the copying can be supplemented with bi linear or bi cubic blending to achieve subpixel accuracy.

When recasting the video original camera motions may result in equivalent smooth motion of feature points with certain assumptions. For example for camera translation if a distance from the camera to objects is much greater than a velocity in any direction then a static camera results in static feature points a constant velocity lateral to camera results in constant feature point velocity a constant velocity in depth approximately results in a constant feature point velocity and the same approximations can be made for accelerations. As another example for camera zoom a constant velocity zoom results in a constant feature point velocity. As still another example for camera rotation feature point motion derivatives may diminish as a square of angular velocity.

As described above using the example methods shown in a 2D original camera path motion C t may be first estimated and a new path P t can be determined. The camera stabilization crop transform B t can then be determined that stabilizes C t resulting in P t . In one embodiment instead of solving for P t in two steps by first estimating C t and then optimizing for the path P t both steps can be performed simultaneously by directly optimizing for the stabilization transform from feature correspondences. In other examples minimization of residuals may not require C t and the per frame transforms F t may be sufficient. Similarly P t may not be computed but rather B t may be obtained. However in some examples C t and P t can be computed via concatenation.

In the example methods shown above in the estimation of the original camera path motion C t can be determined using frame pairs and relying on first order derivatives. The methods are based on N frames which requires concatenation of camera path derivatives and can lead to error accumulation.

As described above using the example methods shown in the original camera path motion is approximately an inverse of an average feature path transformation e.g. as a camera moves to the left the image pixel content or features move to the right . The average can be computed over robust feature points. As another example the estimation of the original camera path motion and determination of the new optimal camera path can be performed to simultaneously stabilize all or several feature points. For example using L1 minimization over all features e.g. for the translation model results in a median of feature tracks as opposed to an average which can be more robust. A frame stabilization transform A t can be estimated at each frame. A t transforms each video frame and equivalently features in the frame as opposed to transforming the camera path or crop window as above in the methods of . For example 

Note that Equation 33 may be a summation over all feature points as opposed to just the camera path. The constraints required to ensure that the crop window remains within the original frame can be handled in an alternate manner. For example applying the constraints as before would result in constraint equations as shown in Equation 34 

As still another example the estimation of the original camera path motion and determination of the new optimal camera path can be performed to stabilize using more than a single transform between frame pairs and less than using all feature points. For example a small number of transforms between a frame pair can be used and each of transforms may correspond to different regions in an image that may be moving differently. Each region may correspond to a different transform and therefore a different M matrix in Equation 13 above. Equation 13 may become 

Each of the transforms could also be weighted differently depending upon various factors such as for example foreground background separation stabilize foreground more than background a size of regions stabilize larger regions more than smaller regions and texturedness stabilize textured regions over untextured regions . The camera path optimization may then determine a stabilization that minimizes the L1 norm of path smoothness over all transforms. The optimization may lead to selecting a set of transforms to smooth while leaving regions unstable. The choice of which transforms are smoothed may be determined by a combination of individual importance weights .

Within embodiments any number of linear constraints may be added for forcing or limiting a modification of the recorded video in some way. For example constraints can be added to ensure that the crop window remain inside an original video frame. Other types of constraints may be used for content aware constraints such as maintaining a face e.g. from a face detector or other salient or user marked objects regions within an original video frame. Content aware constraints may be specified as regions that remain in the cropped frame entirely e.g. hard constraint or to some degree e.g. soft constraint . The constraints may also be specified on a per frame basis as the estimated smooth camera path may propagate the constraints from key frames to other frames.

In one example if a region of interest is represented using a bounding polygon such as a bounding box then one constraint for containment may be that each vertex of the polygon lie within the cropping window e.g. require that specific salient points reside within the crop window. If v is a vertex of the polygon then in the camera path optimization framework the constraint is opposite of Equation 36 and may be represented by 0 Equation 38 This may be considered a hard constraint and may limit the region of interest to remain inside the cropping window.

As another example a more relaxed constraint is a soft one sided constraint that penalizes any vertices that move out of the cropping window. As described above the L1 minimization can be converted to a linear program by adding slack variables which are minimized and modified constraints that bound the original constraint within lowerbound Up upperbound. A similar procedure may be used to bound the constraints from one side. Specifically the objective cost function may include 

In one example to require that specific salient points reside within the crop window an optimization is performed that is the inverse of stabilization transform F i.e. a feature transform W e.g. warp transform can be applied to a set of features in each frame I. An inverse of Fis denoted by G F. Instead of transforming the crop window by B a transform Wof the current features such that motion within a static crop window is composed of static linear or parabolic motion is determined. The transform is then given as B W.

The corresponding objectives for minimization of the warp transform similar to Equation 7 above may be as follows 

In one example saliency constraints may be specified as well using the warp transform. For example a specific point e.g. mode in a saliency map or convex region e.g. from a face detector may be constrained to remain within the crop window. A set of salient points in frame Imay be denoted by s. To estimate the feature transform e.g. instead of the crop window transform a one sided bound instead of a two sided bounds for inclusion constraints as in Equation 29 can be introduced on stransformed by A p 

Inclusion constraint can be used and adjusted from those described above as the crop window points can be transformed by the inverse of the optimized feature transform. In one example transformed frame corners may be required to lie within a rectangular area around a crop rectangle as illustrated in above for example. An estimation of the optimal feature paths can be achieved from feature points fin frame I i.e. without a need to compute G for example. In this setting instead of minimizing the L1 norm of the parameterized residual R p the L1 norm of the feature distance can be minimized. Thus Rbecomes 

To model inter frame motion for shake removal motion models with a higher number of DOFs than similarities may be needed. In one embodiment a hybrid approach can be used with similarities Sto construct an optimal camera path. The optimal camera path can be determined for every k 30 key frames of a recorded video using higher dimensional homographies Hto account for mis alignments.

For an example camera path in C C F. In Fis referred to as Sto indicate that the transformation is similarity e.g. C C S . To determine the relationship between optimal path transforms Pand P in one example if the video could be stabilized perfectly P P S which may indicate that the residual in the L1 minimization is zero. In general however this may not occur and thus the transform from Pto Pcan be referred to as a similarity and a residual motion T such that P P S T. Thus the motion T SPP.

In one example the Tmay be considered a smooth additional motion layered on top of the stabilization transform Sto account for various constraints introduced. The path transform Pcan be re computed by substituting Swith a higher parametric motion model H e.g. homography in the equation for Presulting in P P H T. This may result in a more stabilized result e.g. more degrees of freedom can adapt to rolling shutter etc. and may also lead to drift e.g. instabilities due to concatenation in skew perspective etc. . To remove or compensate for drift the computed P e.g. free of drift as based on similarities may be used at key frames e.g. every 30frame and the substitution of Hmay be used in between. In one example the substitution may be employed from the previous and next key frame to determine P and P . A new wobble reduced camera path can then obtained as a weighted average of a P a P . A linear weight may be used based on a distance to the key frames e.g. a is 1 and a 0 at the previous key frame and a 0 and a 1 at the next frame linear in between.

Content aware constraints may also be used for retargeting in addition to or rather than stabilization. Retargeting refers modifying a recorded video to fit a device with a different resolution aspect ratio than the recorded video. Using methods described herein a cropping window can be matched to an aspect ratio of a target device for example. Further content aware constraints can be used to ensure that salient content stays within the crop window. Optionally stabilization of feature points can be performed as well.

In one embodiment to perform retargeting instead of estimating a forward feature transform F between every pair of frames and using the resulting M matrices e.g. as for performing stabilization a number of matrices M I identity which corresponds to minimizing Equation 46 instead of minimizing Equation 13 including higher order terms as for performing stabilization for example.

Video Retargeting may change the aspect ratio of a video while preserving salient i.e. visually prominent regions.

A crop window may have a fixed predetermined size. For example a scale may be predetermined by first performing a video stabilization and then expanding the crop window to a maximum possible size that fits within the transformed frame windows over all frames i.e. determine A t v where v are the frame window corners for all frames t. A largest rectangle represented by lines m can be determined such that 0 Equation 47 Note that since m may be axis aligned computing this rectangle can be accomplished by identifying minimum and maximum values of the frame window coordinates over all times.

In one embodiment constraints may be added to the one sided constraints above such that the frame transforms A t result in as large a frame window as possible. A corresponding objective and constraint may be of the form 

Depending on the desired configuration the system memory can be of any type including but not limited to volatile memory such as RAM non volatile memory such as ROM flash memory etc. or any combination thereof. System memory may include one or more applications and program data . Application may include an video stabilization algorithm that is arranged to provide inputs to the electronic circuits in accordance with the present disclosure. Program Data may include video content information that could be directed to any number of types of data. In some example embodiments application can be arranged to operate with program data on an operating system.

Computing device can have additional features or functionality and additional interfaces to facilitate communications between the basic configuration and any devices and interfaces. For example data storage devices can be provided including removable storage devices non removable storage devices or a combination thereof. Examples of removable storage and non removable storage devices include magnetic disk devices such as flexible disk drives and hard disk drives HDD optical disk drives such as compact disk CD drives or digital versatile disk DVD drives solid state drives SSD and tape drives to name a few. Computer storage media can include volatile and nonvolatile non transitory removable and non removable media implemented in any method or technology for storage of information such as computer readable instructions data structures program modules or other data.

System memory and storage devices are examples of computer storage media. Computer storage media includes but is not limited to RAM ROM EEPROM flash memory or other memory technology CD ROM digital versatile disks DVD or other optical storage magnetic cassettes magnetic tape magnetic disk storage or other magnetic storage devices or any other medium which can be used to store the desired information and which can be accessed by computing device . Any such computer storage media can be part of device .

Computing device can also include output interfaces that may include a graphics processing unit which can be configured to communicate to various external devices such as display devices or speakers via one or more A V ports or a communication interface . The communication interface may include a network controller which can be arranged to facilitate communications with one or more other computing devices over a network communication via one or more communication ports . The communication connection is one example of a communication media. Communication media may be embodied by computer readable instructions data structures program modules or other data in a modulated data signal such as a carrier wave or other transport mechanism and includes any information delivery media. A modulated data signal can be a signal that has one or more of its characteristics set or changed in such a manner as to encode information in the signal. By way of example and not limitation communication media can include wired media such as a wired network or direct wired connection and wireless media such as acoustic radio frequency RF infrared IR and other wireless media.

Computing device can be implemented as a portion of a small form factor portable or mobile electronic device such as a cell phone a personal data assistant PDA a personal media player device a wireless web watch device a personal headset device an application specific device or a hybrid device that include any of the above functions. Computing device can also be implemented as a personal computer including both laptop computer and non laptop computer configurations.

In some embodiments the disclosed methods may be implemented as computer program instructions encoded on a computer readable storage media in a machine readable format or on other non transitory media or articles of manufacture. is a schematic illustrating a conceptual partial view of an example computer program product that includes a computer program for executing a computer process on a computing device arranged according to at least some embodiments presented herein. In one embodiment the example computer program product is provided using a signal bearing medium . The signal bearing medium may include one or more program instructions that when executed by one or more processors may provide functionality or portions of the functionality described above with respect to . Thus for example referring to the embodiments shown in one or more features of blocks and or blocks may be undertaken by one or more instructions associated with the signal bearing medium . In addition the program instructions in describe example instructions as well.

In some examples the signal bearing medium may encompass a computer readable medium such as but not limited to a hard disk drive a Compact Disc CD a Digital Video Disk DVD a digital tape memory etc. In some implementations the signal bearing medium may encompass a computer recordable medium such as but not limited to memory read write R W CDs R W DVDs etc. In some implementations the signal bearing medium may encompass a communications medium such as but not limited to a digital and or an analog communication medium e.g. a fiber optic cable a waveguide a wired communications link a wireless communication link etc. . Thus for example the signal bearing medium may be conveyed by a wireless form of the communications medium e.g. a wireless communications medium conforming with the IEEE 802.11 standard or other transmission protocol .

The one or more programming instructions may be for example computer executable and or logic implemented instructions. In some examples a computing device such as the computing device of may be configured to provide various operations functions or actions in response to the programming instructions conveyed to the computing device by one or more of the computer readable medium the computer recordable medium and or the communications medium .

It should be understood that arrangements described herein are for purposes of example only. As such those skilled in the art will appreciate that other arrangements and other elements e.g. machines interfaces functions orders and groupings of functions etc. can be used instead and some elements may be omitted altogether according to the desired results. Further many of the elements that are described are functional entities that may be implemented as discrete or distributed components or in conjunction with other components in any suitable combination and location.

While various aspects and embodiments have been disclosed herein other aspects and embodiments will be apparent to those skilled in the art. The various aspects and embodiments disclosed herein are for purposes of illustration and are not intended to be limiting with the true scope being indicated by the following claims along with the full scope of equivalents to which such claims are entitled. It is also to be understood that the terminology used herein is for the purpose of describing particular embodiments only and is not intended to be limiting.

